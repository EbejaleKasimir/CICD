{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import re\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load the JSON data into a pandas DataFrame\n",
    "df = pd.read_json('amazon_data_ext.json')\n",
    "\n",
    "# Replace NaN values in specified string columns with \"None\"\n",
    "string_columns = [\n",
    "    'Customer_1_ID',\n",
    "    'Customer_1_Comment',\n",
    "    'Customer_id_Critical_Review',\n",
    "    'Customer_Name',\n",
    "    'Customer_Review_Comment',\n",
    "    'Customer_Review_Title',\n",
    "    'Customer_2_ID'\n",
    "]\n",
    "df[string_columns] = df[string_columns].fillna(\"None\")\n",
    "\n",
    "# Replace NaN values in specified integer columns with 0\n",
    "integer_columns = [\n",
    "    'Customer_1_Star_Rating',\n",
    "    'Customer_1_buying_influence',\n",
    "    'Customers_Influenced'\n",
    "]\n",
    "df[integer_columns] = df[integer_columns].fillna(0)\n",
    "\n",
    "# Check if the 'Customers_Influenced' column is in the DataFrame\n",
    "if 'Customers_Influenced' not in df.columns:\n",
    "    print(\"Column 'Customers_Influenced' not found in the DataFrame. Please check the column name in the JSON file.\")\n",
    "\n",
    "# Convert 'Post_Date' to datetime object and handle any conversion errors by setting them to NaT\n",
    "df['Post_Date'] = pd.to_datetime(df['Post_Date'], errors='coerce', format='%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "# Replace NaT values with a default date string '0001-01-01'\n",
    "df['Post_Date'].fillna(pd.Timestamp('0001-01-01'), inplace=True)\n",
    "\n",
    "# Convert 'Post_Date' to 'yyyy-mm-dd' string format for PostgreSQL\n",
    "df['Post_Date'] = df['Post_Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# Replace NaN values with 'None' in the specified columns\n",
    "df['Customer_id_Critical_Review'] = df['Customer_id_Critical_Review'].replace({'\"NaN\"': 'None', 'NaN': 'None'})\n",
    "df['Customer_Name'] = df['Customer_Name'].replace({'\"NaN\"': 'None', 'NaN': 'None'})\n",
    "df['Customer_Review_Comment'] = df['Customer_Review_Comment'].replace({'\"NaN\"': 'None', 'NaN': 'None'})\n",
    "df['Customer_Review_Title'] = df['Customer_Review_Title'].replace({'\"NaN\"': 'None', 'NaN': 'None'})\n",
    "df['Customers_Influenced'] = df['Customers_Influenced'].replace({'\"NaN\"': 'None', 'NaN': 'None'})\n",
    "\n",
    "# Define the columns to be updated\n",
    "columns_to_update = [f'Customer_{i}_Comment' for i in range(1, 6)]\n",
    "for column in columns_to_update:\n",
    "    df[column] = df[column].replace({'\"NaN\"': 'None', 'NaN': 'None'})\n",
    "\n",
    "columns_to_update = [f'Customer_{i}_ID' for i in range(1, 6)]\n",
    "for column in columns_to_update:\n",
    "    df[column] = df[column].replace({'\"NaN\"': 'None', 'NaN': 'None'})\n",
    "\n",
    "# Drop all items with review having zero values\n",
    "df.drop(df.index[df['Customer_1_ID'] == 'None'], inplace=True)\n",
    "\n",
    "# Define the columns to be updated\n",
    "new_columns = ['Customer_id_Critical_Review', 'Customer_Name', 'Customer_Review_Comment', 'Customer_Review_Title', 'Customers_Influenced']\n",
    "for column in new_columns:\n",
    "    if column == 'Customers_Influenced': df[column] = df[column].replace({'\"NaN\"': 'None', 'NaN': 'None'})\n",
    "\n",
    "# Drop the 'review_responders' column if it exists\n",
    "if 'review_responders' in df.columns:\n",
    "    df.drop(columns=['review_responders'], inplace=True)\n",
    "\n",
    "# Handle other columns similarly\n",
    "df['price'] = df['price'].apply(lambda x: float(x) if pd.notnull(x) else None)\n",
    "df['ratings'] = df['ratings'].apply(lambda x: float(x) if pd.notnull(x) else None)\n",
    "df['reviews'] = df['reviews'].fillna(0).astype(int)\n",
    "\n",
    "# Drop rows where the 'price' column is NaN\n",
    "df.dropna(subset=['price'], inplace=True)\n",
    "\n",
    "# Drop all items with review having zero values or Customer_1_ID as 'None'\n",
    "df.drop(df.index[(df['reviews'] == 0) | (df['Customer_1_ID'] == 'None')], inplace=True)\n",
    "\n",
    "################################\n",
    "# df.info()\n",
    "# print(df.tail())\n",
    "################################\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"demopass\",\n",
    "    client_encoding='utf8'\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Modify the CREATE TABLE query to include additional columns\n",
    "create_table_query = \"\"\"\n",
    "DROP TABLE IF EXISTS amazon_data_ext;\n",
    "CREATE TABLE IF NOT EXISTS amazon_data_ext (\n",
    "    product_id TEXT NOT NULL,\n",
    "    product TEXT NOT NULL,\n",
    "    star_ratings NUMERIC NULL,\n",
    "    price_dollars NUMERIC NULL,\n",
    "    total_ratings INTEGER NOT NULL,\n",
    "    category TEXT NOT NULL,\n",
    "    url TEXT NOT NULL,\n",
    "    Customer_id_Critical_Review TEXT,\n",
    "    Customer_Name TEXT,\n",
    "    Post_Date DATE,\n",
    "    Customer_Review_Comment TEXT,\n",
    "    Customer_Review_Title TEXT,\n",
    "    Customers_Influenced INTEGER,\n",
    "    \"\"\" + \",\\n    \".join([f\"Customer_{i}_ID TEXT, Customer_{i}_Star_Rating NUMERIC, Customer_{i}_Comment TEXT, Customer_{i}_buying_influence INTEGER\" for i in range(1, 6)]) + \"\"\"\n",
    ")\n",
    "\"\"\"\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "def clean_format_data(row):\n",
    "    # Extract the values directly, as they are already cleaned\n",
    "    ratings = row['ratings']\n",
    "    price = row['price']\n",
    "    reviews = row['reviews']\n",
    "    product_id = row['Product_ID']\n",
    "    product = psycopg2.extensions.adapt(str(row['product']).encode('utf-8', 'replace')).getquoted().decode('utf-8')[1:-1]\n",
    "    category = psycopg2.extensions.adapt(row['category'].encode('utf-8', 'replace')).getquoted().decode('utf-8')[1:-1]\n",
    "    url = row['url']\n",
    "      \n",
    "    critical_review_id = row['Customer_id_Critical_Review'] if row['Customer_id_Critical_Review'] != 'None' else None\n",
    "    customer_name = row['Customer_Name'] if row['Customer_Name'] != 'None' else None\n",
    "    customer_review_comment = row['Customer_Review_Comment'] if row['Customer_Review_Comment'] != 'None' else None\n",
    "    customer_review_title = row['Customer_Review_Title'] if row['Customer_Review_Title'] != 'None' else None\n",
    "    customers_influenced = row['Customers_Influenced'] if row['Customers_Influenced'] != 'None' else None  # Correctly handle NaN values\n",
    "    \n",
    "    # Handle additional customer information\n",
    "    customer_data = []\n",
    "    for i in range(1, 6):\n",
    "        customer_id = row[f'Customer_{i}_ID'] if row[f'Customer_{i}_ID'] != 'None' else None\n",
    "        star_rating = row[f'Customer_{i}_Star_Rating'] if pd.notna(row[f'Customer_{i}_Star_Rating']) else None\n",
    "        comment = psycopg2.extensions.adapt(str(row[f'Customer_{i}_Comment']).encode('utf-8', 'replace')).getquoted().decode('utf-8')[1:-1]\n",
    "        buying_influence = row[f'Customer_{i}_buying_influence'] if pd.notna(row[f'Customer_{i}_buying_influence']) else None\n",
    "\n",
    "        customer_data.extend([customer_id, star_rating, comment, buying_influence])\n",
    "\n",
    "    # Validate and format the 'Post_Date' before returning\n",
    "\n",
    "    # Validate and format the 'Post_Date' before returning\n",
    "    post_date = row['Post_Date']\n",
    "    if post_date is not None and isinstance(post_date, str):\n",
    "        try:\n",
    "            # Check if post_date is already in 'YYYY-MM-DD' format\n",
    "            if re.match(r'\\d{4}-\\d{2}-\\d{2}', post_date):\n",
    "                datetime.strptime(post_date, '%Y-%m-%d')  # Validate the format\n",
    "            else:\n",
    "                # Try to parse the post_date to a datetime object with a different format\n",
    "                parsed_date = datetime.strptime(post_date, '%Y-%m-%dT%H:%M:%S')\n",
    "                # Format it back to a string in the desired format\n",
    "                post_date = parsed_date.strftime('%Y-%m-%d')\n",
    "        except ValueError as ve:\n",
    "            logging.error(f\"Invalid date format for Post_Date: {post_date}. Setting it to default value.\")\n",
    "            post_date = \"0001-01-01\"  # Default value for invalid date format\n",
    "    else:\n",
    "        logging.error(f\"Post_Date is not a string or is None: {post_date}. Setting it to default value.\")\n",
    "        post_date = \"0001-01-01\"  # Default value for None or non-string values\n",
    "    \n",
    "    # Replace other None values with appropriate default values\n",
    "    critical_review_id = critical_review_id if critical_review_id is not None else \"Unavailable\"\n",
    "    customer_name = customer_name if customer_name is not None else \"Unavailable\"\n",
    "    customer_review_comment = customer_review_comment if customer_review_comment is not None else \"Unavailable\"\n",
    "    customer_review_title = customer_review_title if customer_review_title is not None else \"Unavailable\"\n",
    "    customers_influenced = customers_influenced if customers_influenced is not None else 0  # Default numeric value\n",
    "    \n",
    "    # Handle additional customer information\n",
    "    customer_data = []\n",
    "    for i in range(1, 6):\n",
    "        customer_id = row[f'Customer_{i}_ID'] if row[f'Customer_{i}_ID'] != 'None' else \"Unavailable\"\n",
    "        star_rating = row[f'Customer_{i}_Star_Rating'] if pd.notna(row[f'Customer_{i}_Star_Rating']) else 0.0\n",
    "        comment = psycopg2.extensions.adapt(str(row[f'Customer_{i}_Comment']).encode('utf-8', 'replace')).getquoted().decode('utf-8')[1:-1]\n",
    "        comment = comment if comment != 'None' else \"Unavailable\"\n",
    "        buying_influence = row[f'Customer_{i}_buying_influence'] if pd.notna(row[f'Customer_{i}_buying_influence']) else 0\n",
    "        \n",
    "        customer_data.extend([customer_id, star_rating, comment, buying_influence])\n",
    "\n",
    "    logging.info(f\"Formatted Post_Date: {post_date}\")  # Log the formatted post_date\n",
    "    \n",
    "    return product_id, product, price, ratings, reviews, category, url, critical_review_id, customer_name, post_date, customer_review_comment, customer_review_title, customers_influenced, *customer_data\n",
    "\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO amazon_data_ext (\n",
    "    product_id, product, price_dollars, star_ratings, total_ratings, category, url,\n",
    "    Customer_id_Critical_Review, Customer_Name, Post_Date, Customer_Review_Comment, Customer_Review_Title, Customers_Influenced,\n",
    "    \"\"\" + \", \".join([f\"Customer_{i}_ID, Customer_{i}_Star_Rating, Customer_{i}_Comment, Customer_{i}_buying_influence\" for i in range(1, 6)]) + \"\"\"\n",
    ") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \"\"\" + \", \".join([\"%s\"] * 20) + \")\"\n",
    "\n",
    "\n",
    "# Insert the data from the pandas DataFrame into the PostgreSQL table\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        cur.execute(insert_query, clean_format_data(row))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inserting row at index {index}: {e}\")\n",
    "        logging.error(f\"Row data: {row}\")  # Log the entire row data\n",
    "        conn.rollback()\n",
    "\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "df.rename(columns={'ratings': 'star_ratings', 'reviews': 'total_ratings', 'price': 'price_dollars'}, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file with updated column names\n",
    "df.to_csv('amazon_data_ext.csv', index=False, encoding='utf-8')\"\n",
    "\n",
    "\n",
    "\n",
    "             \n",
    "            # Remove the pattern \"k out of 5 stars\\n\" from the comment\n",
    "            actual_comment_title = re.sub(r'\\d+(\\.\\d+)? out of 5 stars\\n', '', actual_comment_title)\n",
    "\n",
    "            result[f'Customer_{i+1}_Comment'] = actual_comment_title\n",
    "\n",
    "            # Extract the Number of people who found the review helpful\n",
    "            helpful_vote_tag = review_tag.select_one('span[data-hook=\"helpful-vote-statement\"]')\n",
    "            helpful_count = w2n.word_to_num(helpful_vote_tag.text.split()[0]) if helpful_vote_tag else 0\n",
    "            result[f'Customer_{i+1}_buying_influence'] = helpful_count\n",
    "        \n",
    "            # Extract all elements matching the criteria\n",
    "            critical_review_tags = soup.select('div[id^=\"viewpoint-\"]')\n",
    "            # critical_review_tags = soup.select('div.a-column.a-span6.view-point-review.critical-review.a-span-last')\n",
    "            if len(critical_review_tags) > 1:\n",
    "                # If there is more than one matching element, select the second one\n",
    "                critical_review_tag = critical_review_tags[1]\n",
    "                critical_review_tag_pack = critical_review_tag.get('id', 'NaN').replace('viewpoint-', '')\n",
    "                result['Customer_id_Critical_Review'] = critical_review_tag_pack\n",
    "                \n",
    "                # Extract Customer_Name\n",
    "                customer_name_tags = soup.select('span.a-profile-name')\n",
    "                result['Customer_Name'] = customer_name_tags[1].text if len(customer_name_tags) > 1 else 'NaN'\n",
    "                    \n",
    "                # Extract Customer_Review_Comment                \n",
    "                review_comment_tag = critical_review_tag.find('div', class_='a-row a-spacing-top-mini')\n",
    "                result['Customer_Review_Comment'] = review_comment_tag.text.strip() if review_comment_tag else 'NaN'\n",
    "                \n",
    "                # Extract Customer_Review_Title\n",
    "                review_title_tag = critical_review_tag.select_one('span[data-hook=\"review-title\"]')\n",
    "                result['Customer_Review_Title'] = review_title_tag.text if review_title_tag else 'NaN'\n",
    "\n",
    "                # Extract the post time\n",
    "                critical_review_tags_date = critical_review_tag.select('div.a-expander-content.a-expander-partial-collapse-content span.a-size-base.a-color-secondary.review-date')\n",
    "                if critical_review_tags_date:\n",
    "                    post_time_text = critical_review_tags_date[0].text.strip()\n",
    "                    match = re.search(r'on (.+)$', post_time_text)\n",
    "                    if match:\n",
    "                        date_string = match.group(1)\n",
    "                        try:\n",
    "                            post_date = datetime.strptime(date_string, '%B %d, %Y')\n",
    "                            # Convert the datetime object to a string in ISO format\n",
    "                            result['Post_Date'] = post_date.isoformat()                            \n",
    "                        except ValueError as ve:\n",
    "                            print(f\"Error parsing date string {date_string}: {ve}\")\n",
    "                            result['Post_Date'] = None\n",
    "                    else:\n",
    "                        print(\"Date not found in text:\", post_time_text)\n",
    "                        result['Post_Date'] = None\n",
    "                else:\n",
    "                    print(\"Date tag not found\")\n",
    "                    result['Post_Date'] = None\n",
    "\n",
    "                # Use soup.select() to find all matching elements\n",
    "                critical_review_tags_ = soup.select('div.a-column.a-span6.view-point-review.critical-review.a-span-last div.a-row.a-spacing-top-small span.a-size-small.a-color-tertiary span.review-votes')\n",
    "\n",
    "\n",
    "                # Check if any elements were found\n",
    "                if critical_review_tags_:\n",
    "                    # Take the first found element (if there are multiple) and directly extract the text\n",
    "                    helpful_text = critical_review_tags_[0].text.strip()\n",
    "                    print(\"Helpful Text:\", helpful_text)  # Debugging line\n",
    "                    \n",
    "                    # Check if the text starts with a digit and extract the first contiguous digit sequence\n",
    "                    match = re.match(r'\\d+', helpful_text)\n",
    "                    if match:\n",
    "                        helpful_count = int(match.group())\n",
    "                    else:\n",
    "                        # If the text doesn't start with a digit, try converting the first word to a number\n",
    "                        helpful_count = w2n.word_to_num(helpful_text.split()[0])\n",
    "                else:\n",
    "                    print(\"Tag not found\")  # Debugging line\n",
    "                    helpful_count = 0\n",
    "\n",
    "                result['Customers_Influenced'] = helpful_count\n",
    "\n",
    "\n",
    "            else:\n",
    "                # Handle the case where there is only one or no matching element\n",
    "                result['Customer_id_Critical_Review'] = 'NaN'\n",
    "                result['Customer_Name'] = 'NaN'\n",
    "                result['Customer_Review_Comment'] = 'NaN'\n",
    "                result['Customer_Review_Title'] = 'NaN'\n",
    "                result['Customers_Influenced'] = 0\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping extra parameters for {url}: {e}\")\n",
    "        traceback.print_exc()\n",
    "    return {}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
