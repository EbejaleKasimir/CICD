[2023-07-26T10:15:23.262+0000] {processor.py:153} INFO - Started process (PID=475) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:15:23.264+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:15:23.286+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:15:23.286+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:15:24.477+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:15:23.690+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:15:24.585+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:15:25.111+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.864 seconds
[2023-07-26T10:15:55.388+0000] {processor.py:153} INFO - Started process (PID=489) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:15:55.390+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:15:55.391+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:15:55.391+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:15:55.874+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:15:55.862+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:15:55.876+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:15:56.837+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.456 seconds
[2023-07-26T10:16:26.945+0000] {processor.py:153} INFO - Started process (PID=516) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:16:26.947+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:16:26.951+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:16:26.949+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:16:27.006+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:16:26.995+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:16:27.008+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:16:27.256+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.317 seconds
[2023-07-26T10:16:57.516+0000] {processor.py:153} INFO - Started process (PID=542) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:16:57.518+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:16:57.520+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:16:57.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:16:57.588+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:16:57.578+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:16:57.590+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:16:58.069+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.560 seconds
[2023-07-26T10:17:28.457+0000] {processor.py:153} INFO - Started process (PID=568) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:17:28.460+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:17:28.462+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:17:28.462+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:17:28.520+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:17:28.509+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:17:28.521+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:17:28.913+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.463 seconds
[2023-07-26T10:17:59.270+0000] {processor.py:153} INFO - Started process (PID=582) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:17:59.271+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:17:59.273+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:17:59.273+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:17:59.329+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:17:59.318+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:17:59.331+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:18:00.219+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.954 seconds
[2023-07-26T10:18:30.357+0000] {processor.py:153} INFO - Started process (PID=609) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:18:30.359+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:18:30.361+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:18:30.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:18:30.415+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:18:30.403+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:18:30.416+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:18:30.646+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.294 seconds
[2023-07-26T10:19:01.042+0000] {processor.py:153} INFO - Started process (PID=635) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:19:08.697+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:19:08.703+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:19:08.702+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:19:08.812+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:19:08.798+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:19:08.813+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:19:10.455+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 9.420 seconds
[2023-07-26T10:19:40.884+0000] {processor.py:153} INFO - Started process (PID=658) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:19:40.886+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:19:40.887+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:19:40.887+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:19:40.951+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:19:40.938+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:19:40.952+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:19:41.815+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.939 seconds
[2023-07-26T10:20:12.330+0000] {processor.py:153} INFO - Started process (PID=675) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:20:12.332+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:20:12.334+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:20:12.333+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:20:12.381+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:20:12.373+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:20:12.382+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:20:12.610+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.285 seconds
[2023-07-26T10:20:43.147+0000] {processor.py:153} INFO - Started process (PID=703) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:20:43.149+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:20:43.150+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:20:43.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:20:43.224+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:20:43.209+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:20:43.226+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:20:43.436+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.295 seconds
[2023-07-26T10:21:14.318+0000] {processor.py:153} INFO - Started process (PID=728) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:21:14.335+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:21:14.337+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:21:14.337+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:21:14.423+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:21:14.400+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:21:14.434+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:21:14.845+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.535 seconds
[2023-07-26T10:21:44.905+0000] {processor.py:153} INFO - Started process (PID=742) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:21:44.907+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:21:44.909+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:21:44.908+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:21:44.981+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:21:44.966+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:21:44.982+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:21:45.354+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.456 seconds
[2023-07-26T10:22:15.597+0000] {processor.py:153} INFO - Started process (PID=768) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:22:15.599+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:22:15.602+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:22:15.602+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:22:15.655+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:22:15.646+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:22:15.656+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:22:16.178+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.593 seconds
[2023-07-26T10:22:46.922+0000] {processor.py:153} INFO - Started process (PID=795) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:22:46.924+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:22:46.926+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:22:46.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:22:46.984+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:22:46.971+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:22:46.985+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:22:47.591+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.678 seconds
[2023-07-26T10:23:18.057+0000] {processor.py:153} INFO - Started process (PID=822) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:23:18.059+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:23:18.061+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:23:18.061+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:23:18.137+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:23:18.121+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:23:18.138+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:23:18.683+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.631 seconds
[2023-07-26T10:23:48.980+0000] {processor.py:153} INFO - Started process (PID=849) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:23:48.983+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:23:48.985+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:23:48.985+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:23:49.042+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:23:49.031+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:23:49.043+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:23:49.141+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.170 seconds
[2023-07-26T10:24:19.297+0000] {processor.py:153} INFO - Started process (PID=876) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:24:19.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:24:19.301+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:19.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:19.373+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:19.360+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 17, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:24:19.375+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:19.549+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.257 seconds
[2023-07-26T10:24:39.852+0000] {processor.py:153} INFO - Started process (PID=890) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:24:39.854+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:24:39.857+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:39.857+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:40.002+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:39.987+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 19, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:24:40.004+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:40.377+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.532 seconds
[2023-07-26T10:24:46.613+0000] {processor.py:153} INFO - Started process (PID=903) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:24:46.617+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:24:46.619+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:46.619+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:46.704+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:46.694+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 19, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:24:46.705+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:46.875+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.269 seconds
[2023-07-26T10:24:49.685+0000] {processor.py:153} INFO - Started process (PID=904) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:24:49.687+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:24:49.689+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:49.689+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:49.778+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:49.767+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 22, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:24:49.780+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:49.902+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.222 seconds
[2023-07-26T10:24:52.777+0000] {processor.py:153} INFO - Started process (PID=905) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:24:52.780+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:24:52.782+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:52.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:52.883+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:52.870+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 22, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:24:52.884+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:53.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.238 seconds
[2023-07-26T10:24:56.110+0000] {processor.py:153} INFO - Started process (PID=906) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:24:56.112+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:24:56.113+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:56.113+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:56.255+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:24:56.241+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 21, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:24:56.256+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:24:56.469+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.363 seconds
[2023-07-26T10:25:06.327+0000] {processor.py:153} INFO - Started process (PID=919) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:25:06.329+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:25:06.330+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:06.330+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:06.423+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:06.412+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 21, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:25:06.424+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:06.513+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.193 seconds
[2023-07-26T10:25:18.891+0000] {processor.py:153} INFO - Started process (PID=933) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:25:18.893+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:25:18.896+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:18.895+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:19.024+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:19.010+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 21, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:25:19.026+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:19.310+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.427 seconds
[2023-07-26T10:25:28.786+0000] {processor.py:153} INFO - Started process (PID=934) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:25:28.789+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:25:28.791+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:28.791+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:28.889+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:28.873+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 40, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:25:28.891+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:29.031+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.252 seconds
[2023-07-26T10:25:35.901+0000] {processor.py:153} INFO - Started process (PID=948) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:25:35.903+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:25:35.905+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:35.905+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:36.017+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:36.001+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 40, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:25:36.018+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:36.355+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.466 seconds
[2023-07-26T10:25:42.882+0000] {processor.py:153} INFO - Started process (PID=950) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:25:42.885+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:25:42.887+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:42.887+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:43.108+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:25:43.099+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 39, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:25:43.109+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:25:43.424+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.551 seconds
[2023-07-26T10:26:13.802+0000] {processor.py:153} INFO - Started process (PID=977) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:26:13.805+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:26:13.808+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:26:13.808+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:26:13.980+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:26:13.968+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 39, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:26:13.983+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:26:14.142+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.347 seconds
[2023-07-26T10:26:44.691+0000] {processor.py:153} INFO - Started process (PID=1003) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:26:44.719+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:26:44.722+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:26:44.722+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:26:44.823+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:26:44.807+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 39, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:26:44.824+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:26:45.076+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.393 seconds
[2023-07-26T10:26:59.236+0000] {processor.py:153} INFO - Started process (PID=1017) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:26:59.239+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:26:59.241+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:26:59.241+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:26:59.454+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:26:59.333+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:26:59.455+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:26:59.637+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.411 seconds
[2023-07-26T10:27:09.896+0000] {processor.py:153} INFO - Started process (PID=1028) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:27:09.898+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:27:09.900+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:27:09.899+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:27:10.300+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:27:10.243+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:27:10.302+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:27:10.727+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.839 seconds
[2023-07-26T10:27:41.213+0000] {processor.py:153} INFO - Started process (PID=1045) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:27:41.215+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:27:41.217+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:27:41.217+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:27:41.279+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:27:41.268+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:27:41.280+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:27:41.451+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.246 seconds
[2023-07-26T10:28:11.861+0000] {processor.py:153} INFO - Started process (PID=1071) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:28:11.863+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:28:11.866+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:28:11.865+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:28:11.939+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:28:11.919+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:28:11.943+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:28:12.069+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.216 seconds
[2023-07-26T10:28:42.496+0000] {processor.py:153} INFO - Started process (PID=1097) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:28:42.498+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:28:42.500+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:28:42.499+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:28:42.551+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:28:42.543+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:28:42.553+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:28:42.642+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.151 seconds
[2023-07-26T10:29:12.887+0000] {processor.py:153} INFO - Started process (PID=1124) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:29:12.911+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:29:12.914+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:29:12.913+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:29:13.040+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:29:13.014+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:29:13.042+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:29:13.306+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.439 seconds
[2023-07-26T10:29:43.182+0000] {processor.py:153} INFO - Started process (PID=1150) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:29:43.186+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:29:43.190+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:29:43.189+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:29:43.311+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:29:43.287+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 59, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:29:43.314+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:29:43.544+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.368 seconds
[2023-07-26T10:30:14.049+0000] {processor.py:153} INFO - Started process (PID=1177) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:30:14.052+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:30:14.055+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:30:14.054+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:30:14.128+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:30:14.116+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 59, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:30:14.129+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:30:14.486+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.454 seconds
[2023-07-26T10:30:45.083+0000] {processor.py:153} INFO - Started process (PID=1204) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:30:45.085+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:30:45.087+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:30:45.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:30:45.158+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:30:45.145+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 59, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:30:45.160+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:30:45.346+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.272 seconds
[2023-07-26T10:31:15.923+0000] {processor.py:153} INFO - Started process (PID=1228) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:31:15.926+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:31:15.928+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:31:15.928+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:31:16.230+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:31:16.195+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 59, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:31:16.233+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:31:16.613+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.697 seconds
[2023-07-26T10:31:49.738+0000] {processor.py:153} INFO - Started process (PID=1244) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:31:49.864+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:31:50.040+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:31:50.040+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:31:52.178+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:31:51.884+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 59, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:31:52.223+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:31:52.694+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.975 seconds
[2023-07-26T10:32:23.009+0000] {processor.py:153} INFO - Started process (PID=1270) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:32:23.011+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:32:23.013+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:32:23.012+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:32:23.067+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:32:23.057+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 59, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:32:23.068+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:32:23.445+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.443 seconds
[2023-07-26T10:32:53.841+0000] {processor.py:153} INFO - Started process (PID=1284) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:32:53.845+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:32:53.853+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:32:53.852+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:32:54.092+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:32:54.077+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 59, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 411, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 891, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 998, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1056, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2327, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-07-26T10:32:54.094+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:32:54.507+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.676 seconds
[2023-07-26T10:33:23.217+0000] {processor.py:153} INFO - Started process (PID=1311) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:33:23.220+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:33:23.223+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:33:23.222+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:33:38.238+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:33:38.224+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 3, in <module>
    import load_to_db
ModuleNotFoundError: No module named 'load_to_db'
[2023-07-26T10:33:38.250+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:33:38.376+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 15.172 seconds
[2023-07-26T10:34:08.900+0000] {processor.py:153} INFO - Started process (PID=1353) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:34:08.903+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:34:08.905+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:34:08.905+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:34:09.776+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:34:09.761+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 3, in <module>
    import load_to_db
ModuleNotFoundError: No module named 'load_to_db'
[2023-07-26T10:34:09.781+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:34:10.021+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.128 seconds
[2023-07-26T10:34:40.818+0000] {processor.py:153} INFO - Started process (PID=1377) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:34:40.820+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:34:40.824+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:34:40.823+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:34:41.694+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:34:41.679+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 3, in <module>
    import load_to_db
ModuleNotFoundError: No module named 'load_to_db'
[2023-07-26T10:34:41.700+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:34:41.824+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.013 seconds
[2023-07-26T10:35:12.492+0000] {processor.py:153} INFO - Started process (PID=1396) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:35:12.494+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:35:12.497+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:12.497+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:35:13.539+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:35:18.944+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:18.944+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:data_engineer_jobs_dag
[2023-07-26T10:35:19.090+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:19.090+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:data_engineer_jobs_dag
[2023-07-26T10:35:19.157+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:19.157+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:data_engineer_jobs_dag
[2023-07-26T10:35:19.159+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:19.158+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:35:19.184+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:19.183+0000] {dag.py:2697} INFO - Creating ORM DAG for data_engineer_jobs_dag
[2023-07-26T10:35:19.208+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:19.208+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:35:19.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.966 seconds
[2023-07-26T10:35:50.051+0000] {processor.py:153} INFO - Started process (PID=1423) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:35:50.053+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:35:50.055+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:50.055+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:35:50.679+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:35:50.793+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:50.792+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:35:50.860+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:35:50.860+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:35:51.149+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.103 seconds
[2023-07-26T10:36:21.282+0000] {processor.py:153} INFO - Started process (PID=1450) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:36:21.285+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:36:21.287+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:36:21.286+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:36:21.811+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:36:21.879+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:36:21.878+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:36:21.927+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:36:21.927+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:36:22.081+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.803 seconds
[2023-07-26T10:36:52.566+0000] {processor.py:153} INFO - Started process (PID=1477) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:36:52.568+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:36:52.570+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:36:52.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:36:53.299+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:36:53.383+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:36:53.382+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:36:53.443+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:36:53.443+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:36:53.570+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.012 seconds
[2023-07-26T10:37:23.724+0000] {processor.py:153} INFO - Started process (PID=1502) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:37:23.727+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:37:23.729+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:37:23.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:37:24.533+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:37:24.623+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:37:24.622+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:37:24.724+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:37:24.723+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:37:24.926+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.210 seconds
[2023-07-26T10:37:55.420+0000] {processor.py:153} INFO - Started process (PID=1521) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:37:55.423+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:37:55.425+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:37:55.425+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:37:55.940+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:37:56.013+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:37:56.012+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:37:56.077+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:37:56.077+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:37:56.162+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.750 seconds
[2023-07-26T10:37:58.413+0000] {processor.py:153} INFO - Started process (PID=1532) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:37:58.417+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:37:58.424+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:37:58.424+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:37:59.731+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:37:59.830+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:37:59.830+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:37:59.947+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:37:59.947+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:38:00.169+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.776 seconds
[2023-07-26T10:38:30.672+0000] {processor.py:153} INFO - Started process (PID=1550) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:38:30.675+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:38:30.677+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:38:30.677+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:38:31.534+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:38:31.592+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:38:31.591+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:38:31.636+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:38:31.636+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:38:31.733+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.069 seconds
[2023-07-26T10:38:55.280+0000] {processor.py:153} INFO - Started process (PID=1575) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:38:55.283+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:38:55.285+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:38:55.285+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:38:56.687+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:38:56.775+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:38:56.774+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:38:56.837+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:38:56.837+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:38:57.182+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.913 seconds
[2023-07-26T10:39:01.317+0000] {processor.py:153} INFO - Started process (PID=1580) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:39:01.319+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:39:01.321+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:39:01.320+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:39:24.914+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:39:24.987+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:39:24.986+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:39:25.034+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:39:25.034+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:39:25.263+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 23.955 seconds
[2023-07-26T10:39:55.869+0000] {processor.py:153} INFO - Started process (PID=1622) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:39:55.871+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:39:55.873+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:39:55.872+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:40:01.223+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:40:01.150+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:40:01.231+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:40:01.668+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.806 seconds
[2023-07-26T10:40:32.450+0000] {processor.py:153} INFO - Started process (PID=1648) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:40:32.452+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:40:32.454+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:40:32.454+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:40:36.867+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:40:36.852+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:40:36.874+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:40:36.993+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.551 seconds
[2023-07-26T10:41:07.551+0000] {processor.py:153} INFO - Started process (PID=1676) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:41:07.553+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:41:07.555+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:41:07.555+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:41:12.153+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:41:12.120+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:41:12.169+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:41:12.478+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.934 seconds
[2023-07-26T10:41:43.161+0000] {processor.py:153} INFO - Started process (PID=1704) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:41:43.163+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:41:43.165+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:41:43.164+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:41:47.402+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:41:47.390+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:41:47.408+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:41:47.596+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.440 seconds
[2023-07-26T10:42:18.039+0000] {processor.py:153} INFO - Started process (PID=1730) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:42:18.041+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:42:18.043+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:42:18.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:42:22.589+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:42:22.572+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:42:22.597+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:42:22.752+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.718 seconds
[2023-07-26T10:42:52.823+0000] {processor.py:153} INFO - Started process (PID=1758) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:42:52.825+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:42:52.827+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:42:52.827+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:42:57.060+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:42:57.043+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:42:57.066+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:42:57.220+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.402 seconds
[2023-07-26T10:43:27.640+0000] {processor.py:153} INFO - Started process (PID=1786) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:43:27.642+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:43:27.644+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:43:27.643+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:43:31.380+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:43:31.362+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:43:31.387+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:43:31.544+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.910 seconds
[2023-07-26T10:44:02.236+0000] {processor.py:153} INFO - Started process (PID=1812) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:44:02.239+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:44:02.240+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:44:02.240+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:44:07.205+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:44:07.186+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:44:07.238+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:44:07.591+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.392 seconds
[2023-07-26T10:44:38.027+0000] {processor.py:153} INFO - Started process (PID=1840) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:44:38.029+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:44:38.032+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:44:38.032+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:44:42.351+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:44:42.338+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:44:42.355+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:44:42.434+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.414 seconds
[2023-07-26T10:45:12.993+0000] {processor.py:153} INFO - Started process (PID=1868) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:45:12.995+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:45:12.998+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:45:12.997+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:45:17.568+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:45:17.556+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:45:17.574+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:45:17.659+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.674 seconds
[2023-07-26T10:45:48.088+0000] {processor.py:153} INFO - Started process (PID=1895) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:45:48.089+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:45:48.091+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:45:48.091+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:45:52.322+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:45:52.305+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:45:52.327+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:45:52.837+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.754 seconds
[2023-07-26T10:46:23.309+0000] {processor.py:153} INFO - Started process (PID=1923) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:46:23.321+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:46:23.324+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:46:23.323+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:46:27.750+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:46:27.732+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:46:27.758+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:46:27.989+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.691 seconds
[2023-07-26T10:46:58.527+0000] {processor.py:153} INFO - Started process (PID=1950) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:46:58.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:46:58.536+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:46:58.535+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:47:03.318+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:47:03.293+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:47:03.325+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:47:03.477+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.958 seconds
[2023-07-26T10:47:34.053+0000] {processor.py:153} INFO - Started process (PID=1977) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:47:34.055+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:47:34.056+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:47:34.056+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:47:37.830+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:47:37.803+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    load_to_db.load_to_postgres(df)
  File "/opt/airflow/dags/load_to_db.py", line 52, in load_to_postgres
    """, (row['job_id'], row['employer_website'], row['job_employment_type'], row['job_title'], row['job_apply_link'], row['job_description'], row['skillset'], row['job_city'], row['job_country'], row['job_posted_at_date'], row['employer_company_type']))
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "data_engineering_jobs_pkey"
DETAIL:  Key (job_id)=(M67OcC-RP-YAAAAAAAAAAA==) already exists.
[2023-07-26T10:47:37.835+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:47:37.942+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.895 seconds
[2023-07-26T10:48:08.517+0000] {processor.py:153} INFO - Started process (PID=2004) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:48:08.519+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:48:08.520+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:48:08.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:48:18.556+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:48:18.836+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:48:18.834+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:48:18.929+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:48:18.929+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:48:19.421+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 10.911 seconds
[2023-07-26T10:48:49.921+0000] {processor.py:153} INFO - Started process (PID=2039) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:48:49.923+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:48:49.926+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:48:49.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:48:55.303+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:48:55.364+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:48:55.363+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:48:55.420+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:48:55.420+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:48:55.705+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.790 seconds
[2023-07-26T10:49:26.017+0000] {processor.py:153} INFO - Started process (PID=2060) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:49:26.019+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:49:26.021+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:49:26.021+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:49:30.682+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:49:30.771+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:49:30.770+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:49:30.837+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:49:30.836+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:49:31.044+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.032 seconds
[2023-07-26T10:50:01.483+0000] {processor.py:153} INFO - Started process (PID=2100) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:50:01.489+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:50:01.492+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:50:01.492+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:50:06.285+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:50:06.364+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:50:06.363+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:50:06.417+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:50:06.416+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:50:06.553+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.080 seconds
[2023-07-26T10:50:36.712+0000] {processor.py:153} INFO - Started process (PID=2127) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:50:36.714+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:50:36.718+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:50:36.717+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:50:40.909+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:50:40.973+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:50:40.972+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:50:41.025+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:50:41.025+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:50:41.131+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.426 seconds
[2023-07-26T10:51:11.596+0000] {processor.py:153} INFO - Started process (PID=2154) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:51:11.598+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:51:11.600+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:51:11.600+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:51:16.101+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:51:16.199+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:51:16.198+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:51:16.290+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:51:16.290+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:51:16.418+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.837 seconds
[2023-07-26T10:51:46.570+0000] {processor.py:153} INFO - Started process (PID=2180) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:51:46.572+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:51:46.575+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:51:46.574+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:51:51.653+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:51:51.780+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:51:51.779+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:51:51.848+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:51:51.847+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:51:52.009+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.447 seconds
[2023-07-26T10:52:22.768+0000] {processor.py:153} INFO - Started process (PID=2207) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:52:22.771+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:52:22.773+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:52:22.773+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:52:27.761+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:52:27.825+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:52:27.824+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:52:27.874+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:52:27.874+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:52:28.129+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.373 seconds
[2023-07-26T10:52:58.257+0000] {processor.py:153} INFO - Started process (PID=2235) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:52:58.259+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:52:58.261+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:52:58.260+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:53:02.753+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:53:02.845+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:53:02.843+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:53:02.946+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:53:02.945+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:53:03.164+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.912 seconds
[2023-07-26T10:53:33.948+0000] {processor.py:153} INFO - Started process (PID=2263) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:53:33.951+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:53:33.954+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:53:33.953+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:53:40.312+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:53:40.370+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:53:40.369+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:53:40.431+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:53:40.431+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:53:41.233+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.291 seconds
[2023-07-26T10:54:11.529+0000] {processor.py:153} INFO - Started process (PID=2291) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:54:11.532+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:54:11.534+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:54:11.534+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:54:16.271+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:54:16.349+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:54:16.348+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:54:16.427+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:54:16.427+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:54:16.905+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.394 seconds
[2023-07-26T10:54:47.152+0000] {processor.py:153} INFO - Started process (PID=2318) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:54:47.155+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:54:47.157+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:54:47.157+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:54:52.629+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:54:52.694+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:54:52.694+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:54:52.782+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:54:52.782+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:54:52.948+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.808 seconds
[2023-07-26T10:55:23.078+0000] {processor.py:153} INFO - Started process (PID=2345) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:55:23.080+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:55:23.083+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:55:23.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:55:27.449+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:55:27.521+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:55:27.520+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:55:27.574+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:55:27.573+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:55:27.698+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.625 seconds
[2023-07-26T10:55:58.072+0000] {processor.py:153} INFO - Started process (PID=2372) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:55:58.073+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:55:58.075+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:55:58.075+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:56:03.566+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:56:03.735+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:56:03.734+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:56:03.805+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:56:03.804+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:56:04.234+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.168 seconds
[2023-07-26T10:56:34.735+0000] {processor.py:153} INFO - Started process (PID=2412) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:56:34.737+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:56:34.739+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:56:34.739+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:56:38.979+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:56:39.067+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:56:39.065+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:56:39.140+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:56:39.140+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:56:39.285+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.568 seconds
[2023-07-26T10:57:09.368+0000] {processor.py:153} INFO - Started process (PID=2439) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:57:09.369+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:57:09.372+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:57:09.371+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:57:14.347+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:57:14.479+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:57:14.477+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:57:14.553+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:57:14.553+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:57:14.771+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.411 seconds
[2023-07-26T10:57:45.143+0000] {processor.py:153} INFO - Started process (PID=2468) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:57:45.146+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:57:45.149+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:57:45.149+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:57:48.803+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:57:48.869+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:57:48.868+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:57:48.921+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:57:48.920+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:57:49.075+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.940 seconds
[2023-07-26T10:58:19.497+0000] {processor.py:153} INFO - Started process (PID=2497) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:58:19.499+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:58:19.502+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:58:19.501+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:58:23.895+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:58:23.994+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:58:23.993+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:58:24.047+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:58:24.047+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:58:24.176+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.686 seconds
[2023-07-26T10:58:54.372+0000] {processor.py:153} INFO - Started process (PID=2532) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:58:54.375+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:58:54.377+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:58:54.376+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:58:59.177+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:58:59.237+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:58:59.237+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:58:59.297+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:58:59.297+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:58:59.807+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.441 seconds
[2023-07-26T10:59:30.214+0000] {processor.py:153} INFO - Started process (PID=2565) to work on /opt/airflow/dags/load_data.py
[2023-07-26T10:59:30.216+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T10:59:30.218+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:59:30.218+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T10:59:34.549+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T10:59:34.619+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:59:34.618+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T10:59:34.669+0000] {logging_mixin.py:137} INFO - [2023-07-26T10:59:34.669+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T10:59:34.852+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.643 seconds
[2023-07-26T11:00:05.357+0000] {processor.py:153} INFO - Started process (PID=2593) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:00:05.359+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:00:05.361+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:00:05.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:00:09.625+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:00:09.697+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:00:09.696+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:00:09.759+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:00:09.759+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:00:09.988+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.638 seconds
[2023-07-26T11:00:41.022+0000] {processor.py:153} INFO - Started process (PID=2620) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:00:41.024+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:00:41.026+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:00:41.026+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:00:45.010+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:00:45.100+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:00:45.099+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:00:45.164+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:00:45.164+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:00:45.298+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.280 seconds
[2023-07-26T11:01:15.741+0000] {processor.py:153} INFO - Started process (PID=2648) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:01:15.744+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:01:15.746+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:01:15.745+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:01:19.889+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:01:19.963+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:01:19.962+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:01:20.030+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:01:20.029+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:01:20.131+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.394 seconds
[2023-07-26T11:01:50.487+0000] {processor.py:153} INFO - Started process (PID=2678) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:01:50.489+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:01:50.491+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:01:50.491+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:01:54.814+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:01:54.878+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:01:54.877+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:01:54.944+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:01:54.944+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:01:55.083+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.601 seconds
[2023-07-26T11:02:25.464+0000] {processor.py:153} INFO - Started process (PID=2718) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:02:25.466+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:02:25.469+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:02:25.468+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:02:29.684+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:02:29.850+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:02:29.849+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:02:29.941+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:02:29.941+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:02:30.098+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.644 seconds
[2023-07-26T11:03:00.478+0000] {processor.py:153} INFO - Started process (PID=2745) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:03:00.480+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:03:00.481+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:03:00.481+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:03:05.173+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:03:05.428+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:03:05.415+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:03:05.584+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:03:05.583+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:03:05.732+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.260 seconds
[2023-07-26T11:03:36.150+0000] {processor.py:153} INFO - Started process (PID=2772) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:03:36.153+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:03:36.155+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:03:36.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:03:42.874+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:03:42.941+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:03:42.940+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:03:43.000+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:03:42.999+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:03:43.232+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.089 seconds
[2023-07-26T11:04:13.645+0000] {processor.py:153} INFO - Started process (PID=2808) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:04:13.647+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:04:13.649+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:04:13.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:04:17.830+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:04:17.885+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:04:17.884+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:04:17.944+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:04:17.944+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:04:18.221+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.581 seconds
[2023-07-26T11:04:48.655+0000] {processor.py:153} INFO - Started process (PID=2839) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:04:48.658+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:04:48.660+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:04:48.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:04:53.355+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:04:53.413+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:04:53.412+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:04:53.457+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:04:53.457+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:04:53.533+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.883 seconds
[2023-07-26T11:05:23.944+0000] {processor.py:153} INFO - Started process (PID=2868) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:05:23.946+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:05:23.949+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:05:23.949+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:05:28.204+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:05:28.257+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:05:28.256+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:05:28.299+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:05:28.299+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:05:28.680+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.743 seconds
[2023-07-26T11:05:58.877+0000] {processor.py:153} INFO - Started process (PID=2897) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:05:58.879+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:05:58.881+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:05:58.880+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:06:03.036+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:06:03.124+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:06:03.123+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:06:03.227+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:06:03.227+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:06:03.435+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.564 seconds
[2023-07-26T11:06:33.692+0000] {processor.py:153} INFO - Started process (PID=2924) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:06:33.694+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:06:33.696+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:06:33.695+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:06:38.104+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:06:38.175+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:06:38.174+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:06:38.246+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:06:38.245+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:06:38.368+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.681 seconds
[2023-07-26T11:07:08.480+0000] {processor.py:153} INFO - Started process (PID=2963) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:07:08.484+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:07:08.488+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:07:08.488+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:07:13.202+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:07:13.310+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:07:13.308+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:07:13.398+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:07:13.397+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:07:13.571+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.101 seconds
[2023-07-26T11:07:44.054+0000] {processor.py:153} INFO - Started process (PID=2991) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:07:44.057+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:07:44.062+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:07:44.061+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:07:48.649+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:07:48.704+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:07:48.704+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:07:48.746+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:07:48.746+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:07:49.081+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.042 seconds
[2023-07-26T11:08:19.384+0000] {processor.py:153} INFO - Started process (PID=3018) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:08:19.389+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:08:19.392+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:08:19.392+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:08:24.927+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:08:24.982+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:08:24.981+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:08:25.050+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:08:25.050+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:08:25.306+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.945 seconds
[2023-07-26T11:08:55.707+0000] {processor.py:153} INFO - Started process (PID=3050) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:08:55.710+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:08:55.711+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:08:55.711+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:09:01.248+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:09:01.307+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:09:01.306+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:09:01.383+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:09:01.383+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:09:01.695+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.993 seconds
[2023-07-26T11:09:32.529+0000] {processor.py:153} INFO - Started process (PID=3079) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:09:32.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:09:32.533+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:09:32.533+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:09:36.925+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:09:36.976+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:09:36.974+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:09:37.019+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:09:37.019+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:09:37.301+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.777 seconds
[2023-07-26T11:10:07.709+0000] {processor.py:153} INFO - Started process (PID=3106) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:10:07.711+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:10:07.712+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:10:07.712+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:10:12.523+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:10:12.746+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:10:12.745+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:10:12.840+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:10:12.839+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:10:13.308+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.605 seconds
[2023-07-26T11:10:44.132+0000] {processor.py:153} INFO - Started process (PID=3135) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:10:44.135+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:10:44.137+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:10:44.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:10:48.548+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:10:48.628+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:10:48.627+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:10:48.686+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:10:48.686+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:10:48.804+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.681 seconds
[2023-07-26T11:11:19.209+0000] {processor.py:153} INFO - Started process (PID=3169) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:11:19.211+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:11:19.213+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:11:19.213+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:11:23.701+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:11:23.769+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:11:23.768+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:11:23.815+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:11:23.815+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:11:24.291+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.089 seconds
[2023-07-26T11:11:54.701+0000] {processor.py:153} INFO - Started process (PID=3200) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:11:54.703+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:11:54.705+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:11:54.705+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:12:00.326+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:12:00.480+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:12:00.478+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:12:00.568+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:12:00.568+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:12:00.749+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.056 seconds
[2023-07-26T11:12:31.134+0000] {processor.py:153} INFO - Started process (PID=3226) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:12:31.136+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:12:31.139+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:12:31.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:12:35.887+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:12:35.938+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:12:35.937+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:12:36.000+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:12:35.999+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:12:36.381+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.253 seconds
[2023-07-26T11:13:06.803+0000] {processor.py:153} INFO - Started process (PID=3255) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:13:06.807+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:13:06.809+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:13:06.809+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:13:11.090+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:13:11.158+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:13:11.157+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:13:11.224+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:13:11.224+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:13:11.534+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.742 seconds
[2023-07-26T11:13:41.956+0000] {processor.py:153} INFO - Started process (PID=3291) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:13:41.958+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:13:41.960+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:13:41.960+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:13:46.852+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:13:46.906+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:13:46.905+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:13:46.949+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:13:46.948+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:13:47.110+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.163 seconds
[2023-07-26T11:14:17.519+0000] {processor.py:153} INFO - Started process (PID=3321) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:14:17.521+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:14:17.523+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:14:17.523+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:14:21.898+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:14:21.976+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:14:21.975+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:14:22.024+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:14:22.024+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:14:22.285+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.771 seconds
[2023-07-26T11:14:52.678+0000] {processor.py:153} INFO - Started process (PID=3349) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:14:52.679+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:14:52.682+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:14:52.681+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:14:57.158+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:14:57.216+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:14:57.215+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:14:57.262+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:14:57.261+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:14:57.761+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.091 seconds
[2023-07-26T11:15:28.146+0000] {processor.py:153} INFO - Started process (PID=3378) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:15:28.148+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:15:28.150+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:15:28.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:15:32.738+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:15:32.839+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:15:32.837+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:15:32.891+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:15:32.891+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:15:33.105+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.965 seconds
[2023-07-26T11:16:03.567+0000] {processor.py:153} INFO - Started process (PID=3418) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:16:03.569+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:16:03.571+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:16:03.571+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:16:08.564+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:16:08.625+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:16:08.623+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:16:08.679+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:16:08.679+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:16:08.802+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.243 seconds
[2023-07-26T11:16:39.227+0000] {processor.py:153} INFO - Started process (PID=3446) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:16:39.229+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:16:39.231+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:16:39.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:16:43.650+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:16:43.707+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:16:43.707+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:16:43.777+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:16:43.777+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:16:43.853+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.632 seconds
[2023-07-26T11:17:14.319+0000] {processor.py:153} INFO - Started process (PID=3476) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:17:14.325+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:17:14.329+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:17:14.328+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:17:19.284+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:17:19.364+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:17:19.362+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:17:19.427+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:17:19.427+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:17:19.582+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.273 seconds
[2023-07-26T11:17:49.996+0000] {processor.py:153} INFO - Started process (PID=3511) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:17:49.999+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:17:50.000+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:17:50.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:17:54.463+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:17:54.533+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:17:54.532+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:17:54.577+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:17:54.577+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:17:54.787+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.799 seconds
[2023-07-26T11:18:25.144+0000] {processor.py:153} INFO - Started process (PID=3543) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:18:25.146+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:18:25.148+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:18:25.148+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:18:28.829+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:18:28.894+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:18:28.893+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:18:28.946+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:18:28.946+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:18:29.156+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.019 seconds
[2023-07-26T11:18:59.533+0000] {processor.py:153} INFO - Started process (PID=3573) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:18:59.536+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:18:59.538+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:18:59.537+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:19:05.089+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:19:05.197+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:19:05.196+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:19:05.261+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:19:05.261+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:19:05.359+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.835 seconds
[2023-07-26T11:19:35.786+0000] {processor.py:153} INFO - Started process (PID=3601) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:19:35.788+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:19:35.790+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:19:35.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:19:40.512+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:19:40.571+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:19:40.570+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:19:40.626+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:19:40.626+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:19:41.050+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.272 seconds
[2023-07-26T11:20:11.465+0000] {processor.py:153} INFO - Started process (PID=3629) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:20:11.498+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:20:11.500+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:20:11.499+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:20:16.084+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:20:16.273+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:20:16.271+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:20:16.383+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:20:16.383+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:20:16.569+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.111 seconds
[2023-07-26T11:20:47.169+0000] {processor.py:153} INFO - Started process (PID=3667) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:20:47.191+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:20:47.198+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:20:47.197+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:20:52.492+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:20:52.557+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:20:52.556+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:20:52.619+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:20:52.618+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:20:53.050+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.889 seconds
[2023-07-26T11:21:23.519+0000] {processor.py:153} INFO - Started process (PID=3696) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:21:23.521+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:21:23.523+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:21:23.523+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:21:27.865+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:21:27.929+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:21:27.928+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:21:27.984+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:21:27.984+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:21:28.098+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.585 seconds
[2023-07-26T11:21:58.475+0000] {processor.py:153} INFO - Started process (PID=3723) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:21:58.478+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:21:58.480+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:21:58.479+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:22:03.183+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:22:03.314+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:22:03.313+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:22:03.388+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:22:03.387+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:22:03.739+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.270 seconds
[2023-07-26T11:22:34.233+0000] {processor.py:153} INFO - Started process (PID=3751) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:22:34.235+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:22:34.238+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:22:34.237+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:22:38.286+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:22:38.351+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:22:38.349+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:22:38.407+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:22:38.406+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:22:38.576+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.354 seconds
[2023-07-26T11:23:09.019+0000] {processor.py:153} INFO - Started process (PID=3778) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:23:09.021+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:23:09.024+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:23:09.023+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:23:14.271+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:23:14.356+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:23:14.355+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:23:14.431+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:23:14.431+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:23:14.605+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.596 seconds
[2023-07-26T11:23:44.922+0000] {processor.py:153} INFO - Started process (PID=3805) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:23:44.924+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:23:44.926+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:23:44.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:23:49.793+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:23:50.002+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:23:50.001+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:23:50.141+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:23:50.141+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:23:50.273+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.356 seconds
[2023-07-26T11:24:21.065+0000] {processor.py:153} INFO - Started process (PID=3832) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:24:21.068+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:24:21.070+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:24:21.069+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:24:25.899+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:24:26.049+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:24:26.036+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:24:26.194+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:24:26.194+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:24:26.300+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.242 seconds
[2023-07-26T11:24:56.437+0000] {processor.py:153} INFO - Started process (PID=3860) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:24:56.439+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:24:56.441+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:24:56.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:25:01.239+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:25:01.384+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:25:01.379+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:25:01.716+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:25:01.715+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:25:02.253+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.830 seconds
[2023-07-26T11:25:32.486+0000] {processor.py:153} INFO - Started process (PID=3889) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:25:32.488+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:25:32.490+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:25:32.490+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:25:37.242+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:25:37.316+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:25:37.315+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:25:37.395+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:25:37.395+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:25:37.555+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.077 seconds
[2023-07-26T11:26:07.704+0000] {processor.py:153} INFO - Started process (PID=3924) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:26:07.706+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:26:07.709+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:26:07.708+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:26:12.382+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:26:12.477+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:26:12.476+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:26:12.554+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:26:12.554+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:26:12.840+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.146 seconds
[2023-07-26T11:26:43.632+0000] {processor.py:153} INFO - Started process (PID=3957) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:26:43.636+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:26:43.644+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:26:43.644+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:26:48.216+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:26:48.277+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:26:48.276+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:26:48.327+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:26:48.326+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:26:48.577+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.961 seconds
[2023-07-26T11:27:18.726+0000] {processor.py:153} INFO - Started process (PID=3984) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:27:18.729+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:27:18.731+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:27:18.730+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:27:23.595+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:27:23.806+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:27:23.803+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:27:24.109+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:27:24.108+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:27:24.439+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.722 seconds
[2023-07-26T11:27:54.882+0000] {processor.py:153} INFO - Started process (PID=4010) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:27:54.884+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:27:54.887+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:27:54.886+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:27:59.650+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:27:59.704+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:27:59.703+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:27:59.746+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:27:59.746+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:28:00.219+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.356 seconds
[2023-07-26T11:28:30.769+0000] {processor.py:153} INFO - Started process (PID=4038) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:28:30.772+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:28:30.774+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:28:30.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:28:38.044+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:28:38.117+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:28:38.116+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:28:38.176+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:28:38.176+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:28:38.308+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.547 seconds
[2023-07-26T11:29:08.530+0000] {processor.py:153} INFO - Started process (PID=4077) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:29:08.532+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:29:08.534+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:29:08.534+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:29:14.414+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:29:14.584+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:29:14.583+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:29:14.697+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:29:14.697+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:29:15.025+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.514 seconds
[2023-07-26T11:29:45.901+0000] {processor.py:153} INFO - Started process (PID=4106) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:29:45.915+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:29:45.931+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:29:45.931+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:29:50.760+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:29:50.886+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:29:50.884+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:29:50.960+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:29:50.960+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:29:51.574+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.680 seconds
[2023-07-26T11:30:21.985+0000] {processor.py:153} INFO - Started process (PID=4124) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:30:22.066+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:30:22.070+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:30:22.070+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:30:26.445+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:30:26.532+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:30:26.531+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:30:26.605+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:30:26.605+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:30:26.840+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.866 seconds
[2023-07-26T11:30:57.334+0000] {processor.py:153} INFO - Started process (PID=4160) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:30:57.336+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:30:57.338+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:30:57.338+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:31:03.764+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:31:03.859+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:31:03.857+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:31:03.959+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:31:03.956+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:31:04.330+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.005 seconds
[2023-07-26T11:31:34.613+0000] {processor.py:153} INFO - Started process (PID=4187) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:31:34.615+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:31:34.618+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:31:34.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:31:39.178+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:31:39.262+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:31:39.261+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:31:39.338+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:31:39.338+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:31:39.509+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.901 seconds
[2023-07-26T11:32:10.232+0000] {processor.py:153} INFO - Started process (PID=4213) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:32:10.235+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:32:10.239+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:32:10.238+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:32:14.552+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:32:14.638+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:32:14.637+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:32:14.716+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:32:14.716+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:32:15.168+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.944 seconds
[2023-07-26T11:32:45.652+0000] {processor.py:153} INFO - Started process (PID=4245) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:32:45.655+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:32:45.657+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:32:45.657+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:32:50.676+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:32:50.771+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:32:50.770+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:32:50.817+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:32:50.816+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:32:50.967+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.322 seconds
[2023-07-26T11:33:21.305+0000] {processor.py:153} INFO - Started process (PID=4269) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:33:21.307+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:33:21.309+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:33:21.309+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:33:27.087+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:33:27.162+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:33:27.161+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:33:27.247+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:33:27.247+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:33:27.368+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.069 seconds
[2023-07-26T11:33:58.123+0000] {processor.py:153} INFO - Started process (PID=4300) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:33:58.125+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:33:58.126+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:33:58.126+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:34:02.868+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:34:02.935+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:34:02.934+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:34:03.002+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:34:03.002+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:34:03.173+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.058 seconds
[2023-07-26T11:34:33.431+0000] {processor.py:153} INFO - Started process (PID=4327) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:34:33.433+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:34:33.436+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:34:33.436+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:34:37.855+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:34:37.962+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:34:37.961+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:34:38.019+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:34:38.019+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:34:38.293+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.872 seconds
[2023-07-26T11:35:09.007+0000] {processor.py:153} INFO - Started process (PID=4364) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:35:09.041+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:35:09.044+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:35:09.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:35:14.479+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:35:14.548+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:35:14.547+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:35:14.610+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:35:14.609+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:35:14.855+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.854 seconds
[2023-07-26T11:35:45.591+0000] {processor.py:153} INFO - Started process (PID=4394) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:35:45.593+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:35:45.594+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:35:45.594+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:35:49.993+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:35:50.202+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:35:50.201+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:35:50.346+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:35:50.345+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:35:50.772+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.187 seconds
[2023-07-26T11:36:21.224+0000] {processor.py:153} INFO - Started process (PID=4424) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:36:21.226+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:36:21.228+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:36:21.228+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:36:25.604+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:36:25.671+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:36:25.670+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:36:25.784+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:36:25.784+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:36:26.055+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.838 seconds
[2023-07-26T11:36:56.467+0000] {processor.py:153} INFO - Started process (PID=4452) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:36:56.470+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:36:56.474+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:36:56.473+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:37:00.140+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:37:00.209+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:37:00.207+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:37:00.269+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:37:00.269+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:37:00.595+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.141 seconds
[2023-07-26T11:37:31.237+0000] {processor.py:153} INFO - Started process (PID=4489) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:37:31.239+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:37:31.242+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:37:31.242+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:37:38.659+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:37:38.725+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:37:38.724+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:37:38.779+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:37:38.779+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:37:40.056+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.827 seconds
[2023-07-26T11:38:10.744+0000] {processor.py:153} INFO - Started process (PID=4507) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:38:10.747+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:38:10.749+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:38:10.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:38:15.271+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:38:15.349+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:38:15.347+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:38:15.438+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:38:15.438+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:38:15.797+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.064 seconds
[2023-07-26T11:38:46.254+0000] {processor.py:153} INFO - Started process (PID=4534) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:38:46.256+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:38:46.258+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:38:46.258+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:38:57.014+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:38:57.066+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:38:57.065+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:38:57.109+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:38:57.109+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:38:57.539+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 11.292 seconds
[2023-07-26T11:39:27.951+0000] {processor.py:153} INFO - Started process (PID=4574) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:39:27.953+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:39:27.955+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:39:27.955+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:39:32.223+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:39:32.279+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:39:32.278+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:39:32.322+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:39:32.322+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:39:32.602+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.658 seconds
[2023-07-26T11:40:03.099+0000] {processor.py:153} INFO - Started process (PID=4602) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:40:03.101+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:40:03.104+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:40:03.104+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:40:32.399+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:40:32.451+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:40:32.451+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:40:32.495+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:40:32.495+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:40:34.564+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 31.474 seconds
[2023-07-26T11:41:05.261+0000] {processor.py:153} INFO - Started process (PID=4638) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:41:05.270+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:41:05.284+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:41:05.283+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:41:11.638+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:41:11.727+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:41:11.726+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:41:11.796+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:41:11.796+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:41:13.720+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.472 seconds
[2023-07-26T11:41:44.310+0000] {processor.py:153} INFO - Started process (PID=4658) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:41:44.314+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:41:44.318+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:41:44.317+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:41:52.405+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:41:52.776+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:41:52.775+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:41:52.870+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:41:52.870+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:41:54.080+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 9.783 seconds
[2023-07-26T11:42:24.697+0000] {processor.py:153} INFO - Started process (PID=4686) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:42:24.700+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:42:24.702+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:42:24.702+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:42:32.076+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:42:32.154+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:42:32.153+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:42:32.200+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:42:32.200+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:42:33.514+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.824 seconds
[2023-07-26T11:43:03.975+0000] {processor.py:153} INFO - Started process (PID=4722) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:43:04.109+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:43:04.112+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:43:04.111+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:43:09.069+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:43:09.140+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:43:09.139+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:43:09.192+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:43:09.192+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:43:09.498+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.531 seconds
[2023-07-26T11:43:39.969+0000] {processor.py:153} INFO - Started process (PID=4754) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:43:39.971+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:43:39.972+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:43:39.972+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:43:44.426+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:43:44.476+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:43:44.475+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:43:44.519+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:43:44.519+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:43:45.120+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.157 seconds
[2023-07-26T11:44:15.282+0000] {processor.py:153} INFO - Started process (PID=4782) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:44:31.678+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:44:31.690+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:44:31.689+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:44:37.014+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:44:37.133+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:44:37.132+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:44:37.231+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:44:37.230+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:44:38.268+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 22.994 seconds
[2023-07-26T11:45:08.435+0000] {processor.py:153} INFO - Started process (PID=4810) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:45:08.438+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:45:08.441+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:45:08.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:45:12.901+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:45:12.971+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:45:12.970+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:45:13.035+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:45:13.035+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:45:13.488+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.063 seconds
[2023-07-26T11:45:43.787+0000] {processor.py:153} INFO - Started process (PID=4837) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:45:43.789+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:45:43.791+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:45:43.791+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:45:47.296+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:45:47.366+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:45:47.365+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:45:47.419+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:45:47.418+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:45:47.607+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.826 seconds
[2023-07-26T11:46:18.729+0000] {processor.py:153} INFO - Started process (PID=4866) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:46:18.731+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:46:18.734+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:46:18.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:46:25.197+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:46:25.275+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:46:25.274+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:46:25.337+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:46:25.336+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:46:25.608+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.885 seconds
[2023-07-26T11:46:56.302+0000] {processor.py:153} INFO - Started process (PID=4894) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:46:56.306+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:46:56.309+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:46:56.308+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:47:01.386+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:47:01.445+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:47:01.444+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:47:01.496+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:47:01.496+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:47:01.825+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.538 seconds
[2023-07-26T11:47:32.195+0000] {processor.py:153} INFO - Started process (PID=4909) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:47:32.344+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:47:32.472+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:47:32.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:47:49.878+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:47:49.955+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:47:49.954+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:47:50.049+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:47:50.049+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:47:51.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 18.899 seconds
[2023-07-26T11:48:21.812+0000] {processor.py:153} INFO - Started process (PID=4936) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:48:21.930+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:48:21.953+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:48:21.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:48:33.655+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:48:33.773+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:48:33.771+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:48:33.861+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:48:33.861+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:48:34.492+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 12.692 seconds
[2023-07-26T11:49:05.135+0000] {processor.py:153} INFO - Started process (PID=4964) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:49:05.138+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:49:05.140+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:49:05.140+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:49:10.683+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:49:10.771+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:49:10.770+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:49:10.865+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:49:10.865+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:49:12.077+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.948 seconds
[2023-07-26T11:49:42.592+0000] {processor.py:153} INFO - Started process (PID=4993) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:49:42.594+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:49:42.596+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:49:42.595+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:49:46.944+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:49:47.012+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:49:47.011+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:49:47.069+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:49:47.068+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:49:47.246+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.661 seconds
[2023-07-26T11:50:17.729+0000] {processor.py:153} INFO - Started process (PID=5028) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:50:17.731+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:50:17.733+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:50:17.733+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:50:22.582+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:50:22.725+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:50:22.724+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:50:22.856+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:50:22.856+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:50:23.102+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.379 seconds
[2023-07-26T11:50:53.703+0000] {processor.py:153} INFO - Started process (PID=5057) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:50:53.716+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:50:53.718+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:50:53.718+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:50:59.284+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:50:59.339+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:50:59.338+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:50:59.387+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:50:59.387+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:50:59.696+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.000 seconds
[2023-07-26T11:51:29.879+0000] {processor.py:153} INFO - Started process (PID=5087) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:51:29.881+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:51:29.884+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:51:29.883+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:51:36.366+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:51:36.417+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:51:36.416+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:51:36.458+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:51:36.457+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:51:36.639+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.768 seconds
[2023-07-26T11:52:07.452+0000] {processor.py:153} INFO - Started process (PID=5114) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:52:07.455+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:52:07.457+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:52:07.457+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:52:12.074+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:52:12.136+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:52:12.135+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:52:12.193+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:52:12.192+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:52:12.311+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.867 seconds
[2023-07-26T11:52:42.788+0000] {processor.py:153} INFO - Started process (PID=5143) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:52:42.794+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:52:42.797+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:52:42.796+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:52:47.927+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:52:48.005+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:52:48.004+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:52:48.073+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:52:48.073+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:52:48.353+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.575 seconds
[2023-07-26T11:53:18.752+0000] {processor.py:153} INFO - Started process (PID=5170) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:53:18.755+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:53:18.758+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:53:18.757+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:53:23.392+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:53:23.515+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:53:23.514+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:53:23.623+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:53:23.623+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:53:23.884+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.143 seconds
[2023-07-26T11:53:54.009+0000] {processor.py:153} INFO - Started process (PID=5196) to work on /opt/airflow/dags/load_data.py
[2023-07-26T11:53:54.012+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T11:53:54.013+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:53:54.013+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T11:53:58.493+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T11:53:58.594+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:53:58.592+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T11:53:58.673+0000] {logging_mixin.py:137} INFO - [2023-07-26T11:53:58.673+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T11:53:58.935+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.931 seconds
[2023-07-26T14:54:18.904+0000] {processor.py:153} INFO - Started process (PID=5211) to work on /opt/airflow/dags/load_data.py
[2023-07-26T14:54:19.540+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T14:54:19.560+0000] {logging_mixin.py:137} INFO - [2023-07-26T14:54:19.560+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T14:54:24.257+0000] {logging_mixin.py:137} INFO - [2023-07-26T14:54:21.947+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db458e950>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e950>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e950>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T14:54:24.259+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T14:54:24.979+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.082 seconds
[2023-07-26T14:54:55.127+0000] {processor.py:153} INFO - Started process (PID=5238) to work on /opt/airflow/dags/load_data.py
[2023-07-26T14:54:55.129+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T14:54:55.131+0000] {logging_mixin.py:137} INFO - [2023-07-26T14:54:55.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T14:54:55.916+0000] {logging_mixin.py:137} INFO - [2023-07-26T14:54:55.902+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db458e950>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e950>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e950>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T14:54:55.918+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T14:54:57.892+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.777 seconds
[2023-07-26T18:46:00.751+0000] {processor.py:153} INFO - Started process (PID=5253) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:46:00.755+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:46:00.757+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:46:00.757+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:46:01.869+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:46:01.855+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db458e9d0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e9d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e9d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:46:02.860+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:46:07.363+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.593 seconds
[2023-07-26T18:46:38.186+0000] {processor.py:153} INFO - Started process (PID=5269) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:46:38.188+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:46:38.190+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:46:38.190+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:46:38.773+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:46:38.760+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db458e990>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e990>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e990>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:46:38.775+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:46:44.498+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.318 seconds
[2023-07-26T18:47:14.692+0000] {processor.py:153} INFO - Started process (PID=5285) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:47:14.693+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:47:14.695+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:47:14.695+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:47:17.071+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:47:17.056+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db458d8d0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458d8d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458d8d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:47:17.813+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:47:21.204+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.519 seconds
[2023-07-26T18:47:51.923+0000] {processor.py:153} INFO - Started process (PID=5300) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:47:52.127+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:47:52.130+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:47:52.129+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:47:52.745+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:47:52.733+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db458d8d0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458d8d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458d8d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:47:52.746+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:47:54.685+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.768 seconds
[2023-07-26T18:48:25.077+0000] {processor.py:153} INFO - Started process (PID=5314) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:48:26.386+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:48:26.408+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:48:26.408+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:48:27.356+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:48:27.342+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6dae4c91d0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6dae4c91d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6dae4c91d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:48:27.358+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:48:28.593+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.534 seconds
[2023-07-26T18:48:59.523+0000] {processor.py:153} INFO - Started process (PID=5329) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:48:59.599+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:48:59.602+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:48:59.602+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:49:00.144+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:49:00.133+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db4dd89d0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db4dd89d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db4dd89d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:49:00.146+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:49:00.763+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.250 seconds
[2023-07-26T18:49:30.960+0000] {processor.py:153} INFO - Started process (PID=5357) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:49:31.011+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:49:31.024+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:49:31.015+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:49:31.870+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:49:31.850+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db4dd8a10>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db4dd8a10>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db4dd8a10>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:49:31.872+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:49:32.842+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.890 seconds
[2023-07-26T18:50:03.446+0000] {processor.py:153} INFO - Started process (PID=5373) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:50:03.660+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:50:03.662+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:50:03.662+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:50:04.284+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:50:04.272+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db4dd8890>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db4dd8890>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db4dd8890>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:50:14.546+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:50:15.133+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 11.695 seconds
[2023-07-26T18:50:45.588+0000] {processor.py:153} INFO - Started process (PID=5400) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:50:45.591+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:50:45.592+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:50:45.592+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:50:46.195+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:50:46.185+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db4dd8a50>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db4dd8a50>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db4dd8a50>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:50:46.198+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:50:46.722+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.139 seconds
[2023-07-26T18:51:17.436+0000] {processor.py:153} INFO - Started process (PID=5415) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:51:23.845+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:51:23.847+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:51:23.847+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:51:24.408+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:51:24.391+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db458e490>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e490>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db458e490>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:51:24.410+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:51:25.596+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.169 seconds
[2023-07-26T18:51:56.031+0000] {processor.py:153} INFO - Started process (PID=5430) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:51:56.033+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:51:56.035+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:51:56.034+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:51:56.620+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:51:56.608+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6dae4c1610>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6dae4c1610>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6dae4c1610>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:52:08.480+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:52:09.477+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 13.452 seconds
[2023-07-26T18:52:39.565+0000] {processor.py:153} INFO - Started process (PID=5457) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:52:39.927+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:52:39.934+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:52:39.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:52:45.927+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:52:45.909+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6dae4bfa10>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6dae4bfa10>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6dae4bfa10>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:52:45.935+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:52:47.327+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.770 seconds
[2023-07-26T18:53:17.496+0000] {processor.py:153} INFO - Started process (PID=5472) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:53:17.498+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:53:17.500+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:53:17.500+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:53:18.179+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:53:18.165+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6dae4bf790>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6dae4bf790>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6dae4bf790>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:53:18.180+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:53:20.336+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.850 seconds
[2023-07-26T18:53:58.274+0000] {processor.py:153} INFO - Started process (PID=5487) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:53:58.349+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:53:58.381+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:53:58.380+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:53:59.947+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:53:59.923+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/usr/local/lib/python3.7/socket.py", line 752, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 187, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f6db00f95d0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 788, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db00f95d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 102, in <module>
    data = get_data_from_api()
  File "/opt/airflow/dags/load_data.py", line 38, in get_data_from_api
    response = requests.get(url, headers=headers, params=querystring)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='jsearch.p.rapidapi.com', port=443): Max retries exceeded with url: /search?query=Data+Engineer+in+Ontario%2C+Canada&page=1&num_pages=1&date_posted=month (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6db00f95d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-07-26T18:53:59.949+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:54:00.558+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.298 seconds
[2023-07-26T18:54:32.057+0000] {processor.py:153} INFO - Started process (PID=5512) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:54:32.064+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:54:32.078+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:54:32.077+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:54:58.937+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:54:59.326+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:54:59.325+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T18:54:59.434+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:54:59.433+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T18:55:02.967+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 30.938 seconds
[2023-07-26T18:55:33.491+0000] {processor.py:153} INFO - Started process (PID=5543) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:55:33.557+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:55:33.560+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:55:33.559+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:55:39.322+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:55:39.545+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:55:39.544+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T18:55:39.816+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:55:39.815+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T18:55:40.172+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.689 seconds
[2023-07-26T18:56:10.507+0000] {processor.py:153} INFO - Started process (PID=5567) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:56:10.517+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:56:10.520+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:56:10.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:56:15.533+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:56:15.596+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:56:15.595+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T18:56:15.647+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:56:15.647+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T18:56:16.467+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.967 seconds
[2023-07-26T18:56:47.305+0000] {processor.py:153} INFO - Started process (PID=5585) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:56:47.307+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:56:47.309+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:56:47.308+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:56:52.245+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:56:52.369+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:56:52.367+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T18:56:52.484+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:56:52.484+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T18:56:52.959+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.661 seconds
[2023-07-26T18:57:24.213+0000] {processor.py:153} INFO - Started process (PID=5611) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:57:24.338+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:57:24.387+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:57:24.387+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:57:34.935+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:57:35.076+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:57:35.075+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T18:57:35.242+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:57:35.242+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T18:57:36.812+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 12.618 seconds
[2023-07-26T18:58:07.034+0000] {processor.py:153} INFO - Started process (PID=5630) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:58:07.040+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:58:07.043+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:58:07.042+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:58:12.802+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:58:12.888+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:58:12.886+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T18:58:12.961+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:58:12.960+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T18:58:13.325+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.303 seconds
[2023-07-26T18:58:43.499+0000] {processor.py:153} INFO - Started process (PID=5665) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:58:43.589+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:58:43.591+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:58:43.591+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:59:08.185+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:59:08.598+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:59:08.591+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T18:59:08.733+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:59:08.732+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T18:59:11.500+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 28.010 seconds
[2023-07-26T18:59:41.913+0000] {processor.py:153} INFO - Started process (PID=5697) to work on /opt/airflow/dags/load_data.py
[2023-07-26T18:59:41.937+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T18:59:41.939+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:59:41.939+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T18:59:48.384+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T18:59:48.595+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:59:48.592+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T18:59:48.700+0000] {logging_mixin.py:137} INFO - [2023-07-26T18:59:48.700+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T18:59:49.603+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.690 seconds
[2023-07-26T19:00:19.790+0000] {processor.py:153} INFO - Started process (PID=5714) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:00:19.802+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:00:19.808+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:00:19.807+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:00:25.484+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:00:25.566+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:00:25.565+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:00:25.638+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:00:25.637+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:00:26.324+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.548 seconds
[2023-07-26T19:00:56.876+0000] {processor.py:153} INFO - Started process (PID=5741) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:00:56.878+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:00:56.880+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:00:56.880+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:01:27.125+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:01:27.123+0000] {timeout.py:68} ERROR - Process timed out, PID: 5741
[2023-07-26T19:01:27.577+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:01:27.128+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 107, in <module>
    load_to_db.create_table()
  File "/opt/airflow/dags/load_to_db.py", line 9, in create_table
    conn = psycopg2.connect(host='host.docker.internal', dbname='cohort_4_', user='postgres', password='P@55w076')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/load_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.5.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.5.0/best-practices.html#reducing-dag-complexity, PID: 5741
[2023-07-26T19:01:27.579+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:01:28.453+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 31.585 seconds
[2023-07-26T19:01:59.106+0000] {processor.py:153} INFO - Started process (PID=5782) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:01:59.108+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:01:59.121+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:01:59.121+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:02:06.480+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:02:06.548+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:02:06.547+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:02:06.603+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:02:06.603+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:02:12.042+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 12.956 seconds
[2023-07-26T19:02:42.460+0000] {processor.py:153} INFO - Started process (PID=5797) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:02:42.462+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:02:42.464+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:02:42.464+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:02:48.313+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:02:48.467+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:02:48.465+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:02:49.011+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:02:49.011+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:02:50.728+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.274 seconds
[2023-07-26T19:03:21.846+0000] {processor.py:153} INFO - Started process (PID=5821) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:03:21.857+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:03:21.877+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:03:21.876+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:03:23.228+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:03:23.213+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 11, in <module>
    'retry_delay':timedelta(minutes=5)
NameError: name 'timedelta' is not defined
[2023-07-26T19:03:23.436+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:03:24.823+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.996 seconds
[2023-07-26T19:03:55.529+0000] {processor.py:153} INFO - Started process (PID=5839) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:03:57.115+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:03:57.118+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:03:57.118+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:03:57.653+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:03:57.642+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 11, in <module>
    'retry_delay':timedelta(minutes=5)
NameError: name 'timedelta' is not defined
[2023-07-26T19:03:57.655+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:03:58.424+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.901 seconds
[2023-07-26T19:04:28.994+0000] {processor.py:153} INFO - Started process (PID=5854) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:04:29.066+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:04:29.076+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:04:29.076+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:04:29.874+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:04:29.860+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 11, in <module>
    'retry_delay':timedelta(minutes=5)
NameError: name 'timedelta' is not defined
[2023-07-26T19:04:29.879+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:04:30.954+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.969 seconds
[2023-07-26T19:05:01.641+0000] {processor.py:153} INFO - Started process (PID=5869) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:05:01.643+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:05:01.645+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:05:01.645+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:05:02.490+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:05:02.464+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 11, in <module>
    'retry_delay':timedelta(minutes=5)
NameError: name 'timedelta' is not defined
[2023-07-26T19:05:02.494+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:05:02.765+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.144 seconds
[2023-07-26T19:05:33.586+0000] {processor.py:153} INFO - Started process (PID=5892) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:05:38.303+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:05:38.449+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:05:38.448+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:05:40.262+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:05:40.238+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 11, in <module>
    'retry_delay':timedelta(minutes=5)
NameError: name 'timedelta' is not defined
[2023-07-26T19:05:40.268+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:05:42.058+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.490 seconds
[2023-07-26T19:06:12.799+0000] {processor.py:153} INFO - Started process (PID=5909) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:06:37.438+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:06:37.443+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:06:37.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:06:37.553+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:06:37.553+0000] {dagbag.py:320} INFO - File /opt/airflow/dags/load_data.py assumed to contain no DAGs. Skipping.
[2023-07-26T19:06:37.555+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:06:39.800+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 27.005 seconds
[2023-07-26T19:07:09.948+0000] {processor.py:153} INFO - Started process (PID=5923) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:07:09.950+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:07:09.952+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:07:09.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:07:15.119+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:07:15.260+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:07:15.258+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:07:15.378+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:07:15.378+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:07:16.801+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.863 seconds
[2023-07-26T19:07:47.691+0000] {processor.py:153} INFO - Started process (PID=5950) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:07:47.694+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:07:47.697+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:07:47.697+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:07:53.387+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:07:53.604+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:07:53.602+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:07:53.830+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:07:53.830+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:07:54.192+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.509 seconds
[2023-07-26T19:08:24.590+0000] {processor.py:153} INFO - Started process (PID=5968) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:08:24.592+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:08:24.593+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:08:24.593+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:08:30.493+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:08:30.555+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:08:30.554+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:08:30.606+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:08:30.606+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:08:32.756+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.172 seconds
[2023-07-26T19:09:03.502+0000] {processor.py:153} INFO - Started process (PID=5996) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:09:03.512+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:09:03.515+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:09:03.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:09:10.838+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:09:10.980+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:09:10.979+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:09:11.073+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:09:11.073+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:09:12.262+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.774 seconds
[2023-07-26T19:09:42.421+0000] {processor.py:153} INFO - Started process (PID=6011) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:09:42.423+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:09:42.425+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:09:42.425+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:09:48.974+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:09:49.119+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:09:49.118+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:09:49.280+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:09:49.280+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:09:50.237+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.828 seconds
[2023-07-26T19:10:20.781+0000] {processor.py:153} INFO - Started process (PID=6037) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:10:20.794+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:10:20.796+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:10:20.796+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:10:26.031+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:10:26.096+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:10:26.095+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:10:26.149+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:10:26.149+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:10:27.379+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.607 seconds
[2023-07-26T19:10:57.761+0000] {processor.py:153} INFO - Started process (PID=6061) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:10:57.769+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:10:57.781+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:10:57.781+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:11:03.505+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:11:05.220+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:11:05.220+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:11:05.282+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:11:05.282+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:11:06.259+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.508 seconds
[2023-07-26T19:11:37.073+0000] {processor.py:153} INFO - Started process (PID=6079) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:11:37.075+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:11:37.077+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:11:37.077+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:11:45.814+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:11:45.968+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:11:45.965+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:11:46.102+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:11:46.102+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:11:46.567+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 9.502 seconds
[2023-07-26T19:12:17.067+0000] {processor.py:153} INFO - Started process (PID=6108) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:12:17.074+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:12:17.083+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:12:17.083+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:12:23.390+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:12:23.459+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:12:23.458+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:12:23.506+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:12:23.506+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:12:24.141+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.083 seconds
[2023-07-26T19:12:54.542+0000] {processor.py:153} INFO - Started process (PID=6135) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:12:54.547+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:12:54.550+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:12:54.549+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:12:59.425+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:12:59.492+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:12:59.491+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:12:59.545+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:12:59.544+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:12:59.693+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.162 seconds
[2023-07-26T19:13:30.333+0000] {processor.py:153} INFO - Started process (PID=6163) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:13:30.335+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:13:30.338+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:13:30.338+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:13:35.519+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:13:35.618+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:13:35.617+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:13:35.680+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:13:35.679+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:13:36.187+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.900 seconds
[2023-07-26T19:14:07.206+0000] {processor.py:153} INFO - Started process (PID=6188) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:14:07.208+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:14:07.216+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:14:07.216+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:14:14.109+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:14:14.310+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:14:14.308+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:14:14.447+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:14:14.447+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:14:15.073+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.880 seconds
[2023-07-26T19:14:45.707+0000] {processor.py:153} INFO - Started process (PID=6207) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:14:45.709+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:14:45.711+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:14:45.711+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:14:50.862+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:14:51.093+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:14:51.092+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:14:51.180+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:14:51.180+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:14:51.385+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.684 seconds
[2023-07-26T19:15:21.949+0000] {processor.py:153} INFO - Started process (PID=6235) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:15:21.951+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:15:21.953+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:15:21.953+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:15:27.052+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:15:27.257+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:15:27.254+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:15:27.371+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:15:27.371+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:15:27.978+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.037 seconds
[2023-07-26T19:15:58.342+0000] {processor.py:153} INFO - Started process (PID=6262) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:15:58.344+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:15:58.346+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:15:58.345+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:16:03.280+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:16:03.363+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:16:03.362+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:16:03.432+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:16:03.431+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:16:04.215+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.880 seconds
[2023-07-26T19:16:34.549+0000] {processor.py:153} INFO - Started process (PID=6283) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:16:34.557+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:16:34.560+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:16:34.560+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:16:39.627+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:16:39.716+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:16:39.715+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:16:39.780+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:16:39.780+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:16:40.284+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.744 seconds
[2023-07-26T19:17:10.757+0000] {processor.py:153} INFO - Started process (PID=6303) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:17:11.924+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:17:11.927+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:17:11.927+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:17:27.773+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:17:27.905+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:17:27.904+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:17:28.009+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:17:28.009+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:17:28.433+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 17.687 seconds
[2023-07-26T19:17:59.261+0000] {processor.py:153} INFO - Started process (PID=6343) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:17:59.265+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:17:59.269+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:17:59.268+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:18:06.414+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:18:06.491+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:18:06.490+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:18:06.550+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:18:06.550+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:18:06.823+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.572 seconds
[2023-07-26T19:18:37.074+0000] {processor.py:153} INFO - Started process (PID=6370) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:18:37.080+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:18:37.082+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:18:37.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:18:41.390+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:18:41.452+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:18:41.452+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:18:41.506+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:18:41.506+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:18:41.770+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.716 seconds
[2023-07-26T19:19:11.963+0000] {processor.py:153} INFO - Started process (PID=6395) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:19:11.967+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:19:11.970+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:19:11.970+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:19:17.609+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:19:17.763+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:19:17.751+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:19:18.062+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:19:18.061+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:19:18.693+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.747 seconds
[2023-07-26T19:19:49.057+0000] {processor.py:153} INFO - Started process (PID=6413) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:19:49.059+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:19:49.062+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:19:49.062+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:19:54.909+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:19:55.123+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:19:55.122+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:19:55.272+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:19:55.272+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:19:55.581+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.543 seconds
[2023-07-26T19:20:25.936+0000] {processor.py:153} INFO - Started process (PID=6441) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:20:25.939+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:20:25.941+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:20:25.941+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:20:30.699+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:20:30.782+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:20:30.781+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:20:30.838+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:20:30.838+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:20:31.411+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.483 seconds
[2023-07-26T19:21:01.993+0000] {processor.py:153} INFO - Started process (PID=6465) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:21:01.995+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:21:01.998+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:21:01.997+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:21:08.754+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:21:08.974+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:21:08.973+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:21:09.167+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:21:09.167+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:21:09.423+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.441 seconds
[2023-07-26T19:21:39.817+0000] {processor.py:153} INFO - Started process (PID=6491) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:21:39.821+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:21:39.823+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:21:39.823+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:21:45.477+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:21:45.626+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:21:45.624+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:21:45.727+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:21:45.726+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:21:45.878+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.078 seconds
[2023-07-26T19:22:16.239+0000] {processor.py:153} INFO - Started process (PID=6511) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:22:16.244+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:22:16.248+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:22:16.248+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:22:21.925+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:22:22.398+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:22:22.397+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:22:22.809+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:22:22.809+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:22:23.185+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.955 seconds
[2023-07-26T19:22:53.990+0000] {processor.py:153} INFO - Started process (PID=6538) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:22:53.997+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:22:54.000+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:22:54.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:22:58.495+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:22:58.570+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:22:58.569+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:22:58.635+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:22:58.635+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:22:59.082+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.104 seconds
[2023-07-26T19:23:29.522+0000] {processor.py:153} INFO - Started process (PID=6566) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:23:29.534+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:23:29.537+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:23:29.536+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:23:36.932+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:23:37.213+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:23:37.211+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:23:37.316+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:23:37.315+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:23:37.685+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.171 seconds
[2023-07-26T19:24:08.263+0000] {processor.py:153} INFO - Started process (PID=6592) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:24:08.266+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:24:08.275+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:24:08.275+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:24:13.377+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:24:13.474+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:24:13.473+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:24:14.015+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:24:14.015+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:24:14.317+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.066 seconds
[2023-07-26T19:24:44.472+0000] {processor.py:153} INFO - Started process (PID=6622) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:24:44.474+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:24:44.477+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:24:44.476+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:24:49.392+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:24:49.478+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:24:49.477+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:24:49.559+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:24:49.559+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:24:49.890+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.434 seconds
[2023-07-26T19:25:20.180+0000] {processor.py:153} INFO - Started process (PID=6650) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:25:20.183+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:25:20.185+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:25:20.184+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:25:24.893+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:25:24.971+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:25:24.970+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:25:25.033+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:25:25.033+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:25:25.485+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.311 seconds
[2023-07-26T19:25:56.063+0000] {processor.py:153} INFO - Started process (PID=6677) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:25:56.065+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:25:56.069+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:25:56.069+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:26:01.723+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:26:01.832+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:26:01.831+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:26:01.953+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:26:01.952+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:26:02.408+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.357 seconds
[2023-07-26T19:26:32.767+0000] {processor.py:153} INFO - Started process (PID=6706) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:26:32.785+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:26:32.795+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:26:32.794+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:26:38.296+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:26:38.507+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:26:38.506+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:26:38.901+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:26:38.900+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:26:39.419+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.673 seconds
[2023-07-26T19:27:09.705+0000] {processor.py:153} INFO - Started process (PID=6731) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:27:09.707+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:27:09.712+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:27:09.712+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:27:16.823+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:27:17.110+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:27:17.109+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:27:17.313+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:27:17.313+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:27:18.341+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.640 seconds
[2023-07-26T19:27:48.550+0000] {processor.py:153} INFO - Started process (PID=6761) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:27:48.552+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:27:48.554+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:27:48.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:27:53.047+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:27:53.223+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:27:53.221+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:27:53.397+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:27:53.397+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:27:53.594+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.051 seconds
[2023-07-26T19:28:24.566+0000] {processor.py:153} INFO - Started process (PID=6788) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:28:24.568+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:28:24.570+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:28:24.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:28:29.114+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:28:29.189+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:28:29.188+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:28:29.238+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:28:29.237+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:28:29.758+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.197 seconds
[2023-07-26T19:29:00.117+0000] {processor.py:153} INFO - Started process (PID=6811) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:29:00.120+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:29:00.133+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:29:00.121+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:29:06.704+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:29:06.881+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:29:06.875+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:29:06.982+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:29:06.982+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:29:07.202+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.101 seconds
[2023-07-26T19:29:37.454+0000] {processor.py:153} INFO - Started process (PID=6832) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:29:37.457+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:29:37.460+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:29:37.459+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:29:43.537+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:29:43.677+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:29:43.676+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:29:43.832+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:29:43.832+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:29:44.573+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.125 seconds
[2023-07-26T19:30:15.421+0000] {processor.py:153} INFO - Started process (PID=6861) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:30:15.442+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:30:15.446+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:30:15.446+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:30:23.427+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:30:23.572+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:30:23.571+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:30:23.690+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:30:23.690+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:30:24.112+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.696 seconds
[2023-07-26T19:30:54.785+0000] {processor.py:153} INFO - Started process (PID=6888) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:30:54.799+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:30:54.801+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:30:54.800+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:31:01.399+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:31:01.695+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:31:01.694+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:31:02.281+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:31:02.280+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:31:02.533+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.758 seconds
[2023-07-26T19:31:33.314+0000] {processor.py:153} INFO - Started process (PID=6914) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:31:33.330+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:31:33.346+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:31:33.346+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:31:38.744+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:31:38.898+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:31:38.888+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:31:39.037+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:31:39.035+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:31:39.283+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.106 seconds
[2023-07-26T19:32:09.658+0000] {processor.py:153} INFO - Started process (PID=6939) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:32:09.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:32:09.667+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:32:09.666+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:32:17.130+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:32:17.489+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:32:17.487+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:32:17.858+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:32:17.857+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:32:18.403+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.751 seconds
[2023-07-26T19:32:49.052+0000] {processor.py:153} INFO - Started process (PID=6960) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:32:49.055+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:32:49.057+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:32:49.057+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:32:53.826+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:32:54.015+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:32:54.014+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:32:54.164+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:32:54.164+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:32:54.296+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.254 seconds
[2023-07-26T19:33:24.426+0000] {processor.py:153} INFO - Started process (PID=6986) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:33:24.430+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:33:24.433+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:33:24.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:33:30.583+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:33:30.971+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:33:30.969+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:33:31.236+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:33:31.235+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:33:31.653+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.241 seconds
[2023-07-26T19:34:01.872+0000] {processor.py:153} INFO - Started process (PID=7005) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:34:01.878+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:34:01.883+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:34:01.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:34:07.572+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:34:07.750+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:34:07.747+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:34:08.385+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:34:08.385+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:34:09.126+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.273 seconds
[2023-07-26T19:34:40.151+0000] {processor.py:153} INFO - Started process (PID=7032) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:34:40.153+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:34:40.156+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:34:40.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:34:45.325+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:34:45.407+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:34:45.406+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:34:45.488+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:34:45.487+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:34:45.759+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.617 seconds
[2023-07-26T19:35:16.374+0000] {processor.py:153} INFO - Started process (PID=7059) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:35:16.377+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:35:16.380+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:35:16.380+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:35:22.513+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:35:22.602+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:35:22.601+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:35:22.660+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:35:22.660+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:35:22.961+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.607 seconds
[2023-07-26T19:35:53.587+0000] {processor.py:153} INFO - Started process (PID=7088) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:35:53.591+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:35:53.595+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:35:53.593+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:36:00.728+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:36:00.806+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:36:00.805+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:36:00.970+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:36:00.970+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:36:01.364+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.786 seconds
[2023-07-26T19:36:31.739+0000] {processor.py:153} INFO - Started process (PID=7115) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:36:31.741+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:36:31.744+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:36:31.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:36:36.731+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:36:36.806+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:36:36.805+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:36:36.901+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:36:36.901+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:36:37.085+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.353 seconds
[2023-07-26T19:37:07.310+0000] {processor.py:153} INFO - Started process (PID=7140) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:37:07.312+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:37:07.320+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:37:07.320+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:37:15.464+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:37:15.748+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:37:15.746+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:37:16.039+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:37:16.039+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:37:17.775+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 10.484 seconds
[2023-07-26T19:37:48.440+0000] {processor.py:153} INFO - Started process (PID=7171) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:37:48.444+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:37:48.447+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:37:48.446+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:37:55.640+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:37:55.792+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:37:55.791+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:37:55.927+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:37:55.927+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:37:56.494+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.062 seconds
[2023-07-26T19:38:26.749+0000] {processor.py:153} INFO - Started process (PID=7198) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:38:26.751+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:38:26.753+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:38:26.753+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:38:30.982+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:38:31.282+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:38:31.278+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:38:31.449+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:38:31.448+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:38:31.691+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.949 seconds
[2023-07-26T19:39:01.983+0000] {processor.py:153} INFO - Started process (PID=7225) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:39:01.986+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:39:01.998+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:39:01.993+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:39:07.424+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:39:07.611+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:39:07.610+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T19:39:07.755+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:39:07.755+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to None, run_after=None
[2023-07-26T19:39:08.419+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.464 seconds
[2023-07-26T19:39:39.089+0000] {processor.py:153} INFO - Started process (PID=7253) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:39:39.091+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:39:39.093+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:39:39.092+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:39:40.613+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:39:40.598+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:39:40.632+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:39:40.834+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.751 seconds
[2023-07-26T19:40:11.297+0000] {processor.py:153} INFO - Started process (PID=7283) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:40:11.348+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:40:11.390+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:40:11.389+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:40:16.118+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:40:16.079+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:40:16.121+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:40:16.481+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.206 seconds
[2023-07-26T19:40:47.007+0000] {processor.py:153} INFO - Started process (PID=7299) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:40:47.009+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:40:47.011+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:40:47.011+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:40:48.514+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:40:48.505+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:40:48.518+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:40:48.703+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.703 seconds
[2023-07-26T19:41:19.096+0000] {processor.py:153} INFO - Started process (PID=7326) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:41:19.100+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:41:19.102+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:41:19.101+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:41:20.414+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:41:20.405+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:41:20.419+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:41:20.708+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.618 seconds
[2023-07-26T19:41:51.686+0000] {processor.py:153} INFO - Started process (PID=7352) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:41:51.691+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:41:51.700+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:41:51.698+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:41:55.910+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:41:55.881+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:41:55.924+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:41:56.396+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.746 seconds
[2023-07-26T19:42:27.030+0000] {processor.py:153} INFO - Started process (PID=7380) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:42:27.112+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:42:27.114+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:42:27.114+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:42:39.762+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:42:39.728+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:42:39.767+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:42:40.192+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 13.189 seconds
[2023-07-26T19:43:10.789+0000] {processor.py:153} INFO - Started process (PID=7409) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:43:10.839+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:43:10.857+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:43:10.857+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:43:16.288+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:43:16.271+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:43:16.298+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:43:16.878+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.124 seconds
[2023-07-26T19:43:48.105+0000] {processor.py:153} INFO - Started process (PID=7436) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:43:48.107+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:43:48.109+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:43:48.108+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:43:51.030+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:43:50.937+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:43:51.045+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:43:51.755+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.659 seconds
[2023-07-26T19:44:21.932+0000] {processor.py:153} INFO - Started process (PID=7455) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:44:21.935+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:44:21.948+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:44:21.947+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:44:23.879+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:44:23.858+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:44:23.889+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:44:24.051+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.136 seconds
[2023-07-26T19:44:54.594+0000] {processor.py:153} INFO - Started process (PID=7483) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:44:54.603+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:44:54.607+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:44:54.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:44:56.408+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:44:56.395+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:44:56.411+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:44:56.537+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.954 seconds
[2023-07-26T19:45:26.892+0000] {processor.py:153} INFO - Started process (PID=7507) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:45:26.949+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:45:26.951+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:45:26.951+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:45:29.013+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:45:28.999+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:45:29.018+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:45:29.194+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.317 seconds
[2023-07-26T19:46:00.042+0000] {processor.py:153} INFO - Started process (PID=7526) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:46:00.048+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:46:00.051+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:46:00.051+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:46:03.003+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:46:02.985+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:46:03.008+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:46:03.260+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.228 seconds
[2023-07-26T19:46:33.745+0000] {processor.py:153} INFO - Started process (PID=7552) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:46:33.747+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:46:33.749+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:46:33.748+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:46:35.920+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:46:35.907+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:46:35.925+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:46:36.074+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.337 seconds
[2023-07-26T19:47:06.243+0000] {processor.py:153} INFO - Started process (PID=7576) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:47:06.258+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:47:06.266+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:47:06.265+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:47:08.771+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:47:08.757+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:47:08.781+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:47:09.172+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.950 seconds
[2023-07-26T19:47:40.065+0000] {processor.py:153} INFO - Started process (PID=7594) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:47:40.184+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:47:40.186+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:47:40.186+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:47:41.757+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:47:41.747+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:47:41.760+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:47:42.209+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.150 seconds
[2023-07-26T19:48:12.637+0000] {processor.py:153} INFO - Started process (PID=7622) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:48:12.640+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:48:12.649+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:48:12.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:48:15.168+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:48:15.129+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:48:15.196+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:48:15.489+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.873 seconds
[2023-07-26T19:48:45.952+0000] {processor.py:153} INFO - Started process (PID=7649) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:48:45.954+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:48:45.956+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:48:45.955+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:48:47.542+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:48:47.522+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:48:47.546+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:48:47.664+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.722 seconds
[2023-07-26T19:49:18.164+0000] {processor.py:153} INFO - Started process (PID=7678) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:49:18.167+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:49:18.169+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:49:18.169+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:49:19.515+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:49:19.506+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:49:19.519+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:49:19.746+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.589 seconds
[2023-07-26T19:49:50.212+0000] {processor.py:153} INFO - Started process (PID=7705) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:49:50.214+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:49:50.216+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:49:50.216+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:49:51.734+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:49:51.717+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:49:51.740+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:49:52.013+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.810 seconds
[2023-07-26T19:50:22.325+0000] {processor.py:153} INFO - Started process (PID=7729) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:50:22.328+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:50:22.331+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:50:22.330+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:50:23.904+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:50:23.895+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:50:23.908+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:50:24.282+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.963 seconds
[2023-07-26T19:50:54.629+0000] {processor.py:153} INFO - Started process (PID=7754) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:50:54.632+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:50:54.634+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:50:54.633+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:50:56.592+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:50:56.582+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:50:56.595+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:50:56.824+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.202 seconds
[2023-07-26T19:51:27.163+0000] {processor.py:153} INFO - Started process (PID=7774) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:51:27.165+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:51:27.167+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:51:27.166+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:51:28.587+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:51:28.574+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:51:28.591+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:51:28.752+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.596 seconds
[2023-07-26T19:51:59.373+0000] {processor.py:153} INFO - Started process (PID=7801) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:51:59.375+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:51:59.389+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:51:59.388+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:52:01.912+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:52:01.830+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:52:01.982+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:52:02.212+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.850 seconds
[2023-07-26T19:52:32.612+0000] {processor.py:153} INFO - Started process (PID=7829) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:52:32.614+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:52:32.616+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:52:32.616+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:52:34.106+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:52:34.098+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:52:34.112+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:52:34.322+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.723 seconds
[2023-07-26T19:53:04.557+0000] {processor.py:153} INFO - Started process (PID=7856) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:53:04.564+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:53:04.568+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:53:04.568+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:53:06.941+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:53:06.929+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:53:06.967+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:53:07.146+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.600 seconds
[2023-07-26T19:53:37.635+0000] {processor.py:153} INFO - Started process (PID=7871) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:53:37.636+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:53:37.639+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:53:37.639+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:53:39.461+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:53:39.429+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:53:39.470+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:53:39.691+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.064 seconds
[2023-07-26T19:54:10.513+0000] {processor.py:153} INFO - Started process (PID=7900) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:54:10.525+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:54:10.529+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:54:10.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:54:14.012+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:54:14.000+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:54:14.016+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:54:14.250+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.765 seconds
[2023-07-26T19:54:44.937+0000] {processor.py:153} INFO - Started process (PID=7927) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:54:44.964+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:54:44.971+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:54:44.969+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:54:47.602+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:54:47.544+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:54:47.626+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:54:47.893+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.963 seconds
[2023-07-26T19:55:18.276+0000] {processor.py:153} INFO - Started process (PID=7943) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:55:18.284+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:55:18.287+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:55:18.286+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:55:20.440+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:55:20.424+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:55:20.453+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:55:20.693+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.427 seconds
[2023-07-26T19:55:51.018+0000] {processor.py:153} INFO - Started process (PID=7970) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:55:51.020+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:55:51.022+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:55:51.022+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:55:52.424+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:55:52.373+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:55:52.533+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:55:52.876+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.866 seconds
[2023-07-26T19:56:23.396+0000] {processor.py:153} INFO - Started process (PID=7998) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:56:23.409+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:56:23.412+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:56:23.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:56:24.977+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:56:24.961+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:56:24.983+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:56:25.173+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.786 seconds
[2023-07-26T19:56:55.300+0000] {processor.py:153} INFO - Started process (PID=8025) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:56:55.304+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:56:55.307+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:56:55.307+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:56:57.126+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:56:57.115+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:56:57.131+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:56:57.260+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.972 seconds
[2023-07-26T19:57:27.529+0000] {processor.py:153} INFO - Started process (PID=8051) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:57:27.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:57:27.534+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:57:27.532+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:57:29.602+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:57:29.570+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:57:29.618+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:57:29.943+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.422 seconds
[2023-07-26T19:58:00.738+0000] {processor.py:153} INFO - Started process (PID=8079) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:58:00.763+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:58:00.765+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:58:00.765+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:58:04.698+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:58:04.683+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:58:04.702+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:58:05.281+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.550 seconds
[2023-07-26T19:58:35.766+0000] {processor.py:153} INFO - Started process (PID=8094) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:58:35.769+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:58:35.771+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:58:35.770+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:58:37.782+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:58:37.755+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:58:37.788+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:58:38.318+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.559 seconds
[2023-07-26T19:59:08.666+0000] {processor.py:153} INFO - Started process (PID=8129) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:59:08.671+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:59:08.677+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:59:08.675+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:59:11.429+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:59:11.279+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:59:11.434+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:59:11.647+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.997 seconds
[2023-07-26T19:59:42.295+0000] {processor.py:153} INFO - Started process (PID=8156) to work on /opt/airflow/dags/load_data.py
[2023-07-26T19:59:42.299+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T19:59:42.308+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:59:42.308+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T19:59:44.161+0000] {logging_mixin.py:137} INFO - [2023-07-26T19:59:44.146+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T19:59:44.165+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T19:59:44.475+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.191 seconds
[2023-07-26T20:00:15.282+0000] {processor.py:153} INFO - Started process (PID=8185) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:00:15.286+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:00:15.293+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:00:15.290+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:00:17.470+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:00:17.433+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:00:17.473+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:00:17.631+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.362 seconds
[2023-07-26T20:00:48.188+0000] {processor.py:153} INFO - Started process (PID=8213) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:00:48.192+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:00:48.195+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:00:48.194+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:00:49.744+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:00:49.729+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:00:49.748+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:00:49.918+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.737 seconds
[2023-07-26T20:01:20.574+0000] {processor.py:153} INFO - Started process (PID=8233) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:01:20.614+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:01:20.617+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:01:20.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:01:22.348+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:01:22.303+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:01:22.361+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:01:22.909+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.344 seconds
[2023-07-26T20:01:53.213+0000] {processor.py:153} INFO - Started process (PID=8268) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:01:53.216+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:01:53.219+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:01:53.218+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:01:54.823+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:01:54.810+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:01:54.828+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:01:55.011+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.812 seconds
[2023-07-26T20:02:25.660+0000] {processor.py:153} INFO - Started process (PID=8296) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:02:25.669+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:02:25.672+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:02:25.671+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:02:30.131+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:02:30.117+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:02:30.134+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:02:30.820+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.170 seconds
[2023-07-26T20:03:01.461+0000] {processor.py:153} INFO - Started process (PID=8314) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:03:01.464+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:03:01.466+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:03:01.465+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:03:05.532+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:03:05.388+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:03:05.564+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:03:05.940+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.486 seconds
[2023-07-26T20:03:36.667+0000] {processor.py:153} INFO - Started process (PID=8342) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:03:36.669+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:03:36.670+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:03:36.670+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:03:38.168+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:03:38.155+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:03:38.171+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:03:38.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.788 seconds
[2023-07-26T20:04:08.655+0000] {processor.py:153} INFO - Started process (PID=8368) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:04:08.661+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:04:08.663+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:04:08.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:04:11.036+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:04:10.968+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:04:11.059+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:04:11.293+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.652 seconds
[2023-07-26T20:04:41.511+0000] {processor.py:153} INFO - Started process (PID=8392) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:04:41.514+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:04:41.516+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:04:41.516+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:04:43.644+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:04:43.618+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:04:43.651+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:04:44.320+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.821 seconds
[2023-07-26T20:05:14.418+0000] {processor.py:153} INFO - Started process (PID=8413) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:05:14.423+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:05:14.426+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:05:14.425+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:05:16.695+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:05:16.673+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:05:16.699+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:05:16.930+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.521 seconds
[2023-07-26T20:05:47.309+0000] {processor.py:153} INFO - Started process (PID=8440) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:05:47.311+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:05:47.314+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:05:47.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:05:49.180+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:05:49.166+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:05:49.184+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:05:49.518+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.215 seconds
[2023-07-26T20:06:19.840+0000] {processor.py:153} INFO - Started process (PID=8465) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:06:19.856+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:06:19.875+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:06:19.875+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:06:22.828+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:06:22.753+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:06:22.844+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:06:23.425+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.594 seconds
[2023-07-26T20:06:54.338+0000] {processor.py:153} INFO - Started process (PID=8483) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:06:54.340+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:06:54.344+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:06:54.342+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:06:56.369+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:06:56.341+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:06:56.384+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:06:56.746+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.415 seconds
[2023-07-26T20:07:26.873+0000] {processor.py:153} INFO - Started process (PID=8511) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:07:26.880+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:07:26.882+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:07:26.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:07:29.271+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:07:29.235+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:07:29.288+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:07:29.570+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.712 seconds
[2023-07-26T20:07:59.720+0000] {processor.py:153} INFO - Started process (PID=8539) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:07:59.723+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:07:59.726+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:07:59.726+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:08:01.819+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:08:01.786+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:08:01.824+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:08:02.081+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.368 seconds
[2023-07-26T20:08:32.725+0000] {processor.py:153} INFO - Started process (PID=8566) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:08:32.727+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:08:32.730+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:08:32.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:08:34.355+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:08:34.344+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:08:34.359+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:08:34.616+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.899 seconds
[2023-07-26T20:09:05.570+0000] {processor.py:153} INFO - Started process (PID=8591) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:09:05.579+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:09:05.598+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:09:05.597+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:09:08.906+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:09:08.876+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:09:08.911+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:09:09.083+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.532 seconds
[2023-07-26T20:09:39.613+0000] {processor.py:153} INFO - Started process (PID=8609) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:09:39.616+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:09:39.618+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:09:39.618+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:09:41.469+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:09:41.430+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:09:41.476+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:09:41.619+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.017 seconds
[2023-07-26T20:10:12.273+0000] {processor.py:153} INFO - Started process (PID=8636) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:10:12.275+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:10:12.278+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:10:12.278+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:10:14.654+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:10:14.643+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:10:14.657+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:10:15.015+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.757 seconds
[2023-07-26T20:10:45.669+0000] {processor.py:153} INFO - Started process (PID=8664) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:10:45.673+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:10:45.678+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:10:45.677+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:10:48.150+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:10:48.141+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:10:48.153+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:10:48.490+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.837 seconds
[2023-07-26T20:11:23.610+0000] {processor.py:153} INFO - Started process (PID=8688) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:11:23.732+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:11:23.790+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:11:23.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:11:31.567+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:11:31.381+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:11:31.615+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:11:32.331+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.739 seconds
[2023-07-26T20:12:02.959+0000] {processor.py:153} INFO - Started process (PID=8715) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:12:02.962+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:12:02.964+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:12:02.963+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:12:05.589+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:12:05.568+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:12:05.594+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:12:05.831+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.892 seconds
[2023-07-26T20:12:36.439+0000] {processor.py:153} INFO - Started process (PID=8735) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:12:36.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:12:36.443+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:12:36.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:12:38.395+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:12:38.380+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:12:38.399+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:12:38.597+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.169 seconds
[2023-07-26T20:13:09.164+0000] {processor.py:153} INFO - Started process (PID=8767) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:13:09.166+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:13:09.168+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:13:09.168+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:13:11.132+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:13:11.105+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:13:11.188+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:13:11.704+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.549 seconds
[2023-07-26T20:13:42.197+0000] {processor.py:153} INFO - Started process (PID=8796) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:13:42.199+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:13:42.202+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:13:42.201+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:13:44.784+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:13:44.770+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:13:44.790+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:13:44.927+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.740 seconds
[2023-07-26T20:14:15.772+0000] {processor.py:153} INFO - Started process (PID=8823) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:14:15.786+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:14:15.795+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:14:15.795+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:14:18.793+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:14:18.774+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:14:18.803+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:14:18.947+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.208 seconds
[2023-07-26T20:14:49.651+0000] {processor.py:153} INFO - Started process (PID=8846) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:14:49.661+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:14:49.679+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:14:49.679+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:14:51.529+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:14:51.518+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:14:51.533+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:14:51.812+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.178 seconds
[2023-07-26T20:15:22.207+0000] {processor.py:153} INFO - Started process (PID=8866) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:15:22.210+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:15:22.213+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:15:22.212+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:15:24.315+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:15:24.299+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:15:24.320+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:15:24.455+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.257 seconds
[2023-07-26T20:15:54.858+0000] {processor.py:153} INFO - Started process (PID=8894) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:15:54.874+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:15:54.924+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:15:54.923+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:15:59.626+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:15:59.607+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:15:59.637+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:16:00.129+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.285 seconds
[2023-07-26T20:16:30.384+0000] {processor.py:153} INFO - Started process (PID=8923) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:16:30.386+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:16:30.403+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:16:30.403+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:16:33.507+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:16:33.477+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:16:33.515+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:16:33.828+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.468 seconds
[2023-07-26T20:17:03.953+0000] {processor.py:153} INFO - Started process (PID=8947) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:17:03.955+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:17:03.958+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:17:03.958+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:17:05.987+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:17:05.963+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:17:05.993+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:17:06.129+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.183 seconds
[2023-07-26T20:17:36.406+0000] {processor.py:153} INFO - Started process (PID=8966) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:17:36.408+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:17:36.410+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:17:36.409+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:17:39.178+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:17:39.162+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:17:39.182+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:17:39.500+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.102 seconds
[2023-07-26T20:18:09.673+0000] {processor.py:153} INFO - Started process (PID=8993) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:18:09.676+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:18:09.684+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:18:09.684+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:18:11.530+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:18:11.516+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:18:11.533+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:18:11.861+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.195 seconds
[2023-07-26T20:18:41.978+0000] {processor.py:153} INFO - Started process (PID=9020) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:18:41.980+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:18:41.983+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:18:41.982+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:18:44.039+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:18:44.027+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:18:44.043+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:18:44.151+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.181 seconds
[2023-07-26T20:19:14.522+0000] {processor.py:153} INFO - Started process (PID=9044) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:19:14.529+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:19:14.532+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:19:14.532+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:19:16.567+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:19:16.507+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:19:16.573+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:19:16.757+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.246 seconds
[2023-07-26T20:19:47.123+0000] {processor.py:153} INFO - Started process (PID=9062) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:19:47.125+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:19:47.128+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:19:47.127+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:19:48.564+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:19:48.555+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:19:48.568+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:19:49.005+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.894 seconds
[2023-07-26T20:20:19.151+0000] {processor.py:153} INFO - Started process (PID=9089) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:20:19.154+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:20:19.156+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:20:19.156+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:20:20.833+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:20:20.821+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:20:20.838+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:20:21.032+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.891 seconds
[2023-07-26T20:20:51.819+0000] {processor.py:153} INFO - Started process (PID=9116) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:20:51.821+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:20:51.824+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:20:51.823+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:20:54.840+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:20:54.826+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:20:54.843+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:20:55.145+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.335 seconds
[2023-07-26T20:21:25.865+0000] {processor.py:153} INFO - Started process (PID=9135) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:21:25.868+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:21:25.872+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:21:25.871+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:21:27.483+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:21:27.474+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:21:27.486+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:21:27.875+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.021 seconds
[2023-07-26T20:21:58.772+0000] {processor.py:153} INFO - Started process (PID=9163) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:21:58.775+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:21:58.777+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:21:58.777+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:22:00.703+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:22:00.693+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:22:00.709+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:22:00.950+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.185 seconds
[2023-07-26T20:22:31.438+0000] {processor.py:153} INFO - Started process (PID=9190) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:22:31.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:22:31.443+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:22:31.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:22:33.055+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:22:33.043+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:22:33.059+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:22:33.301+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.870 seconds
[2023-07-26T20:23:03.966+0000] {processor.py:153} INFO - Started process (PID=9222) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:23:03.978+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:23:03.992+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:23:03.991+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:23:06.140+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:23:06.130+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:23:06.173+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:23:06.405+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.465 seconds
[2023-07-26T20:23:36.816+0000] {processor.py:153} INFO - Started process (PID=9243) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:23:36.819+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:23:36.820+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:23:36.820+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:23:38.367+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:23:38.355+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:23:38.381+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:23:38.553+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.742 seconds
[2023-07-26T20:24:09.056+0000] {processor.py:153} INFO - Started process (PID=9275) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:24:09.058+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:24:09.071+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:24:09.071+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:24:12.256+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:24:12.233+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:24:12.266+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:24:12.504+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.465 seconds
[2023-07-26T20:24:43.238+0000] {processor.py:153} INFO - Started process (PID=9305) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:24:43.242+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:24:43.244+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:24:43.244+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:24:45.321+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:24:45.310+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:24:45.326+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:24:45.509+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.279 seconds
[2023-07-26T20:25:16.514+0000] {processor.py:153} INFO - Started process (PID=9333) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:25:16.527+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:25:16.529+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:25:16.529+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:25:18.590+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:25:18.576+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:25:18.595+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:25:18.757+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.262 seconds
[2023-07-26T20:25:49.094+0000] {processor.py:153} INFO - Started process (PID=9349) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:25:49.097+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:25:49.099+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:25:49.099+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:25:51.275+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:25:51.263+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:25:51.278+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:25:51.493+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.404 seconds
[2023-07-26T20:26:21.820+0000] {processor.py:153} INFO - Started process (PID=9380) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:26:21.822+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:26:21.824+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:26:21.824+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:26:23.319+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:26:23.307+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:26:23.322+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:26:23.464+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.654 seconds
[2023-07-26T20:26:53.748+0000] {processor.py:153} INFO - Started process (PID=9408) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:26:53.751+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:26:53.754+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:26:53.753+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:26:55.874+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:26:55.860+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:26:55.877+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:26:56.001+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.264 seconds
[2023-07-26T20:27:26.413+0000] {processor.py:153} INFO - Started process (PID=9424) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:27:26.415+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:27:26.417+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:27:26.416+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:27:28.343+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:27:28.292+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:27:28.432+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:27:28.805+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.400 seconds
[2023-07-26T20:27:59.373+0000] {processor.py:153} INFO - Started process (PID=9452) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:27:59.375+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:27:59.377+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:27:59.376+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:28:01.036+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:28:01.023+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:28:01.039+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:28:01.236+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.871 seconds
[2023-07-26T20:28:31.553+0000] {processor.py:153} INFO - Started process (PID=9480) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:28:31.557+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:28:31.559+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:28:31.559+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:28:33.179+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:28:33.168+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:28:33.182+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:28:33.332+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.787 seconds
[2023-07-26T20:29:03.768+0000] {processor.py:153} INFO - Started process (PID=9505) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:29:03.771+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:29:03.774+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:29:03.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:29:06.783+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:29:06.757+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:29:06.789+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:29:07.255+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.499 seconds
[2023-07-26T20:29:37.832+0000] {processor.py:153} INFO - Started process (PID=9526) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:29:37.834+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:29:37.837+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:29:37.836+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:29:39.645+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:29:39.627+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:29:39.650+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:29:39.755+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.930 seconds
[2023-07-26T20:30:10.694+0000] {processor.py:153} INFO - Started process (PID=9556) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:30:10.762+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:30:10.817+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:30:10.816+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:30:14.662+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:30:14.589+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:30:14.690+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:30:14.929+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.263 seconds
[2023-07-26T20:30:45.839+0000] {processor.py:153} INFO - Started process (PID=9585) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:30:45.841+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:30:45.843+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:30:45.843+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:30:47.586+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:30:47.543+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:30:47.598+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:30:47.915+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.085 seconds
[2023-07-26T20:31:18.452+0000] {processor.py:153} INFO - Started process (PID=9602) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:31:18.454+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:31:18.457+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:31:18.457+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:31:19.812+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:31:19.802+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:31:19.815+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:31:20.091+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.647 seconds
[2023-07-26T20:31:50.549+0000] {processor.py:153} INFO - Started process (PID=9630) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:31:50.552+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:31:50.553+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:31:50.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:31:51.970+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:31:51.958+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:31:51.974+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:31:52.338+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.796 seconds
[2023-07-26T20:32:22.732+0000] {processor.py:153} INFO - Started process (PID=9658) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:32:22.734+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:32:22.737+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:32:22.736+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:32:24.517+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:32:24.497+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:32:24.523+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:32:24.650+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.926 seconds
[2023-07-26T20:32:55.220+0000] {processor.py:153} INFO - Started process (PID=9687) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:32:55.247+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:32:55.253+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:32:55.252+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:32:57.311+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:32:57.294+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:32:57.315+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:32:57.864+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.665 seconds
[2023-07-26T20:33:28.328+0000] {processor.py:153} INFO - Started process (PID=9703) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:33:28.329+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:33:28.331+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:33:28.331+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:33:29.887+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:33:29.870+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:33:29.890+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:33:30.124+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.802 seconds
[2023-07-26T20:34:00.425+0000] {processor.py:153} INFO - Started process (PID=9731) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:34:00.427+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:34:00.429+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:34:00.429+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:34:02.386+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:34:02.375+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:34:02.390+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:34:02.531+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.112 seconds
[2023-07-26T20:34:32.712+0000] {processor.py:153} INFO - Started process (PID=9760) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:34:32.732+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:34:32.737+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:34:32.735+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:34:35.550+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:34:35.482+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:34:35.569+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:34:35.910+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.217 seconds
[2023-07-26T20:35:06.442+0000] {processor.py:153} INFO - Started process (PID=9785) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:35:06.548+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:35:06.553+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:35:06.552+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:35:08.943+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:35:08.911+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:35:08.946+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:35:09.115+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.683 seconds
[2023-07-26T20:35:39.568+0000] {processor.py:153} INFO - Started process (PID=9805) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:35:39.573+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:35:39.576+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:35:39.575+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:35:40.948+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:35:40.938+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:35:40.952+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:35:41.125+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.565 seconds
[2023-07-26T20:36:12.253+0000] {processor.py:153} INFO - Started process (PID=9836) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:36:12.256+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:36:12.269+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:36:12.268+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:36:16.548+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:36:16.368+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:36:16.581+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:36:16.771+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.567 seconds
[2023-07-26T20:36:47.697+0000] {processor.py:153} INFO - Started process (PID=9865) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:36:47.699+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:36:47.702+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:36:47.701+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:36:51.327+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:36:51.313+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:36:51.331+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:36:51.728+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.042 seconds
[2023-07-26T20:37:22.486+0000] {processor.py:153} INFO - Started process (PID=9881) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:37:22.488+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:37:22.490+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:37:22.490+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:37:25.665+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:37:25.656+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:37:25.668+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:37:25.879+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.410 seconds
[2023-07-26T20:37:56.406+0000] {processor.py:153} INFO - Started process (PID=9911) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:37:56.408+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:37:56.411+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:37:56.410+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:37:58.938+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:37:58.924+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:37:58.942+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:37:59.252+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.852 seconds
[2023-07-26T20:38:29.649+0000] {processor.py:153} INFO - Started process (PID=9939) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:38:29.656+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:38:29.659+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:38:29.658+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:38:31.413+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:38:31.389+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:38:31.416+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:38:31.634+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.993 seconds
[2023-07-26T20:39:02.065+0000] {processor.py:153} INFO - Started process (PID=9956) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:39:02.075+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:39:02.079+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:39:02.078+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:39:06.285+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:39:06.255+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:39:06.295+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:39:06.619+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.562 seconds
[2023-07-26T20:39:37.747+0000] {processor.py:153} INFO - Started process (PID=9984) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:39:37.789+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:39:37.802+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:39:37.801+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:39:43.405+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:39:43.360+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:39:43.423+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:39:43.760+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.023 seconds
[2023-07-26T20:40:14.561+0000] {processor.py:153} INFO - Started process (PID=10011) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:40:14.563+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:40:14.566+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:40:14.565+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:40:18.109+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:40:17.894+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:40:18.120+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:40:18.426+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.871 seconds
[2023-07-26T20:40:48.886+0000] {processor.py:153} INFO - Started process (PID=10036) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:40:48.891+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:40:48.900+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:40:48.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:40:51.267+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:40:51.250+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:40:51.271+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:40:51.450+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.582 seconds
[2023-07-26T20:41:21.624+0000] {processor.py:153} INFO - Started process (PID=10057) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:41:21.627+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:41:21.630+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:41:21.629+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:41:23.183+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:41:23.172+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:41:23.187+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:41:23.505+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.887 seconds
[2023-07-26T20:41:54.198+0000] {processor.py:153} INFO - Started process (PID=10087) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:41:54.201+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:41:54.208+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:41:54.207+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:41:55.988+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:41:55.974+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:41:55.991+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:41:56.140+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.957 seconds
[2023-07-26T20:42:26.883+0000] {processor.py:153} INFO - Started process (PID=10113) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:42:26.886+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:42:26.888+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:42:26.888+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:42:28.818+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:42:28.804+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:42:28.821+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:42:28.955+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.085 seconds
[2023-07-26T20:42:59.078+0000] {processor.py:153} INFO - Started process (PID=10135) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:42:59.080+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:42:59.082+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:42:59.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:43:00.935+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:43:00.919+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:43:00.940+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:43:01.421+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.350 seconds
[2023-07-26T20:43:32.007+0000] {processor.py:153} INFO - Started process (PID=10164) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:43:32.026+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:43:32.104+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:43:32.103+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:43:34.166+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:43:34.149+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:43:34.171+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:43:34.332+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.335 seconds
[2023-07-26T20:44:04.972+0000] {processor.py:153} INFO - Started process (PID=10190) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:44:04.977+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:44:04.992+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:44:04.992+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:44:07.206+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:44:07.140+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:44:07.250+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:44:07.580+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.620 seconds
[2023-07-26T20:44:39.140+0000] {processor.py:153} INFO - Started process (PID=10211) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:44:39.153+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:44:39.158+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:44:39.158+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:44:46.191+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:44:46.166+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:44:46.195+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:44:46.528+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 7.396 seconds
[2023-07-26T20:45:17.388+0000] {processor.py:153} INFO - Started process (PID=10240) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:45:17.401+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:45:17.403+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:45:17.403+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:45:19.901+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:45:19.857+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:45:19.916+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:45:20.083+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.712 seconds
[2023-07-26T20:45:50.583+0000] {processor.py:153} INFO - Started process (PID=10271) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:45:50.586+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:45:50.588+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:45:50.588+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:45:53.111+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:45:53.087+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:45:53.125+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:45:53.309+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.740 seconds
[2023-07-26T20:46:24.156+0000] {processor.py:153} INFO - Started process (PID=10300) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:46:24.158+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:46:24.161+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:46:24.160+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:46:25.621+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:46:25.610+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:46:25.778+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:46:26.072+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.923 seconds
[2023-07-26T20:46:56.370+0000] {processor.py:153} INFO - Started process (PID=10329) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:46:56.372+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:46:56.374+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:46:56.374+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:46:57.970+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:46:57.928+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:46:57.993+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:46:58.119+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.762 seconds
[2023-07-26T20:47:28.834+0000] {processor.py:153} INFO - Started process (PID=10347) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:47:28.840+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:47:28.846+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:47:28.843+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:47:31.031+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:47:31.019+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:47:31.035+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:47:31.321+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.498 seconds
[2023-07-26T20:48:01.850+0000] {processor.py:153} INFO - Started process (PID=10378) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:48:01.855+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:48:01.868+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:48:01.868+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:48:03.998+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:48:03.971+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:48:04.002+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:48:04.650+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.817 seconds
[2023-07-26T20:48:35.749+0000] {processor.py:153} INFO - Started process (PID=10407) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:48:35.767+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:48:35.847+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:48:35.847+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:48:39.486+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:48:39.470+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:48:39.492+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:48:39.668+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.925 seconds
[2023-07-26T20:49:09.902+0000] {processor.py:153} INFO - Started process (PID=10437) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:49:09.904+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:49:09.906+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:49:09.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:49:12.276+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:49:12.215+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:49:12.288+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:49:12.519+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.627 seconds
[2023-07-26T20:49:42.788+0000] {processor.py:153} INFO - Started process (PID=10454) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:49:42.790+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:49:42.793+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:49:42.791+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:49:44.498+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:49:44.489+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:49:44.501+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:49:44.604+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.821 seconds
[2023-07-26T20:50:15.029+0000] {processor.py:153} INFO - Started process (PID=10483) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:50:15.042+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:50:15.051+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:50:15.051+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:50:19.338+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:50:19.280+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:50:19.381+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:50:19.886+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.874 seconds
[2023-07-26T20:50:51.466+0000] {processor.py:153} INFO - Started process (PID=10514) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:50:51.471+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:50:51.481+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:50:51.481+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:50:53.960+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:50:53.928+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:50:53.970+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:50:54.256+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.821 seconds
[2023-07-26T20:51:24.527+0000] {processor.py:153} INFO - Started process (PID=10531) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:51:24.532+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:51:24.534+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:51:24.534+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:51:27.956+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:51:27.936+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:51:27.965+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:51:28.351+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.832 seconds
[2023-07-26T20:51:58.513+0000] {processor.py:153} INFO - Started process (PID=10560) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:51:58.515+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:51:58.520+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:51:58.519+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:52:00.831+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:52:00.131+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:52:01.387+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:52:02.009+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.505 seconds
[2023-07-26T20:52:33.824+0000] {processor.py:153} INFO - Started process (PID=10589) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:52:33.826+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:52:33.829+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:52:33.828+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:52:36.358+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:52:36.333+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:52:36.365+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:52:36.755+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.940 seconds
[2023-07-26T20:53:07.451+0000] {processor.py:153} INFO - Started process (PID=10614) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:53:07.453+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:53:07.463+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:53:07.463+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:53:11.287+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:53:11.249+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:53:11.304+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:53:11.576+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.166 seconds
[2023-07-26T20:53:42.026+0000] {processor.py:153} INFO - Started process (PID=10637) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:53:42.029+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:53:42.032+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:53:42.031+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:53:43.836+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:53:43.822+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:53:43.841+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:53:44.133+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.114 seconds
[2023-07-26T20:54:15.938+0000] {processor.py:153} INFO - Started process (PID=10667) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:54:15.950+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:54:15.966+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:54:15.966+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:54:20.348+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:54:20.335+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:54:20.354+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:54:20.669+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.735 seconds
[2023-07-26T20:54:51.457+0000] {processor.py:153} INFO - Started process (PID=10698) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:54:51.461+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:54:51.468+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:54:51.467+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:54:53.495+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:54:53.478+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:54:53.500+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:54:53.804+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.355 seconds
[2023-07-26T20:55:24.414+0000] {processor.py:153} INFO - Started process (PID=10726) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:55:24.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:55:24.420+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:55:24.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:55:26.796+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:55:26.783+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:55:26.799+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:55:27.078+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.671 seconds
[2023-07-26T20:55:57.427+0000] {processor.py:153} INFO - Started process (PID=10746) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:55:57.429+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:55:57.431+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:55:57.431+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:55:58.977+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:55:58.956+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:55:59.004+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:55:59.262+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.843 seconds
[2023-07-26T20:56:30.022+0000] {processor.py:153} INFO - Started process (PID=10776) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:56:30.041+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:56:30.045+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:56:30.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:56:32.639+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:56:32.497+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:56:32.650+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:56:32.944+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.940 seconds
[2023-07-26T20:57:03.094+0000] {processor.py:153} INFO - Started process (PID=10803) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:57:03.096+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:57:03.099+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:57:03.098+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:57:05.481+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:57:05.319+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:57:05.596+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:57:06.115+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.030 seconds
[2023-07-26T20:57:36.450+0000] {processor.py:153} INFO - Started process (PID=10825) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:57:36.452+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:57:36.453+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:57:36.453+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:57:38.030+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:57:38.021+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:57:38.033+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:57:38.244+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.802 seconds
[2023-07-26T20:58:08.944+0000] {processor.py:153} INFO - Started process (PID=10856) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:58:08.959+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:58:08.964+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:58:08.964+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:58:11.735+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:58:11.716+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:58:11.738+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:58:11.886+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.968 seconds
[2023-07-26T20:58:42.246+0000] {processor.py:153} INFO - Started process (PID=10883) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:58:42.256+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:58:42.258+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:58:42.258+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:58:44.080+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:58:44.070+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:58:44.084+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:58:44.261+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.023 seconds
[2023-07-26T20:59:14.494+0000] {processor.py:153} INFO - Started process (PID=10903) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:59:14.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:59:14.533+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:59:14.533+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:59:16.434+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:59:16.405+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:59:16.437+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:59:16.666+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.180 seconds
[2023-07-26T20:59:47.179+0000] {processor.py:153} INFO - Started process (PID=10932) to work on /opt/airflow/dags/load_data.py
[2023-07-26T20:59:47.187+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T20:59:47.193+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:59:47.192+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T20:59:49.024+0000] {logging_mixin.py:137} INFO - [2023-07-26T20:59:49.015+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T20:59:49.028+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T20:59:49.150+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.986 seconds
[2023-07-26T21:00:19.379+0000] {processor.py:153} INFO - Started process (PID=10961) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:00:19.382+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:00:19.384+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:00:19.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:00:21.311+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:00:21.301+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:00:21.315+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:00:21.477+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.103 seconds
[2023-07-26T21:00:51.728+0000] {processor.py:153} INFO - Started process (PID=10990) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:00:51.731+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:00:51.744+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:00:51.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:00:55.086+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:00:55.077+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:00:55.091+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:00:55.341+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.640 seconds
[2023-07-26T21:01:27.800+0000] {processor.py:153} INFO - Started process (PID=11018) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:01:27.827+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:01:27.871+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:01:27.871+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:01:32.219+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:01:32.200+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:01:32.223+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:01:32.716+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.933 seconds
[2023-07-26T21:02:03.544+0000] {processor.py:153} INFO - Started process (PID=11049) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:02:03.551+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:02:03.558+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:02:03.558+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:02:07.934+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:02:07.921+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:02:07.941+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:02:08.206+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.676 seconds
[2023-07-26T21:02:38.397+0000] {processor.py:153} INFO - Started process (PID=11080) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:02:38.399+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:02:38.403+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:02:38.403+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:02:40.347+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:02:40.332+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:02:40.350+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:02:40.625+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.234 seconds
[2023-07-26T21:03:11.515+0000] {processor.py:153} INFO - Started process (PID=11102) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:03:11.525+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:03:11.531+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:03:11.531+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:03:15.115+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:03:14.855+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:03:15.130+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:03:15.444+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.951 seconds
[2023-07-26T21:03:45.684+0000] {processor.py:153} INFO - Started process (PID=11132) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:03:45.688+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:03:45.691+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:03:45.691+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:03:47.631+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:03:47.621+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:03:47.635+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:03:47.868+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.192 seconds
[2023-07-26T21:04:18.314+0000] {processor.py:153} INFO - Started process (PID=11164) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:04:18.328+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:04:18.337+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:04:18.336+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:04:20.885+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:04:20.838+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:04:20.889+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:04:21.184+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.883 seconds
[2023-07-26T21:04:51.369+0000] {processor.py:153} INFO - Started process (PID=11181) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:04:51.371+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:04:51.373+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:04:51.372+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:04:53.003+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:04:52.976+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:04:53.010+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:04:53.236+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.876 seconds
[2023-07-26T21:05:24.306+0000] {processor.py:153} INFO - Started process (PID=11210) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:05:24.310+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:05:24.313+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:05:24.312+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:05:26.945+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:05:26.900+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:05:26.950+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:05:27.208+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.910 seconds
[2023-07-26T21:05:57.335+0000] {processor.py:153} INFO - Started process (PID=11237) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:05:57.337+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:05:57.340+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:05:57.339+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:05:59.316+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:05:59.304+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:05:59.319+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:05:59.658+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.332 seconds
[2023-07-26T21:06:29.924+0000] {processor.py:153} INFO - Started process (PID=11260) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:06:29.926+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:06:29.929+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:06:29.928+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:06:31.675+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:06:31.664+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:06:31.679+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:06:31.957+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.041 seconds
[2023-07-26T21:07:02.681+0000] {processor.py:153} INFO - Started process (PID=11292) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:07:02.682+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:07:02.685+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:07:02.684+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:07:04.540+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:07:04.495+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:07:04.548+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:07:04.900+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.227 seconds
[2023-07-26T21:07:35.167+0000] {processor.py:153} INFO - Started process (PID=11321) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:07:35.184+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:07:35.187+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:07:35.187+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:07:37.226+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:07:37.200+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:07:37.233+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:07:37.335+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.178 seconds
[2023-07-26T21:08:07.742+0000] {processor.py:153} INFO - Started process (PID=11344) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:08:07.746+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:08:07.749+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:08:07.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:08:10.335+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:08:10.324+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:08:10.340+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:08:10.548+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.820 seconds
[2023-07-26T21:08:40.742+0000] {processor.py:153} INFO - Started process (PID=11374) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:08:40.745+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:08:40.748+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:08:40.747+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:08:43.652+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:08:43.599+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:08:43.667+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:08:43.838+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.118 seconds
[2023-07-26T21:09:14.264+0000] {processor.py:153} INFO - Started process (PID=11393) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:09:14.270+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:09:14.272+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:09:14.272+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:09:15.862+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:09:15.842+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:09:15.878+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:09:16.154+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.896 seconds
[2023-07-26T21:09:46.240+0000] {processor.py:153} INFO - Started process (PID=11424) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:09:46.243+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:09:46.244+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:09:46.244+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:09:48.052+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:09:48.042+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:09:48.056+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:09:48.330+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.096 seconds
[2023-07-26T21:10:18.842+0000] {processor.py:153} INFO - Started process (PID=11458) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:10:18.846+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:10:18.849+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:10:18.849+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:10:20.602+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:10:20.583+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:10:20.606+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:10:20.779+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.950 seconds
[2023-07-26T21:10:51.561+0000] {processor.py:153} INFO - Started process (PID=11484) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:10:51.565+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:10:51.569+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:10:51.568+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:10:53.222+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:10:53.212+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:10:53.226+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:10:53.478+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.927 seconds
[2023-07-26T21:11:23.666+0000] {processor.py:153} INFO - Started process (PID=11509) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:11:23.668+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:11:23.671+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:11:23.670+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:11:25.043+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:11:25.032+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:11:25.046+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:11:25.367+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.708 seconds
[2023-07-26T21:11:55.752+0000] {processor.py:153} INFO - Started process (PID=11541) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:11:55.761+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:11:55.764+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:11:55.764+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:11:57.454+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:11:57.445+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:11:57.458+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:11:57.623+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.882 seconds
[2023-07-26T21:12:27.713+0000] {processor.py:153} INFO - Started process (PID=11567) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:12:27.715+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:12:27.717+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:12:27.717+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:12:29.634+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:12:29.586+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:12:29.654+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:12:29.850+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.145 seconds
[2023-07-26T21:13:00.189+0000] {processor.py:153} INFO - Started process (PID=11593) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:13:00.192+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:13:00.203+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:13:00.194+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:13:02.164+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:13:02.154+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:13:02.167+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:13:02.348+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.176 seconds
[2023-07-26T21:13:32.684+0000] {processor.py:153} INFO - Started process (PID=11621) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:13:32.689+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:13:32.704+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:13:32.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:13:34.667+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:13:34.644+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:13:34.680+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:13:34.867+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.197 seconds
[2023-07-26T21:14:05.469+0000] {processor.py:153} INFO - Started process (PID=11643) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:14:05.471+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:14:05.473+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:14:05.473+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:14:07.553+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:14:07.534+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:14:07.556+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:14:07.852+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.399 seconds
[2023-07-26T21:14:38.745+0000] {processor.py:153} INFO - Started process (PID=11675) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:14:38.748+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:14:38.760+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:14:38.759+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:14:41.662+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:14:41.651+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:14:41.665+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:14:41.831+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.123 seconds
[2023-07-26T21:15:12.703+0000] {processor.py:153} INFO - Started process (PID=11704) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:15:12.711+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:15:12.713+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:15:12.713+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:15:15.043+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:15:15.027+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:15:15.101+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:15:15.264+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.569 seconds
[2023-07-26T21:15:45.513+0000] {processor.py:153} INFO - Started process (PID=11726) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:15:45.515+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:15:45.516+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:15:45.516+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:15:47.280+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:15:47.261+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:15:47.283+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:15:47.456+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.949 seconds
[2023-07-26T21:16:17.954+0000] {processor.py:153} INFO - Started process (PID=11758) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:16:17.956+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:16:17.958+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:16:17.958+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:16:20.448+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:16:20.435+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:16:20.452+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:16:20.599+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.657 seconds
[2023-07-26T21:16:51.412+0000] {processor.py:153} INFO - Started process (PID=11783) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:16:51.414+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:16:51.416+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:16:51.416+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:16:53.229+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:16:53.215+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:16:53.232+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:16:53.379+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.977 seconds
[2023-07-26T21:17:23.815+0000] {processor.py:153} INFO - Started process (PID=11808) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:17:23.822+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:17:23.824+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:17:23.823+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:17:25.399+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:17:25.383+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:17:25.405+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:17:25.648+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.839 seconds
[2023-07-26T21:17:56.008+0000] {processor.py:153} INFO - Started process (PID=11841) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:17:56.039+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:17:56.055+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:17:56.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:17:59.542+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:17:59.501+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:17:59.586+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:17:59.925+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.925 seconds
[2023-07-26T21:18:30.459+0000] {processor.py:153} INFO - Started process (PID=11860) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:18:30.467+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:18:30.475+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:18:30.475+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:18:32.183+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:18:32.171+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:18:32.186+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:18:32.359+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.911 seconds
[2023-07-26T21:19:03.598+0000] {processor.py:153} INFO - Started process (PID=11893) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:19:03.608+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:19:03.614+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:19:03.614+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:19:09.075+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:19:08.874+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:19:09.105+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:19:09.395+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.816 seconds
[2023-07-26T21:19:40.138+0000] {processor.py:153} INFO - Started process (PID=11927) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:19:40.151+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:19:40.155+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:19:40.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:19:43.805+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:19:43.792+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:19:43.810+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:19:44.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.879 seconds
[2023-07-26T21:20:14.439+0000] {processor.py:153} INFO - Started process (PID=11948) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:20:14.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:20:14.444+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:20:14.444+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:20:17.073+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:20:17.040+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:20:17.091+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:20:18.101+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.669 seconds
[2023-07-26T21:20:48.300+0000] {processor.py:153} INFO - Started process (PID=11980) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:20:48.302+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:20:48.305+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:20:48.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:20:49.830+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:20:49.820+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:20:49.834+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:20:50.097+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.803 seconds
[2023-07-26T21:21:20.483+0000] {processor.py:153} INFO - Started process (PID=12008) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:21:20.486+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:21:20.488+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:21:20.488+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:21:22.363+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:21:22.349+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:21:22.370+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:21:22.667+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.191 seconds
[2023-07-26T21:21:52.839+0000] {processor.py:153} INFO - Started process (PID=12030) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:21:52.842+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:21:52.844+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:21:52.843+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:21:54.418+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:21:54.406+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:21:54.422+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:21:54.570+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.737 seconds
[2023-07-26T21:22:24.931+0000] {processor.py:153} INFO - Started process (PID=12062) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:22:24.933+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:22:24.936+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:22:24.935+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:22:26.378+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:22:26.359+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:22:26.381+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:22:26.592+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.668 seconds
[2023-07-26T21:22:56.749+0000] {processor.py:153} INFO - Started process (PID=12094) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:22:56.751+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:22:56.753+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:22:56.753+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:22:58.545+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:22:58.536+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:22:58.549+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:22:58.696+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.954 seconds
[2023-07-26T21:23:29.544+0000] {processor.py:153} INFO - Started process (PID=12126) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:23:29.549+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:23:29.551+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:23:29.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:23:31.008+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:23:30.999+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:23:31.011+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:23:31.156+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.618 seconds
[2023-07-26T21:24:01.656+0000] {processor.py:153} INFO - Started process (PID=12154) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:24:01.661+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:24:01.664+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:24:01.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:24:03.548+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:24:03.534+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:24:03.553+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:24:03.741+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.093 seconds
[2023-07-26T21:24:33.961+0000] {processor.py:153} INFO - Started process (PID=12175) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:24:33.965+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:24:33.967+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:24:33.967+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:24:35.361+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:24:35.326+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:24:35.368+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:24:35.466+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.513 seconds
[2023-07-26T21:25:06.857+0000] {processor.py:153} INFO - Started process (PID=12207) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:25:06.860+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:25:06.905+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:25:06.904+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:25:10.794+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:25:10.734+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:25:10.853+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:25:11.529+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.690 seconds
[2023-07-26T21:25:41.717+0000] {processor.py:153} INFO - Started process (PID=12239) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:25:41.719+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:25:41.721+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:25:41.721+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:25:43.122+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:25:43.106+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:25:43.128+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:25:43.258+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.548 seconds
[2023-07-26T21:26:14.229+0000] {processor.py:153} INFO - Started process (PID=12271) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:26:14.237+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:26:14.241+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:26:14.240+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:26:16.388+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:26:16.367+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:26:16.391+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:26:16.559+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.338 seconds
[2023-07-26T21:26:47.452+0000] {processor.py:153} INFO - Started process (PID=12300) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:26:47.456+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:26:47.476+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:26:47.476+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:26:49.368+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:26:49.357+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:26:49.372+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:26:49.738+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.306 seconds
[2023-07-26T21:27:20.025+0000] {processor.py:153} INFO - Started process (PID=12323) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:27:20.028+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:27:20.030+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:27:20.030+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:27:21.644+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:27:21.632+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:27:21.651+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:27:21.916+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.899 seconds
[2023-07-26T21:27:52.643+0000] {processor.py:153} INFO - Started process (PID=12355) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:27:52.646+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:27:52.648+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:27:52.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:27:54.142+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:27:54.131+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:27:54.147+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:27:54.284+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.646 seconds
[2023-07-26T21:28:24.652+0000] {processor.py:153} INFO - Started process (PID=12384) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:28:24.654+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:28:24.660+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:28:24.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:28:26.611+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:28:26.602+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:28:26.615+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:28:26.763+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.118 seconds
[2023-07-26T21:28:57.237+0000] {processor.py:153} INFO - Started process (PID=12414) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:28:57.239+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:28:57.241+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:28:57.241+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:28:59.341+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:28:59.319+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:28:59.345+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:28:59.709+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.501 seconds
[2023-07-26T21:29:29.951+0000] {processor.py:153} INFO - Started process (PID=12440) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:29:29.954+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:29:29.956+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:29:29.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:29:31.831+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:29:31.822+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:29:31.834+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:29:31.944+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.000 seconds
[2023-07-26T21:30:02.308+0000] {processor.py:153} INFO - Started process (PID=12471) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:30:02.310+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:30:02.313+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:30:02.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:30:04.275+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:30:04.249+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:30:04.279+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:30:04.595+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.298 seconds
[2023-07-26T21:30:35.177+0000] {processor.py:153} INFO - Started process (PID=12505) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:30:35.180+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:30:35.182+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:30:35.182+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:30:37.243+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:30:37.232+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:30:37.247+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:30:37.394+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.234 seconds
[2023-07-26T21:31:08.231+0000] {processor.py:153} INFO - Started process (PID=12537) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:31:08.234+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:31:08.239+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:31:08.239+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:31:12.361+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:31:12.282+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:31:12.377+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:31:12.830+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.620 seconds
[2023-07-26T21:31:43.367+0000] {processor.py:153} INFO - Started process (PID=12570) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:31:43.370+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:31:43.375+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:31:43.372+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:31:45.153+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:31:45.141+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:31:45.156+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:31:45.350+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.997 seconds
[2023-07-26T21:32:16.031+0000] {processor.py:153} INFO - Started process (PID=12601) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:32:16.034+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:32:16.038+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:32:16.038+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:32:17.758+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:32:17.689+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 108, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
  File "/opt/airflow/dags/load_data.py", line 60, in extract_relevant_records_from_overall_data
    for i in range(len(data['data'])):
KeyError: 'data'
[2023-07-26T21:32:17.767+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:32:18.348+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.339 seconds
[2023-07-26T21:32:39.855+0000] {processor.py:153} INFO - Started process (PID=12616) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:32:39.869+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:32:39.874+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:32:39.874+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:32:43.520+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:32:43.538+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:32:43.521+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:32:43.541+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:32:43.931+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.090 seconds
[2023-07-26T21:33:02.796+0000] {processor.py:153} INFO - Started process (PID=12635) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:33:02.798+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:33:02.811+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:33:02.811+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:33:05.621+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:33:05.660+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:33:05.630+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:33:05.674+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:33:05.924+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.142 seconds
[2023-07-26T21:33:36.428+0000] {processor.py:153} INFO - Started process (PID=12666) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:33:36.431+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:33:36.433+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:33:36.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:33:52.214+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:33:52.226+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:33:52.215+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:33:52.231+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:33:52.444+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 16.023 seconds
[2023-07-26T21:34:22.682+0000] {processor.py:153} INFO - Started process (PID=12714) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:34:22.685+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:34:22.686+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:34:22.686+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:34:24.967+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:34:24.979+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:34:24.968+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:34:24.984+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:34:25.245+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.572 seconds
[2023-07-26T21:34:55.511+0000] {processor.py:153} INFO - Started process (PID=12744) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:34:55.513+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:34:55.516+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:34:55.516+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:34:58.535+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:34:58.561+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:34:58.538+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:34:58.571+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:34:58.754+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.252 seconds
[2023-07-26T21:35:29.222+0000] {processor.py:153} INFO - Started process (PID=12766) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:35:29.224+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:35:29.225+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:35:29.225+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:35:30.747+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:35:30.761+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:35:30.748+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:35:30.764+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:35:30.947+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.733 seconds
[2023-07-26T21:36:01.431+0000] {processor.py:153} INFO - Started process (PID=12797) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:36:01.434+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:36:01.436+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:36:01.435+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:36:03.778+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:36:03.789+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:36:03.779+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:36:03.792+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:36:04.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.663 seconds
[2023-07-26T21:36:34.726+0000] {processor.py:153} INFO - Started process (PID=12828) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:36:34.732+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:36:34.741+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:36:34.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:36:38.220+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:36:38.238+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:36:38.221+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:36:38.244+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:36:38.395+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.676 seconds
[2023-07-26T21:37:09.144+0000] {processor.py:153} INFO - Started process (PID=12857) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:37:09.163+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:37:09.177+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:37:09.176+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:37:11.624+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:37:11.688+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:37:11.640+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:37:11.712+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:37:15.313+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.188 seconds
[2023-07-26T21:37:46.217+0000] {processor.py:153} INFO - Started process (PID=12890) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:37:46.219+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:37:46.222+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:37:46.221+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:37:47.893+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:37:48.023+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:37:47.911+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:37:48.035+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:37:48.263+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.055 seconds
[2023-07-26T21:38:19.160+0000] {processor.py:153} INFO - Started process (PID=12912) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:38:19.180+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:38:19.182+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:38:19.182+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:38:22.119+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:38:22.131+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:38:22.120+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:38:22.134+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:38:22.406+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.279 seconds
[2023-07-26T21:38:52.799+0000] {processor.py:153} INFO - Started process (PID=12946) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:38:52.803+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:38:52.806+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:38:52.806+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:38:56.594+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:38:56.639+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:38:56.595+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:38:56.662+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:38:57.091+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.301 seconds
[2023-07-26T21:39:27.376+0000] {processor.py:153} INFO - Started process (PID=12978) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:39:27.379+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:39:27.381+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:39:27.380+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:39:29.356+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:39:29.368+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:39:29.358+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:39:29.372+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:39:29.619+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.251 seconds
[2023-07-26T21:40:00.314+0000] {processor.py:153} INFO - Started process (PID=13000) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:40:00.332+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:40:00.335+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:40:00.334+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:40:02.588+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:40:02.601+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:40:02.590+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:40:02.605+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:40:02.810+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.510 seconds
[2023-07-26T21:40:33.017+0000] {processor.py:153} INFO - Started process (PID=13031) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:40:33.020+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:40:33.022+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:40:33.022+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:40:34.943+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:40:34.952+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:40:34.944+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:40:34.956+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:40:35.304+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.308 seconds
[2023-07-26T21:41:05.532+0000] {processor.py:153} INFO - Started process (PID=13061) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:41:05.535+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:41:05.538+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:41:05.537+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:41:08.491+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:41:08.532+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:41:08.493+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:41:08.544+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:41:08.783+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.266 seconds
[2023-07-26T21:41:39.168+0000] {processor.py:153} INFO - Started process (PID=13088) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:41:39.170+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:41:39.173+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:41:39.172+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:41:40.907+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:41:40.920+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:41:40.909+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:41:40.928+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:41:41.131+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.973 seconds
[2023-07-26T21:42:11.495+0000] {processor.py:153} INFO - Started process (PID=13112) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:42:11.498+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:42:11.501+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:42:11.500+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:42:13.484+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:42:13.503+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:42:13.490+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:42:13.511+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:42:13.642+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.161 seconds
[2023-07-26T21:42:43.732+0000] {processor.py:153} INFO - Started process (PID=13144) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:42:43.734+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:42:43.736+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:42:43.736+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:42:45.449+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:42:45.460+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:42:45.450+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:42:45.462+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:42:45.689+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.963 seconds
[2023-07-26T21:43:15.804+0000] {processor.py:153} INFO - Started process (PID=13175) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:43:15.809+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:43:15.812+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:43:15.811+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:43:17.632+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:43:17.644+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:43:17.634+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:43:17.649+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:43:17.878+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.084 seconds
[2023-07-26T21:43:48.003+0000] {processor.py:153} INFO - Started process (PID=13206) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:43:48.005+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:43:48.007+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:43:48.007+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:43:49.687+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:43:49.711+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:43:49.689+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:43:49.714+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:43:49.942+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.946 seconds
[2023-07-26T21:44:20.828+0000] {processor.py:153} INFO - Started process (PID=13238) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:44:20.830+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:44:20.832+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:44:20.831+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:44:22.747+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:44:22.760+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:44:22.749+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:44:22.765+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:44:22.867+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.044 seconds
[2023-07-26T21:44:53.123+0000] {processor.py:153} INFO - Started process (PID=13266) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:44:53.127+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:44:53.128+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:44:53.128+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:44:54.801+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:44:54.814+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:44:54.803+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:44:54.817+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:44:54.970+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.855 seconds
[2023-07-26T21:45:25.061+0000] {processor.py:153} INFO - Started process (PID=13288) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:45:25.063+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:45:25.065+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:45:25.065+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:45:27.043+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:45:27.058+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:45:27.045+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:45:27.061+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:45:27.172+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.119 seconds
[2023-07-26T21:45:57.801+0000] {processor.py:153} INFO - Started process (PID=13319) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:45:57.803+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:45:57.807+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:45:57.807+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:45:59.487+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:45:59.498+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:45:59.488+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:45:59.502+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:45:59.598+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.804 seconds
[2023-07-26T21:46:29.848+0000] {processor.py:153} INFO - Started process (PID=13350) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:46:29.850+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:46:29.852+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:46:29.852+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:46:31.819+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:46:31.889+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:46:31.835+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:46:31.911+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:46:32.459+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.618 seconds
[2023-07-26T21:47:03.094+0000] {processor.py:153} INFO - Started process (PID=13378) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:47:03.097+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:47:03.100+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:47:03.099+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:47:05.920+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:47:05.940+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:47:05.922+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:47:05.944+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:47:06.172+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.092 seconds
[2023-07-26T21:47:36.936+0000] {processor.py:153} INFO - Started process (PID=13400) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:47:36.939+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:47:36.941+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:47:36.940+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:47:38.538+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:47:38.550+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:47:38.539+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:47:38.553+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:47:38.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.888 seconds
[2023-07-26T21:48:09.819+0000] {processor.py:153} INFO - Started process (PID=13431) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:48:09.829+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:48:09.831+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:48:09.831+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:48:12.195+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:48:12.230+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:48:12.213+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:48:12.237+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:48:12.586+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.776 seconds
[2023-07-26T21:48:43.594+0000] {processor.py:153} INFO - Started process (PID=13464) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:48:43.597+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:48:43.600+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:48:43.599+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:48:46.642+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:48:46.772+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:48:46.660+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:48:46.798+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:48:47.067+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.496 seconds
[2023-07-26T21:49:17.558+0000] {processor.py:153} INFO - Started process (PID=13484) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:49:17.565+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:49:17.568+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:49:17.568+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:49:20.526+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:49:20.673+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:49:20.542+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:49:20.679+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:49:20.981+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.431 seconds
[2023-07-26T21:49:51.552+0000] {processor.py:153} INFO - Started process (PID=13513) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:49:51.555+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:49:51.557+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:49:51.557+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:49:54.206+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:49:54.222+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:49:54.207+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:49:54.226+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:49:54.488+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.949 seconds
[2023-07-26T21:50:24.998+0000] {processor.py:153} INFO - Started process (PID=13541) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:50:25.007+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:50:25.013+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:50:25.012+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:50:27.816+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:50:27.828+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:50:27.818+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:50:27.833+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:50:27.962+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.001 seconds
[2023-07-26T21:50:58.713+0000] {processor.py:153} INFO - Started process (PID=13566) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:50:58.720+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:50:58.728+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:50:58.728+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:51:00.818+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:51:00.903+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:51:00.833+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:51:00.914+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:51:01.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.393 seconds
[2023-07-26T21:51:31.867+0000] {processor.py:153} INFO - Started process (PID=13600) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:51:31.875+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:51:31.879+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:51:31.878+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:51:34.246+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:51:34.259+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:51:34.247+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:51:34.262+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:51:34.416+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.562 seconds
[2023-07-26T21:52:04.552+0000] {processor.py:153} INFO - Started process (PID=13632) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:52:04.555+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:52:04.557+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:52:04.557+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:52:06.513+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:52:06.526+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:52:06.515+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:52:06.531+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:52:06.897+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.359 seconds
[2023-07-26T21:52:37.521+0000] {processor.py:153} INFO - Started process (PID=13663) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:52:37.523+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:52:37.526+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:52:37.525+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:52:39.102+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:52:39.114+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:52:39.104+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:52:39.118+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:52:39.322+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.810 seconds
[2023-07-26T21:53:10.248+0000] {processor.py:153} INFO - Started process (PID=13692) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:53:10.250+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:53:10.253+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:53:10.253+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:53:12.880+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:53:12.912+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:53:12.899+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:53:12.916+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:53:13.022+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.790 seconds
[2023-07-26T21:53:43.177+0000] {processor.py:153} INFO - Started process (PID=13715) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:53:43.179+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:53:43.182+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:53:43.181+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:53:44.781+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:53:44.812+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:53:44.789+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:53:44.828+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:53:44.984+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.815 seconds
[2023-07-26T21:54:16.517+0000] {processor.py:153} INFO - Started process (PID=13745) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:54:16.540+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:54:16.543+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:54:16.543+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:54:19.682+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:54:19.714+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:54:19.695+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:54:19.724+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:54:19.987+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.473 seconds
[2023-07-26T21:54:50.702+0000] {processor.py:153} INFO - Started process (PID=13776) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:54:50.709+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:54:50.715+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:54:50.714+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:54:53.461+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:54:53.481+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:54:53.466+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:54:53.491+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:54:53.615+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.920 seconds
[2023-07-26T21:55:24.119+0000] {processor.py:153} INFO - Started process (PID=13796) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:55:24.121+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:55:24.124+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:55:24.123+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:55:25.802+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:55:25.939+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:55:25.843+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:55:25.946+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:55:26.137+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.027 seconds
[2023-07-26T21:55:56.246+0000] {processor.py:153} INFO - Started process (PID=13827) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:55:56.249+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:55:56.251+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:55:56.251+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:55:57.757+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:55:57.846+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:55:57.798+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:55:57.850+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:55:57.962+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.727 seconds
[2023-07-26T21:56:28.655+0000] {processor.py:153} INFO - Started process (PID=13852) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:56:28.667+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:56:28.671+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:56:28.670+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:56:32.417+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:56:32.506+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:56:32.438+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:56:32.512+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:56:32.766+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.119 seconds
[2023-07-26T21:57:03.002+0000] {processor.py:153} INFO - Started process (PID=13878) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:57:03.005+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:57:03.006+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:57:03.006+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:57:05.600+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:57:05.627+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:57:05.613+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:57:05.630+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:57:06.326+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.335 seconds
[2023-07-26T21:57:37.247+0000] {processor.py:153} INFO - Started process (PID=13911) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:57:37.250+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:57:37.254+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:57:37.254+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:57:39.424+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:57:39.440+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:57:39.425+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:57:39.448+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:57:39.567+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.353 seconds
[2023-07-26T21:58:12.225+0000] {processor.py:153} INFO - Started process (PID=13940) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:58:12.242+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:58:12.256+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:58:12.256+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:58:17.472+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:58:17.971+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:58:17.536+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:58:18.147+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:58:20.389+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.284 seconds
[2023-07-26T21:58:50.612+0000] {processor.py:153} INFO - Started process (PID=13961) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:58:50.614+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:58:50.617+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:58:50.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:58:52.091+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:58:52.103+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:58:52.092+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:58:52.108+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:58:52.334+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.732 seconds
[2023-07-26T21:59:22.620+0000] {processor.py:153} INFO - Started process (PID=13994) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:59:22.625+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:59:22.628+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:59:22.628+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:59:24.452+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:59:24.465+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:59:24.453+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:59:24.468+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:59:24.669+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.057 seconds
[2023-07-26T21:59:55.037+0000] {processor.py:153} INFO - Started process (PID=14025) to work on /opt/airflow/dags/load_data.py
[2023-07-26T21:59:55.040+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T21:59:55.043+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:59:55.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T21:59:57.330+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T21:59:57.346+0000] {logging_mixin.py:137} INFO - [2023-07-26T21:59:57.335+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T21:59:57.353+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T21:59:57.589+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.568 seconds
[2023-07-26T22:00:27.903+0000] {processor.py:153} INFO - Started process (PID=14044) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:00:27.905+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:00:27.909+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:00:27.908+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:00:29.297+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:00:29.316+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:00:29.298+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:00:29.320+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:00:29.451+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.555 seconds
[2023-07-26T22:01:00.141+0000] {processor.py:153} INFO - Started process (PID=14076) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:01:00.143+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:01:00.153+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:01:00.153+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:01:02.889+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:01:02.923+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:01:02.891+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:01:02.927+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:01:03.231+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.105 seconds
[2023-07-26T22:01:33.426+0000] {processor.py:153} INFO - Started process (PID=14108) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:01:33.430+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:01:33.432+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:01:33.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:01:35.385+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:01:35.408+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:01:35.386+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:01:35.419+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:01:35.576+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.161 seconds
[2023-07-26T22:02:06.016+0000] {processor.py:153} INFO - Started process (PID=14138) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:02:06.018+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:02:06.022+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:02:06.022+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:02:08.695+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:02:08.798+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:02:08.712+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:02:08.863+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:02:09.251+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.244 seconds
[2023-07-26T22:02:40.292+0000] {processor.py:153} INFO - Started process (PID=14161) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:02:40.294+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:02:40.296+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:02:40.296+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:02:41.694+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:02:41.703+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:02:41.695+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:02:41.706+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:02:41.816+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.532 seconds
[2023-07-26T22:03:12.283+0000] {processor.py:153} INFO - Started process (PID=14193) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:03:12.285+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:03:12.301+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:03:12.300+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:03:14.798+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:03:14.826+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:03:14.799+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:03:14.832+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:03:15.088+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.836 seconds
[2023-07-26T22:03:45.761+0000] {processor.py:153} INFO - Started process (PID=14222) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:03:45.766+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:03:45.769+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:03:45.769+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:03:48.517+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:03:48.554+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:03:48.519+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:03:48.564+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:03:48.718+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.983 seconds
[2023-07-26T22:04:19.239+0000] {processor.py:153} INFO - Started process (PID=14244) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:04:19.241+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:04:19.244+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:04:19.243+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:04:22.231+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:04:22.275+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:04:22.246+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:04:22.292+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:04:22.586+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.360 seconds
[2023-07-26T22:04:52.851+0000] {processor.py:153} INFO - Started process (PID=14276) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:04:52.875+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:04:52.878+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:04:52.877+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:04:55.309+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:04:55.328+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:04:55.313+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:04:55.334+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:04:55.463+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.623 seconds
[2023-07-26T22:05:26.412+0000] {processor.py:153} INFO - Started process (PID=14296) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:05:26.417+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:05:26.424+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:05:26.423+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:05:28.352+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:05:28.372+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:05:28.356+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:05:28.376+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:05:28.562+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.161 seconds
[2023-07-26T22:05:59.335+0000] {processor.py:153} INFO - Started process (PID=14329) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:05:59.337+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:05:59.339+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:05:59.339+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:06:01.119+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:06:01.150+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:06:01.127+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:06:01.190+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:06:02.055+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.728 seconds
[2023-07-26T22:06:32.340+0000] {processor.py:153} INFO - Started process (PID=14358) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:06:32.343+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:06:32.347+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:06:32.346+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:06:34.966+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:06:35.030+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:06:34.983+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:06:35.037+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:06:35.256+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.926 seconds
[2023-07-26T22:07:05.499+0000] {processor.py:153} INFO - Started process (PID=14381) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:07:05.501+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:07:05.505+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:07:05.504+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:07:07.232+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:07:07.245+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:07:07.234+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:07:07.249+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:07:07.490+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.997 seconds
[2023-07-26T22:07:37.780+0000] {processor.py:153} INFO - Started process (PID=14413) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:07:37.787+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:07:37.805+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:07:37.805+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:07:39.570+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:07:39.607+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:07:39.574+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:07:39.622+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:07:40.156+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.391 seconds
[2023-07-26T22:08:11.029+0000] {processor.py:153} INFO - Started process (PID=14433) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:08:11.052+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:08:11.067+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:08:11.066+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:08:14.783+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:08:14.851+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:08:14.791+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:08:14.890+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:08:15.037+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.025 seconds
[2023-07-26T22:08:45.466+0000] {processor.py:153} INFO - Started process (PID=14464) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:08:45.469+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:08:45.472+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:08:45.471+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:08:46.885+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:08:46.899+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:08:46.889+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:08:46.904+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:08:47.016+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.560 seconds
[2023-07-26T22:09:17.528+0000] {processor.py:153} INFO - Started process (PID=14495) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:09:17.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:09:17.535+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:09:17.534+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:09:19.315+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:09:19.327+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:09:19.316+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:09:19.330+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:09:19.491+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.967 seconds
[2023-07-26T22:09:50.039+0000] {processor.py:153} INFO - Started process (PID=14515) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:09:50.042+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:09:50.045+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:09:50.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:09:51.609+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:09:51.626+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:09:51.611+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:09:51.630+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:09:51.869+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.837 seconds
[2023-07-26T22:10:22.127+0000] {processor.py:153} INFO - Started process (PID=14546) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:10:22.128+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:10:22.131+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:10:22.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:10:23.718+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:10:23.733+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:10:23.720+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:10:23.740+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:10:23.954+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.835 seconds
[2023-07-26T22:10:54.589+0000] {processor.py:153} INFO - Started process (PID=14574) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:10:54.633+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:10:54.637+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:10:54.636+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:10:56.768+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:10:56.799+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:10:56.772+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:10:56.806+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:10:57.151+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.603 seconds
[2023-07-26T22:11:27.726+0000] {processor.py:153} INFO - Started process (PID=14597) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:11:27.731+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:11:27.735+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:11:27.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:11:29.059+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:11:29.071+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:11:29.061+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:11:29.074+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:11:29.261+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.541 seconds
[2023-07-26T22:11:59.502+0000] {processor.py:153} INFO - Started process (PID=14627) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:11:59.504+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:11:59.506+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:11:59.506+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:12:01.678+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:12:01.694+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:12:01.680+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:12:01.698+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:12:01.955+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.461 seconds
[2023-07-26T22:12:32.139+0000] {processor.py:153} INFO - Started process (PID=14646) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:12:32.142+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:12:32.144+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:12:32.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:12:34.354+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:12:34.371+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:12:34.356+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:12:34.375+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:12:34.514+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.384 seconds
[2023-07-26T22:13:04.921+0000] {processor.py:153} INFO - Started process (PID=14678) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:13:04.928+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:13:04.930+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:13:04.930+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:13:07.214+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:13:07.232+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:13:07.219+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:13:07.237+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:13:08.100+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.189 seconds
[2023-07-26T22:13:38.647+0000] {processor.py:153} INFO - Started process (PID=14711) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:13:38.649+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:13:38.652+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:13:38.651+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:13:40.826+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:13:40.838+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:13:40.827+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:13:40.845+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:13:40.980+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.341 seconds
[2023-07-26T22:14:11.292+0000] {processor.py:153} INFO - Started process (PID=14739) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:14:11.306+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:14:11.317+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:14:11.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:14:15.067+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:14:15.209+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:14:15.080+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:14:15.225+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:14:15.605+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.336 seconds
[2023-07-26T22:14:46.137+0000] {processor.py:153} INFO - Started process (PID=14761) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:14:46.139+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:14:46.142+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:14:46.141+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:14:47.696+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:14:47.706+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:14:47.697+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:14:47.709+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:14:47.900+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.774 seconds
[2023-07-26T22:15:18.111+0000] {processor.py:153} INFO - Started process (PID=14793) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:15:18.113+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:15:18.115+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:15:18.115+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:15:19.516+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:15:19.529+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:15:19.519+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:15:19.532+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:15:19.820+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.717 seconds
[2023-07-26T22:15:50.357+0000] {processor.py:153} INFO - Started process (PID=14824) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:15:50.367+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:15:50.376+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:15:50.371+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:15:52.750+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:15:52.835+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:15:52.757+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:15:52.839+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:15:53.048+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.761 seconds
[2023-07-26T22:16:23.321+0000] {processor.py:153} INFO - Started process (PID=14844) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:16:23.327+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:16:23.329+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:16:23.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:16:24.968+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:16:25.109+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:16:25.097+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:16:25.114+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:16:25.465+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.152 seconds
[2023-07-26T22:16:55.585+0000] {processor.py:153} INFO - Started process (PID=14876) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:16:55.591+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:16:55.594+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:16:55.593+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:16:57.555+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:16:57.569+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:16:57.556+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:16:57.574+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:16:57.707+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.131 seconds
[2023-07-26T22:17:28.124+0000] {processor.py:153} INFO - Started process (PID=14895) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:17:28.126+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:17:28.132+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:17:28.131+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:17:30.180+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:17:30.212+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:17:30.191+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:17:30.223+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:17:30.505+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.395 seconds
[2023-07-26T22:18:00.785+0000] {processor.py:153} INFO - Started process (PID=14926) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:18:00.801+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:18:00.804+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:18:00.803+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:18:02.499+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:18:02.514+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:18:02.500+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:18:02.517+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:18:02.695+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.923 seconds
[2023-07-26T22:18:33.044+0000] {processor.py:153} INFO - Started process (PID=14957) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:18:33.047+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:18:33.050+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:18:33.050+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:18:34.998+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:18:35.014+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:18:35.003+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:18:35.021+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:18:35.174+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.140 seconds
[2023-07-26T22:19:06.355+0000] {processor.py:153} INFO - Started process (PID=14984) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:19:06.373+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:19:06.376+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:19:06.375+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:19:09.250+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:19:09.308+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:19:09.262+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:19:09.313+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:19:09.682+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.346 seconds
[2023-07-26T22:19:40.436+0000] {processor.py:153} INFO - Started process (PID=15008) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:19:40.449+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:19:40.451+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:19:40.451+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:19:42.664+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:19:42.677+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:19:42.666+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:19:42.681+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:19:42.937+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.504 seconds
[2023-07-26T22:20:13.578+0000] {processor.py:153} INFO - Started process (PID=15038) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:20:13.579+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:20:13.583+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:20:13.583+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:20:16.238+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:20:16.268+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:20:16.239+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:20:16.284+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:20:16.508+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.952 seconds
[2023-07-26T22:20:46.866+0000] {processor.py:153} INFO - Started process (PID=15069) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:20:46.879+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:20:46.881+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:20:46.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:20:49.122+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:20:49.133+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:20:49.123+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:20:49.138+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:20:49.504+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.660 seconds
[2023-07-26T22:21:19.686+0000] {processor.py:153} INFO - Started process (PID=15088) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:21:19.691+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:21:19.695+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:21:19.695+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:21:21.419+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:21:21.436+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:21:21.420+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:21:21.441+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:21:21.619+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.943 seconds
[2023-07-26T22:21:51.772+0000] {processor.py:153} INFO - Started process (PID=15120) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:21:51.774+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:21:51.776+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:21:51.776+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:21:53.259+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:21:53.272+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:21:53.260+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:21:53.277+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:21:53.392+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.628 seconds
[2023-07-26T22:22:23.762+0000] {processor.py:153} INFO - Started process (PID=15145) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:22:23.775+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:22:23.778+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:22:23.778+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:22:26.604+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:22:26.633+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:22:26.609+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:22:26.637+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:22:26.805+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.069 seconds
[2023-07-26T22:22:57.067+0000] {processor.py:153} INFO - Started process (PID=15169) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:22:57.070+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:22:57.072+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:22:57.072+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:22:58.548+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:22:58.564+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:22:58.549+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:22:58.572+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:22:58.787+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.728 seconds
[2023-07-26T22:23:29.340+0000] {processor.py:153} INFO - Started process (PID=15197) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:23:29.344+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:23:29.357+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:23:29.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:23:32.733+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:23:32.753+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:23:32.738+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:23:32.757+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:23:33.041+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.724 seconds
[2023-07-26T22:24:03.685+0000] {processor.py:153} INFO - Started process (PID=15220) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:24:03.688+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:24:03.691+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:24:03.691+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:24:07.306+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:24:07.454+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:24:07.311+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:24:07.459+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:24:07.654+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.994 seconds
[2023-07-26T22:24:38.598+0000] {processor.py:153} INFO - Started process (PID=15253) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:24:38.613+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:24:38.616+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:24:38.615+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:24:40.777+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:24:40.794+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:24:40.781+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:24:40.803+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:24:40.921+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.340 seconds
[2023-07-26T22:24:52.153+0000] {processor.py:153} INFO - Started process (PID=15269) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:24:52.155+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:24:52.158+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:24:52.157+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:24:53.807+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:24:53.822+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:24:53.810+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:24:53.826+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:24:54.010+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.876 seconds
[2023-07-26T22:25:24.424+0000] {processor.py:153} INFO - Started process (PID=15295) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:25:24.427+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:25:24.430+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:25:24.430+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:25:26.673+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:25:26.689+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:25:26.675+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:25:26.695+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:25:26.929+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.520 seconds
[2023-07-26T22:25:34.622+0000] {processor.py:153} INFO - Started process (PID=15302) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:25:34.625+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:25:34.631+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:25:34.630+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:25:37.193+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:25:37.569+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:25:37.235+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 111, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:25:37.586+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:25:37.802+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.195 seconds
[2023-07-26T22:26:08.387+0000] {processor.py:153} INFO - Started process (PID=15331) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:26:08.421+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:26:08.469+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:26:08.469+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:26:12.419+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:26:12.478+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:26:12.425+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:26:12.493+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:26:13.538+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.183 seconds
[2023-07-26T22:26:44.786+0000] {processor.py:153} INFO - Started process (PID=15361) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:26:44.788+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:26:44.790+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:26:44.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:26:46.960+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:26:47.000+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:26:46.961+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:26:47.008+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:26:47.209+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.431 seconds
[2023-07-26T22:27:17.352+0000] {processor.py:153} INFO - Started process (PID=15386) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:27:17.355+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:27:17.357+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:27:17.357+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:27:18.967+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:27:18.976+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:27:18.967+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:27:18.979+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:27:19.063+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.718 seconds
[2023-07-26T22:27:49.608+0000] {processor.py:153} INFO - Started process (PID=15420) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:27:49.610+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:27:49.612+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:27:49.612+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:27:50.963+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:27:50.971+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:27:50.964+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:27:50.974+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:27:51.117+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.516 seconds
[2023-07-26T22:28:21.331+0000] {processor.py:153} INFO - Started process (PID=15452) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:28:21.333+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:28:21.336+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:28:21.336+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:28:22.665+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:28:22.677+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:28:22.666+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:28:22.680+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:28:22.853+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.527 seconds
[2023-07-26T22:28:53.297+0000] {processor.py:153} INFO - Started process (PID=15483) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:28:53.298+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:28:53.300+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:28:53.300+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:28:54.845+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:28:54.857+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:28:54.847+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:28:54.861+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:28:54.978+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.688 seconds
[2023-07-26T22:29:25.535+0000] {processor.py:153} INFO - Started process (PID=15514) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:29:25.537+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:29:25.539+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:29:25.539+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:29:26.835+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:29:26.846+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:29:26.836+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:29:26.849+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:29:27.131+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.602 seconds
[2023-07-26T22:29:57.579+0000] {processor.py:153} INFO - Started process (PID=15546) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:29:57.581+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:29:57.582+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:29:57.582+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:29:59.290+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:29:59.301+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:29:59.291+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:29:59.304+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:29:59.411+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.838 seconds
[2023-07-26T22:30:29.737+0000] {processor.py:153} INFO - Started process (PID=15580) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:30:29.739+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:30:29.741+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:30:29.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:30:31.296+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:30:31.305+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:30:31.297+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:30:31.308+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:30:31.468+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.737 seconds
[2023-07-26T22:31:02.081+0000] {processor.py:153} INFO - Started process (PID=15612) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:31:02.083+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:31:02.085+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:31:02.085+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:31:04.675+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:31:04.697+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:31:04.676+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:31:04.703+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:31:04.995+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.926 seconds
[2023-07-26T22:31:35.314+0000] {processor.py:153} INFO - Started process (PID=15640) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:31:35.316+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:31:35.318+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:31:35.318+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:31:37.134+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:31:37.147+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:31:37.137+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:31:37.151+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:31:37.360+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.054 seconds
[2023-07-26T22:32:08.312+0000] {processor.py:153} INFO - Started process (PID=15671) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:32:08.315+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:32:08.318+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:32:08.317+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:32:10.358+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:32:10.392+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:32:10.359+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:32:10.398+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:32:10.646+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.342 seconds
[2023-07-26T22:32:40.956+0000] {processor.py:153} INFO - Started process (PID=15702) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:32:40.959+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:32:40.961+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:32:40.961+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:32:42.794+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:32:42.807+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:32:42.795+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:32:42.812+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:32:42.907+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.961 seconds
[2023-07-26T22:33:13.295+0000] {processor.py:153} INFO - Started process (PID=15734) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:33:13.298+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:33:13.300+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:33:13.300+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:33:15.244+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:33:15.255+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:33:15.245+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:33:15.257+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:33:15.485+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.197 seconds
[2023-07-26T22:33:46.587+0000] {processor.py:153} INFO - Started process (PID=15765) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:33:46.592+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:33:46.607+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:33:46.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:33:50.403+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:33:50.417+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:33:50.405+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:33:50.422+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:33:50.668+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.131 seconds
[2023-07-26T22:34:21.984+0000] {processor.py:153} INFO - Started process (PID=15789) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:34:22.001+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:34:22.018+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:34:22.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:34:25.428+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:34:25.467+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:34:25.432+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:34:25.485+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:34:25.654+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.712 seconds
[2023-07-26T22:34:56.345+0000] {processor.py:153} INFO - Started process (PID=15822) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:34:56.348+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:34:56.350+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:34:56.350+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:34:57.806+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:34:57.821+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:34:57.809+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:34:57.826+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:34:57.946+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.607 seconds
[2023-07-26T22:35:28.155+0000] {processor.py:153} INFO - Started process (PID=15853) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:35:28.157+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:35:28.159+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:35:28.159+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:35:29.698+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:35:29.710+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:35:29.699+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:35:29.714+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:35:29.906+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.756 seconds
[2023-07-26T22:36:00.696+0000] {processor.py:153} INFO - Started process (PID=15885) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:36:00.698+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:36:00.700+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:36:00.700+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:36:03.305+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:36:03.315+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:36:03.306+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:36:03.317+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:36:03.693+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.004 seconds
[2023-07-26T22:36:34.111+0000] {processor.py:153} INFO - Started process (PID=15914) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:36:34.117+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:36:34.120+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:36:34.120+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:36:36.442+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:36:36.490+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:36:36.459+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:36:36.495+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:36:36.745+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.643 seconds
[2023-07-26T22:37:07.262+0000] {processor.py:153} INFO - Started process (PID=15943) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:37:07.264+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:37:07.267+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:37:07.266+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:37:09.862+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:37:09.889+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:37:09.866+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:37:09.893+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:37:10.087+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.834 seconds
[2023-07-26T22:37:40.462+0000] {processor.py:153} INFO - Started process (PID=15969) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:37:40.465+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:37:40.467+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:37:40.466+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:37:42.059+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:37:42.077+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:37:42.060+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:37:42.080+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:37:42.241+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.786 seconds
[2023-07-26T22:38:12.472+0000] {processor.py:153} INFO - Started process (PID=15998) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:38:12.475+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:38:12.478+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:38:12.477+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:38:14.954+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:38:14.988+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:38:14.957+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:38:15.035+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:38:15.343+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.883 seconds
[2023-07-26T22:38:45.807+0000] {processor.py:153} INFO - Started process (PID=16020) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:38:45.809+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:38:45.810+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:38:45.810+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:38:47.564+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:38:47.603+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:38:47.573+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:38:47.607+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:38:48.797+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.996 seconds
[2023-07-26T22:39:19.159+0000] {processor.py:153} INFO - Started process (PID=16052) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:39:19.212+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:39:19.216+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:39:19.215+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:39:21.086+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:39:21.102+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:39:21.089+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:39:21.108+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:39:21.437+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.286 seconds
[2023-07-26T22:39:54.801+0000] {processor.py:153} INFO - Started process (PID=16081) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:39:54.803+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:39:54.805+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:39:54.805+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:39:57.165+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:39:57.177+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:39:57.166+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:39:57.182+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:39:57.553+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.761 seconds
[2023-07-26T22:40:28.307+0000] {processor.py:153} INFO - Started process (PID=16103) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:40:28.311+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:40:28.313+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:40:28.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:40:30.175+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:40:30.186+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:40:30.176+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:40:30.189+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:40:31.335+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.036 seconds
[2023-07-26T22:41:02.615+0000] {processor.py:153} INFO - Started process (PID=16130) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:41:02.646+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:41:02.656+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:41:02.655+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:41:07.849+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:41:07.936+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:41:07.859+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:41:07.978+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:41:08.626+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.018 seconds
[2023-07-26T22:41:38.797+0000] {processor.py:153} INFO - Started process (PID=16152) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:41:38.799+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:41:38.800+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:41:38.800+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:41:40.291+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:41:40.441+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:41:40.341+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:41:40.445+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:41:41.653+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.864 seconds
[2023-07-26T22:42:12.225+0000] {processor.py:153} INFO - Started process (PID=16171) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:42:12.228+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:42:12.230+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:42:12.229+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:42:14.889+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:42:14.912+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:42:14.892+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:42:14.948+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:42:15.452+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.239 seconds
[2023-07-26T22:42:46.570+0000] {processor.py:153} INFO - Started process (PID=16201) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:42:46.572+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:42:46.575+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:42:46.575+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:42:50.475+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:42:50.486+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:42:50.477+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:42:50.490+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:42:52.385+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 5.815 seconds
[2023-07-26T22:43:22.927+0000] {processor.py:153} INFO - Started process (PID=16221) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:43:22.950+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:43:23.014+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:43:23.013+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:43:29.213+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:43:29.845+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:43:29.274+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:43:29.926+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:43:31.482+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 8.563 seconds
[2023-07-26T22:44:02.367+0000] {processor.py:153} INFO - Started process (PID=16250) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:44:02.379+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:44:02.400+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:44:02.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:44:05.856+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:44:05.879+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:44:05.861+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:44:05.885+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:44:06.119+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.765 seconds
[2023-07-26T22:44:36.417+0000] {processor.py:153} INFO - Started process (PID=16273) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:44:36.419+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:44:36.422+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:44:36.421+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:44:38.454+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:44:38.465+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:44:38.456+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:44:38.470+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:44:40.021+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.617 seconds
[2023-07-26T22:45:11.492+0000] {processor.py:153} INFO - Started process (PID=16291) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:45:11.544+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:45:11.620+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:45:11.619+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:45:17.489+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:45:17.874+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:45:17.522+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:45:17.986+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:45:18.414+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 6.940 seconds
[2023-07-26T22:45:49.194+0000] {processor.py:153} INFO - Started process (PID=16319) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:45:49.198+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:45:49.201+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:45:49.201+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:45:51.839+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:45:51.863+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:45:51.853+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:45:51.870+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:45:52.425+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.278 seconds
[2023-07-26T22:46:22.597+0000] {processor.py:153} INFO - Started process (PID=16341) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:46:22.599+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:46:22.601+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:46:22.600+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:46:24.321+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:46:24.330+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:46:24.322+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:46:24.333+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:46:24.697+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.108 seconds
[2023-07-26T22:46:55.171+0000] {processor.py:153} INFO - Started process (PID=16373) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:46:55.173+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:46:55.175+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:46:55.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:46:56.955+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:46:56.964+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:46:56.956+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:46:56.967+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:46:57.167+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.006 seconds
[2023-07-26T22:47:27.980+0000] {processor.py:153} INFO - Started process (PID=16405) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:47:27.982+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:47:27.984+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:47:27.984+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:47:30.698+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:47:30.738+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:47:30.700+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:47:30.752+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:47:31.160+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.186 seconds
[2023-07-26T22:48:01.596+0000] {processor.py:153} INFO - Started process (PID=16433) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:48:01.598+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:48:01.600+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:48:01.600+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:48:04.593+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:48:04.623+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:48:04.600+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:48:04.629+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:48:04.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.231 seconds
[2023-07-26T22:48:35.052+0000] {processor.py:153} INFO - Started process (PID=16456) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:48:35.054+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:48:35.057+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:48:35.056+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:48:36.735+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:48:36.745+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:48:36.735+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:48:36.748+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:48:37.079+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.034 seconds
[2023-07-26T22:49:07.626+0000] {processor.py:153} INFO - Started process (PID=16488) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:49:07.628+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:49:07.630+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:49:07.630+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:49:12.057+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:49:12.075+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:49:12.059+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:49:12.079+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:49:12.455+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.841 seconds
[2023-07-26T22:49:43.214+0000] {processor.py:153} INFO - Started process (PID=16520) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:49:43.216+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:49:43.218+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:49:43.218+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:49:45.321+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:49:45.335+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:49:45.323+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:49:45.339+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:49:45.558+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.351 seconds
[2023-07-26T22:50:16.116+0000] {processor.py:153} INFO - Started process (PID=16552) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:50:16.197+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:50:16.199+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:50:16.199+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:50:18.491+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:50:18.535+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:50:18.500+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:50:18.543+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:50:20.204+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 4.096 seconds
[2023-07-26T22:50:50.378+0000] {processor.py:153} INFO - Started process (PID=16584) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:50:50.383+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:50:50.388+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:50:50.387+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:50:52.932+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:50:52.955+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:50:52.935+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:50:52.959+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:50:53.122+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.758 seconds
[2023-07-26T22:51:23.485+0000] {processor.py:153} INFO - Started process (PID=16617) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:51:23.487+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:51:23.492+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:51:23.492+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:51:25.398+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:51:25.447+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:51:25.400+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:51:25.453+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:51:25.813+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.334 seconds
[2023-07-26T22:51:56.183+0000] {processor.py:153} INFO - Started process (PID=16638) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:51:56.185+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:51:56.187+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:51:56.187+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:51:58.070+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T22:51:58.084+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:51:58.072+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T22:51:58.089+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:51:58.627+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.450 seconds
[2023-07-26T22:52:28.308+0000] {processor.py:153} INFO - Started process (PID=16669) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:52:28.311+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:52:28.313+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:52:28.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:52:29.276+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:52:29.262+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:52:29.280+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:52:30.239+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.939 seconds
[2023-07-26T22:53:00.490+0000] {processor.py:153} INFO - Started process (PID=16702) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:53:00.498+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:53:00.506+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:53:00.505+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:53:03.040+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:53:03.024+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:53:03.044+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:53:03.484+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.013 seconds
[2023-07-26T22:53:33.582+0000] {processor.py:153} INFO - Started process (PID=16733) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:53:33.583+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:53:33.586+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:53:33.585+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:53:34.447+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:53:34.435+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:53:34.451+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:53:35.294+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.720 seconds
[2023-07-26T22:54:05.665+0000] {processor.py:153} INFO - Started process (PID=16763) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:54:05.669+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:54:05.672+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:54:05.671+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:54:06.645+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:54:06.627+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:54:06.655+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:54:06.969+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.320 seconds
[2023-07-26T22:54:37.328+0000] {processor.py:153} INFO - Started process (PID=16786) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:54:37.330+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:54:37.332+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:54:37.332+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:54:38.156+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:54:38.147+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:54:38.160+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:54:38.403+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.081 seconds
[2023-07-26T22:55:08.498+0000] {processor.py:153} INFO - Started process (PID=16818) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:55:08.500+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:55:08.504+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:55:08.504+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:55:09.530+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:55:09.521+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:55:09.533+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:55:09.671+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.181 seconds
[2023-07-26T22:55:40.041+0000] {processor.py:153} INFO - Started process (PID=16852) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:55:40.045+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:55:40.050+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:55:40.050+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:55:41.119+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:55:41.107+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:55:41.122+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:55:41.439+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.417 seconds
[2023-07-26T22:56:12.093+0000] {processor.py:153} INFO - Started process (PID=16882) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:56:12.096+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:56:12.111+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:56:12.110+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:56:13.837+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:56:13.819+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:56:13.848+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:56:14.177+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.094 seconds
[2023-07-26T22:56:44.321+0000] {processor.py:153} INFO - Started process (PID=16904) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:56:44.322+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:56:44.324+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:56:44.324+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:56:45.236+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:56:45.215+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:56:45.242+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:56:45.466+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.151 seconds
[2023-07-26T22:57:16.295+0000] {processor.py:153} INFO - Started process (PID=16936) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:57:16.297+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:57:16.299+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:57:16.299+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:57:18.232+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:57:18.207+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:57:18.237+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:57:18.410+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.146 seconds
[2023-07-26T22:57:48.525+0000] {processor.py:153} INFO - Started process (PID=16967) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:57:48.528+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:57:48.530+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:57:48.529+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:57:49.434+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:57:49.425+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:57:49.438+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:57:49.634+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.116 seconds
[2023-07-26T22:58:20.208+0000] {processor.py:153} INFO - Started process (PID=16998) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:58:20.211+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:58:20.213+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:58:20.213+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:58:21.251+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:58:21.242+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:58:21.254+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:58:21.557+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.359 seconds
[2023-07-26T22:58:52.243+0000] {processor.py:153} INFO - Started process (PID=17018) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:58:52.245+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:58:52.248+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:58:52.247+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:58:53.393+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:58:53.379+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:58:53.397+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:58:53.537+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.299 seconds
[2023-07-26T22:59:24.076+0000] {processor.py:153} INFO - Started process (PID=17049) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:59:24.078+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:59:24.080+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:59:24.079+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:59:24.778+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:59:24.771+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:59:24.781+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:59:25.294+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.224 seconds
[2023-07-26T22:59:56.157+0000] {processor.py:153} INFO - Started process (PID=17081) to work on /opt/airflow/dags/load_data.py
[2023-07-26T22:59:56.159+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T22:59:56.161+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:59:56.161+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T22:59:56.997+0000] {logging_mixin.py:137} INFO - [2023-07-26T22:59:56.983+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T22:59:57.000+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T22:59:57.299+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.149 seconds
[2023-07-26T23:00:27.778+0000] {processor.py:153} INFO - Started process (PID=17112) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:00:27.781+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:00:27.783+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:00:27.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:00:28.971+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:00:28.948+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T23:00:28.982+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:00:29.141+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.369 seconds
[2023-07-26T23:00:59.916+0000] {processor.py:153} INFO - Started process (PID=17144) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:00:59.919+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:00:59.921+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:00:59.920+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:01:01.175+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:01:01.127+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T23:01:01.191+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:01:01.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.539 seconds
[2023-07-26T23:01:31.878+0000] {processor.py:153} INFO - Started process (PID=17172) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:01:31.880+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:01:31.882+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:01:31.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:01:32.935+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:01:32.926+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T23:01:32.939+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:01:33.420+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.550 seconds
[2023-07-26T23:02:03.677+0000] {processor.py:153} INFO - Started process (PID=17204) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:02:03.679+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:02:03.681+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:02:03.681+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:02:04.812+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:02:04.802+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T23:02:04.819+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:02:05.318+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.652 seconds
[2023-07-26T23:02:35.937+0000] {processor.py:153} INFO - Started process (PID=17235) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:02:35.940+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:02:35.942+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:02:35.942+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:02:37.040+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:02:37.031+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 9, in <module>
    'start_date': datetime(2023, 7, 26),
NameError: name 'datetime' is not defined
[2023-07-26T23:02:37.044+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:02:37.201+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.285 seconds
[2023-07-26T23:02:49.721+0000] {processor.py:153} INFO - Started process (PID=17243) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:02:49.723+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:02:49.725+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:02:49.725+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:02:51.860+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:02:51.873+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:02:51.861+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:02:51.876+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:02:52.356+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.645 seconds
[2023-07-26T23:03:22.506+0000] {processor.py:153} INFO - Started process (PID=17275) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:03:22.507+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:03:22.510+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:03:22.509+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:03:24.257+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:03:24.268+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:03:24.258+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:03:24.271+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:03:24.527+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.028 seconds
[2023-07-26T23:03:54.668+0000] {processor.py:153} INFO - Started process (PID=17307) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:03:54.748+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:03:54.752+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:03:54.752+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:03:56.660+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:03:56.675+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:03:56.663+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:03:56.683+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:03:57.017+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.357 seconds
[2023-07-26T23:04:28.135+0000] {processor.py:153} INFO - Started process (PID=17335) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:04:28.149+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:04:28.151+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:04:28.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:04:30.503+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:04:30.515+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:04:30.504+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:04:30.520+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:04:30.660+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.533 seconds
[2023-07-26T23:04:48.892+0000] {processor.py:153} INFO - Started process (PID=17354) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:04:48.894+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:04:48.896+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:04:48.896+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:05:00.731+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:05:00.723+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 7, in <module>
    'start_date': datetime(2023, 1, 1)
NameError: name 'datetime' is not defined
[2023-07-26T23:05:00.738+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:05:02.088+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 13.213 seconds
[2023-07-26T23:05:32.918+0000] {processor.py:153} INFO - Started process (PID=17385) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:05:32.923+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:05:32.928+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:05:32.927+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:05:33.112+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:05:33.099+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 7, in <module>
    'start_date': datetime(2023, 1, 1)
NameError: name 'datetime' is not defined
[2023-07-26T23:05:33.118+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:05:33.443+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.538 seconds
[2023-07-26T23:06:03.909+0000] {processor.py:153} INFO - Started process (PID=17406) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:06:03.911+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:06:03.913+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:06:03.913+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:06:04.015+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:06:04.004+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 7, in <module>
    'start_date': datetime(2023, 1, 1)
NameError: name 'datetime' is not defined
[2023-07-26T23:06:04.019+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:06:04.209+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.307 seconds
[2023-07-26T23:06:34.869+0000] {processor.py:153} INFO - Started process (PID=17436) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:06:34.873+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:06:34.877+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:06:34.876+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:06:35.124+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:06:35.108+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 7, in <module>
    'start_date': datetime(2023, 1, 1)
NameError: name 'datetime' is not defined
[2023-07-26T23:06:35.128+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:06:35.374+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.520 seconds
[2023-07-26T23:07:05.765+0000] {processor.py:153} INFO - Started process (PID=17462) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:07:05.767+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:07:05.774+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:07:05.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:07:06.112+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:07:06.056+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 7, in <module>
    'start_date': datetime(2023, 1, 1)
NameError: name 'datetime' is not defined
[2023-07-26T23:07:06.118+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:07:06.335+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.581 seconds
[2023-07-26T23:07:36.809+0000] {processor.py:153} INFO - Started process (PID=17484) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:07:36.812+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:07:36.816+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:07:36.815+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:07:36.930+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:07:36.918+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 7, in <module>
    'start_date': datetime(2023, 1, 1)
NameError: name 'datetime' is not defined
[2023-07-26T23:07:36.935+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:07:37.057+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 0.255 seconds
[2023-07-26T23:08:07.202+0000] {processor.py:153} INFO - Started process (PID=17515) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:08:07.205+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:08:07.210+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:08:07.210+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:08:08.771+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:08:08.473+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 7, in <module>
    'start_date': datetime(2023, 1, 1)
NameError: name 'datetime' is not defined
[2023-07-26T23:08:08.802+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:08:09.214+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.030 seconds
[2023-07-26T23:08:24.953+0000] {processor.py:153} INFO - Started process (PID=17527) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:08:24.956+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:08:24.958+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:08:24.958+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:08:27.632+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:08:27.650+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:08:27.634+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:08:27.658+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:08:28.035+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.088 seconds
[2023-07-26T23:08:58.335+0000] {processor.py:153} INFO - Started process (PID=17549) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:08:58.362+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:08:58.364+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:08:58.363+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:09:00.058+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:09:00.070+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:09:00.059+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:09:00.073+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:09:00.449+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.120 seconds
[2023-07-26T23:09:30.673+0000] {processor.py:153} INFO - Started process (PID=17581) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:09:30.675+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:09:30.677+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:09:30.677+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:09:32.594+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:09:32.606+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:09:32.596+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:09:32.610+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:09:32.816+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.150 seconds
[2023-07-26T23:10:03.458+0000] {processor.py:153} INFO - Started process (PID=17610) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:10:03.460+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:10:03.463+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:10:03.462+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:10:05.706+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:10:05.717+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:10:05.707+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:10:05.720+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:10:06.628+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.180 seconds
[2023-07-26T23:10:36.778+0000] {processor.py:153} INFO - Started process (PID=17638) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:10:36.780+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:10:36.783+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:10:36.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:10:38.545+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:10:38.556+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:10:38.546+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:10:38.559+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:10:38.857+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.086 seconds
[2023-07-26T23:11:09.070+0000] {processor.py:153} INFO - Started process (PID=17662) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:11:09.072+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:11:09.074+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:11:09.074+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:11:11.229+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:11:11.242+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:11:11.231+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:11:11.246+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:11:12.795+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.733 seconds
[2023-07-26T23:11:43.557+0000] {processor.py:153} INFO - Started process (PID=17694) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:11:43.561+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:11:43.565+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:11:43.564+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:11:45.249+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:11:45.259+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:11:45.250+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:11:45.262+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:11:45.456+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.908 seconds
[2023-07-26T23:12:15.701+0000] {processor.py:153} INFO - Started process (PID=17726) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:12:15.706+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:12:15.711+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:12:15.711+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:12:17.429+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:12:17.442+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:12:17.431+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:12:17.446+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:12:17.587+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.896 seconds
[2023-07-26T23:12:47.998+0000] {processor.py:153} INFO - Started process (PID=17767) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:12:48.000+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:12:48.002+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:12:48.002+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:12:50.305+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:12:50.328+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:12:50.311+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:12:50.333+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:12:50.640+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.648 seconds
[2023-07-26T23:13:20.822+0000] {processor.py:153} INFO - Started process (PID=17791) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:13:20.824+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:13:20.826+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:13:20.826+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:13:22.400+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:13:22.409+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:13:22.401+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:13:22.412+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:13:22.566+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.750 seconds
[2023-07-26T23:13:52.878+0000] {processor.py:153} INFO - Started process (PID=17823) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:13:52.880+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:13:52.882+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:13:52.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:13:54.857+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:13:54.867+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:13:54.858+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:13:54.870+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:13:55.160+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.288 seconds
[2023-07-26T23:14:25.526+0000] {processor.py:153} INFO - Started process (PID=17855) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:14:25.528+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:14:25.530+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:14:25.530+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:14:27.600+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:14:27.619+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:14:27.602+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:14:27.626+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:14:27.763+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.245 seconds
[2023-07-26T23:14:58.138+0000] {processor.py:153} INFO - Started process (PID=17886) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:14:58.140+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:14:58.143+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:14:58.142+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:14:59.803+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:14:59.813+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:14:59.804+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:14:59.816+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:14:59.975+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.846 seconds
[2023-07-26T23:15:30.776+0000] {processor.py:153} INFO - Started process (PID=17918) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:15:30.786+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:15:30.789+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:15:30.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:15:32.348+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:15:32.359+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:15:32.349+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:15:32.363+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:15:32.499+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.730 seconds
[2023-07-26T23:16:02.699+0000] {processor.py:153} INFO - Started process (PID=17950) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:16:02.702+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:16:02.704+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:16:02.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:16:04.895+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:16:04.910+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:16:04.897+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:16:04.913+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:16:05.225+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.533 seconds
[2023-07-26T23:16:35.475+0000] {processor.py:153} INFO - Started process (PID=17982) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:16:35.477+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:16:35.480+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:16:35.479+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:16:37.097+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:16:37.108+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:16:37.098+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:16:37.111+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:16:37.446+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.982 seconds
[2023-07-26T23:17:07.692+0000] {processor.py:153} INFO - Started process (PID=18014) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:17:07.694+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:17:07.697+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:17:07.697+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:17:09.622+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:17:09.635+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:17:09.623+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:17:09.638+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:17:09.858+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.173 seconds
[2023-07-26T23:17:40.003+0000] {processor.py:153} INFO - Started process (PID=18044) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:17:40.008+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:17:40.012+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:17:40.012+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:17:41.604+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:17:41.615+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:17:41.605+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:17:41.619+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:17:41.838+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.851 seconds
[2023-07-26T23:18:12.285+0000] {processor.py:153} INFO - Started process (PID=18074) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:18:12.288+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:18:12.291+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:18:12.290+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:18:14.483+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:18:14.494+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:18:14.485+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:18:14.497+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:18:14.723+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.452 seconds
[2023-07-26T23:18:45.232+0000] {processor.py:153} INFO - Started process (PID=18107) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:18:45.235+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:18:45.237+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:18:45.237+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:18:47.090+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:18:47.105+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:18:47.092+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:18:47.109+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:18:47.283+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.060 seconds
[2023-07-26T23:19:17.609+0000] {processor.py:153} INFO - Started process (PID=18139) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:19:17.611+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:19:17.613+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:19:17.612+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:19:19.670+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:19:19.683+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:19:19.672+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:19:19.686+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:19:19.876+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.275 seconds
[2023-07-26T23:19:50.435+0000] {processor.py:153} INFO - Started process (PID=18170) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:19:50.439+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:19:50.442+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:19:50.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:19:52.301+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:19:52.315+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:19:52.302+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:19:52.319+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:19:52.588+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.160 seconds
[2023-07-26T23:20:23.126+0000] {processor.py:153} INFO - Started process (PID=18202) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:20:23.129+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:20:23.131+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:20:23.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:20:25.084+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:20:25.096+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:20:25.086+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:20:25.099+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:20:25.344+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.225 seconds
[2023-07-26T23:20:55.635+0000] {processor.py:153} INFO - Started process (PID=18233) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:20:55.638+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:20:55.641+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:20:55.641+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:20:57.415+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:20:57.444+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:20:57.425+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:20:57.449+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:20:57.600+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.971 seconds
[2023-07-26T23:21:28.018+0000] {processor.py:153} INFO - Started process (PID=18264) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:21:28.020+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:21:28.022+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:21:28.022+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:21:29.668+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:21:29.681+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:21:29.669+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:21:29.685+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:21:29.956+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.943 seconds
[2023-07-26T23:22:00.136+0000] {processor.py:153} INFO - Started process (PID=18296) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:22:00.147+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:22:00.150+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:22:00.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:22:02.485+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:22:02.497+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:22:02.488+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:22:02.500+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:22:02.696+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.568 seconds
[2023-07-26T23:22:33.023+0000] {processor.py:153} INFO - Started process (PID=18329) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:22:33.026+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:22:33.029+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:22:33.028+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:22:34.790+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:22:34.801+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:22:34.791+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:22:34.804+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:22:34.904+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.890 seconds
[2023-07-26T23:23:05.324+0000] {processor.py:153} INFO - Started process (PID=18362) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:23:05.326+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:23:05.328+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:23:05.328+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:23:07.020+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:23:07.031+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:23:07.021+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:23:07.038+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:23:07.376+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.060 seconds
[2023-07-26T23:23:37.852+0000] {processor.py:153} INFO - Started process (PID=18393) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:23:37.855+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:23:37.857+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:23:37.857+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:23:40.300+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:23:40.313+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:23:40.304+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:23:40.317+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:23:40.792+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.950 seconds
[2023-07-26T23:24:11.087+0000] {processor.py:153} INFO - Started process (PID=18413) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:24:11.097+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:24:11.100+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:24:11.099+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:24:13.496+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:24:13.507+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:24:13.497+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:24:13.511+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:24:13.720+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.638 seconds
[2023-07-26T23:24:43.833+0000] {processor.py:153} INFO - Started process (PID=18451) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:24:43.836+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:24:43.838+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:24:43.837+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:24:46.322+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:24:46.338+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:24:46.323+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:24:46.352+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:24:46.654+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.829 seconds
[2023-07-26T23:25:17.074+0000] {processor.py:153} INFO - Started process (PID=18478) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:25:17.076+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:25:17.078+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:25:17.078+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:25:18.588+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:25:18.600+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:25:18.590+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:25:18.603+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:25:18.699+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.634 seconds
[2023-07-26T23:25:48.802+0000] {processor.py:153} INFO - Started process (PID=18509) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:25:48.804+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:25:48.806+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:25:48.806+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:25:50.293+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:25:50.306+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:25:50.294+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:25:50.310+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:25:50.555+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.758 seconds
[2023-07-26T23:26:20.749+0000] {processor.py:153} INFO - Started process (PID=18541) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:26:20.752+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:26:20.757+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:26:20.755+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:26:22.963+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:26:22.972+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:26:22.963+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 110, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:26:22.976+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:26:23.200+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.459 seconds
[2023-07-26T23:26:47.150+0000] {processor.py:153} INFO - Started process (PID=18573) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:26:47.152+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:26:47.153+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:26:47.153+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:26:49.584+0000] {logging_mixin.py:137} INFO - The data dictionary does not contain the 'data' key.
[2023-07-26T23:26:49.595+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:26:49.586+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 194, in <module>
    employer_website, job_id, job_employment_type, job_title, job_apply_link, job_description, job_city, job_country, job_posted_at_date, employer_company_type = extract_relevant_records_from_overall_data(data)
TypeError: cannot unpack non-iterable NoneType object
[2023-07-26T23:26:49.599+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:26:49.737+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.593 seconds
[2023-07-26T23:27:02.584+0000] {processor.py:153} INFO - Started process (PID=18590) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:27:02.586+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:27:02.588+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:27:02.587+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:27:04.109+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:27:04.487+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:27:04.486+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:27:04.547+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:27:04.547+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:27:05.149+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.573 seconds
[2023-07-26T23:27:35.452+0000] {processor.py:153} INFO - Started process (PID=18621) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:27:35.463+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:27:35.467+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:27:35.467+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:27:36.303+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:27:36.372+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:27:36.372+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:27:36.440+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:27:36.440+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:27:36.574+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.128 seconds
[2023-07-26T23:28:06.815+0000] {processor.py:153} INFO - Started process (PID=18652) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:28:06.819+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:28:06.820+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:28:06.820+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:28:08.257+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:28:08.404+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:28:08.402+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:28:08.615+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:28:08.613+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:28:09.000+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.194 seconds
[2023-07-26T23:28:13.982+0000] {processor.py:153} INFO - Started process (PID=18657) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:28:13.985+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:28:13.990+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:28:13.989+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:28:15.254+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:28:15.322+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:28:15.321+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:28:15.370+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:28:15.369+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:28:15.580+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.607 seconds
[2023-07-26T23:28:45.974+0000] {processor.py:153} INFO - Started process (PID=18690) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:28:45.976+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:28:45.977+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:28:45.977+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:28:46.692+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:28:46.756+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:28:46.755+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:28:46.819+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:28:46.819+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:28:46.996+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.029 seconds
[2023-07-26T23:29:17.515+0000] {processor.py:153} INFO - Started process (PID=18723) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:29:17.518+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:29:17.520+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:29:17.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:29:18.379+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:29:18.434+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:29:18.434+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:29:18.475+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:29:18.475+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:29:18.623+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.113 seconds
[2023-07-26T23:29:48.643+0000] {processor.py:153} INFO - Started process (PID=18755) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:29:48.648+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:29:48.657+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:29:48.657+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:29:49.842+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:29:49.900+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:29:49.899+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:29:49.941+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:29:49.941+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:29:50.371+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.738 seconds
[2023-07-26T23:30:20.740+0000] {processor.py:153} INFO - Started process (PID=18781) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:30:20.742+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:30:20.744+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:30:20.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:30:22.076+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:30:22.153+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:30:22.152+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:30:22.224+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:30:22.223+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:30:22.463+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.742 seconds
[2023-07-26T23:30:52.769+0000] {processor.py:153} INFO - Started process (PID=18805) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:30:52.771+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:30:52.773+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:30:52.773+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:30:53.682+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:30:53.757+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:30:53.755+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:30:53.822+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:30:53.821+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:30:53.936+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.172 seconds
[2023-07-26T23:31:24.425+0000] {processor.py:153} INFO - Started process (PID=18837) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:31:24.428+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:31:24.429+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:31:24.429+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:31:25.934+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:31:26.106+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:31:26.104+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:31:26.261+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:31:26.260+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:31:26.435+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.016 seconds
[2023-07-26T23:31:56.778+0000] {processor.py:153} INFO - Started process (PID=18868) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:31:56.781+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:31:56.784+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:31:56.784+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:31:58.072+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:31:58.183+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:31:58.182+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:31:58.251+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:31:58.251+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:31:58.430+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.661 seconds
[2023-07-26T23:32:29.060+0000] {processor.py:153} INFO - Started process (PID=18896) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:32:29.064+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:32:29.066+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:32:29.066+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:32:30.710+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:32:30.805+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:32:30.804+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:32:30.883+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:32:30.883+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:32:31.211+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.160 seconds
[2023-07-26T23:33:01.394+0000] {processor.py:153} INFO - Started process (PID=18919) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:33:01.396+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:33:01.398+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:33:01.398+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:33:02.551+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:33:02.647+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:33:02.646+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:33:02.738+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:33:02.737+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:33:03.039+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.655 seconds
[2023-07-26T23:33:15.900+0000] {processor.py:153} INFO - Started process (PID=18935) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:33:15.902+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:33:15.905+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:33:15.904+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:33:16.808+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:33:16.981+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:33:16.979+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:33:17.045+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:33:17.045+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:33:17.211+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.318 seconds
[2023-07-26T23:33:47.617+0000] {processor.py:153} INFO - Started process (PID=18967) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:33:47.619+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:33:47.623+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:33:47.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:33:49.289+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:33:49.423+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:33:49.422+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:33:49.504+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:33:49.504+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:33:49.619+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.093 seconds
[2023-07-26T23:34:20.049+0000] {processor.py:153} INFO - Started process (PID=18986) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:34:20.052+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:34:20.054+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:34:20.054+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:34:21.748+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:34:21.842+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:34:21.841+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:34:21.933+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:34:21.932+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2023-07-26T23:34:22.147+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.115 seconds
[2023-07-26T23:34:52.689+0000] {processor.py:153} INFO - Started process (PID=19018) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:34:52.691+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:34:52.693+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:34:52.693+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:34:54.741+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:34:54.964+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:34:54.963+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:34:55.365+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:34:55.364+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-07T00:00:00+00:00, run_after=2022-01-08T00:00:00+00:00
[2023-07-26T23:34:55.900+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.221 seconds
[2023-07-26T23:35:26.321+0000] {processor.py:153} INFO - Started process (PID=19034) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:35:26.408+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:35:26.412+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:35:26.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:35:40.998+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:35:41.373+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:35:41.372+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:35:41.555+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:35:41.554+0000] {dag.py:3427} INFO - Setting next_dagrun for data_engineer_jobs_dag to 2022-01-14T00:00:00+00:00, run_after=2022-01-15T00:00:00+00:00
[2023-07-26T23:35:42.039+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 15.735 seconds
[2023-07-26T23:36:16.141+0000] {processor.py:153} INFO - Started process (PID=19094) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:36:16.195+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:36:16.460+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:36:16.460+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:36:46.985+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:36:46.970+0000] {timeout.py:68} ERROR - Process timed out, PID: 19094
[2023-07-26T23:36:47.656+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:36:46.990+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/load_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_data.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 29, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/__init__.py", line 7, in <module>
    from pandas.core.arrays.categorical import Categorical
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/categorical.py", line 113, in <module>
    from pandas.core.strings.object_array import ObjectStringArrayMixin
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 818, in get_code
  File "<frozen importlib._bootstrap_external>", line 917, in get_data
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/load_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.5.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.5.0/best-practices.html#reducing-dag-complexity, PID: 19094
[2023-07-26T23:36:47.657+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:36:49.050+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 33.025 seconds
[2023-07-26T23:37:19.220+0000] {processor.py:153} INFO - Started process (PID=19141) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:37:19.222+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:37:19.224+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:37:19.224+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:38:18.609+0000] {processor.py:153} INFO - Started process (PID=19183) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:38:18.705+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:38:18.710+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:38:18.710+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:38:51.655+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:38:51.653+0000] {timeout.py:68} ERROR - Process timed out, PID: 19183
[2023-07-26T23:38:51.656+0000] {logging_mixin.py:137} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7f6dcb8e7440>
[2023-07-26T23:38:51.656+0000] {logging_mixin.py:137} WARNING - Traceback (most recent call last):
[2023-07-26T23:38:51.657+0000] {logging_mixin.py:137} WARNING -   File "/usr/local/lib/python3.7/weakref.py", line 358, in remove
[2023-07-26T23:38:51.658+0000] {logging_mixin.py:137} WARNING -     def remove(k, selfref=ref(self)):
[2023-07-26T23:38:51.659+0000] {logging_mixin.py:137} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
[2023-07-26T23:38:51.660+0000] {logging_mixin.py:137} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-07-26T23:38:51.661+0000] {logging_mixin.py:137} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/load_data.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.5.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.5.0/best-practices.html#reducing-dag-complexity, PID: 19183
[2023-07-26T23:38:52.704+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:38:52.823+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:38:52.823+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:38:53.088+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 34.489 seconds
[2023-07-26T23:39:23.528+0000] {processor.py:153} INFO - Started process (PID=19236) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:39:23.541+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:39:23.544+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:39:23.544+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:39:25.896+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:39:26.033+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:39:26.032+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:39:26.666+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 3.149 seconds
[2023-07-26T23:39:57.323+0000] {processor.py:153} INFO - Started process (PID=19262) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:39:57.325+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:39:57.327+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:39:57.326+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:39:58.484+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:39:58.686+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:39:58.675+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:39:59.904+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 2.588 seconds
[2023-07-26T23:40:30.131+0000] {processor.py:153} INFO - Started process (PID=19293) to work on /opt/airflow/dags/load_data.py
[2023-07-26T23:40:30.132+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/load_data.py for tasks to queue
[2023-07-26T23:40:30.134+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:40:30.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/load_data.py
[2023-07-26T23:40:30.868+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_engineer_jobs_dag']) retrieved from /opt/airflow/dags/load_data.py
[2023-07-26T23:40:30.926+0000] {logging_mixin.py:137} INFO - [2023-07-26T23:40:30.925+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-07-26T23:40:31.993+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/load_data.py took 1.869 seconds
